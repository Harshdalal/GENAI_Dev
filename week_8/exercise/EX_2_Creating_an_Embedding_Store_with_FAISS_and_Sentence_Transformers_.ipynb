{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Creating an Embedding Store with FAISS and Sentence Transformers\n",
        "\n",
        "## Objective\n",
        "This assignment focuses on building an efficient embedding store using FAISS (Facebook AI Similarity Search) and Sentence Transformers. You will learn to generate meaningful sentence embeddings and index them for fast similarity search, a fundamental component in many NLP applications like semantic search, recommendation systems, and RAG (Retrieval Augmented Generation) pipelines."
      ],
      "metadata": {
        "id": "VB4maJuL2oIs"
      },
      "id": "VB4maJuL2oIs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Environment Setup and Data Preparation (20 Marks)\n",
        "\n",
        "1.  **Environment Setup:**\n",
        "    * Create a new Python virtual environment for this assignment.\n",
        "    * Install the necessary libraries: `torch`, `transformers`, `sentence-transformers`, `faiss-cpu`, `numpy`, `scikit-learn`.\n",
        "    * Provide a `requirements.txt` file listing all dependencies.\n",
        "\n",
        "2.  **Dataset Acquisition:**\n",
        "    * Choose a text dataset for this assignment. Recommended options:\n",
        "        * A collection of movie plot summaries (e.g., from Kaggle or public domain sources).\n",
        "        * A subset of a news article dataset (e.g., AG News).\n",
        "        * A collection of scientific paper abstracts.\n",
        "    * **Minimum Requirement:** The dataset should contain at least **500 distinct text documents/sentences/paragraphs**.\n",
        "    * Load your chosen dataset into a suitable data structure (e.g., a list of strings or a Pandas DataFrame).\n",
        "    * Describe your chosen dataset, its source, and its characteristics (e.g., average sentence length, topic diversity)."
      ],
      "metadata": {
        "id": "JIe0osbL2oIt"
      },
      "id": "JIe0osbL2oIt"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5ajVQjR2oIu"
      },
      "outputs": [],
      "source": [
        "# Your code for environment setup description and dataset acquisition here.\n",
        "# Include comments and explanations."
      ],
      "id": "-5ajVQjR2oIu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Sentence Embedding Generation (30 Marks)\n",
        "\n",
        "1.  **Load Sentence Transformer Model:**\n",
        "    * Load a pre-trained Sentence Transformer model. Recommended models:\n",
        "        * `'all-MiniLM-L6-v2'` (good balance of performance and speed)\n",
        "        * `'all-mpnet-base-v2'` (higher performance)\n",
        "        * `'distilbert-base-nli-stsb-mean-tokens'`\n",
        "    * Justify your choice of model.\n",
        "\n",
        "2.  **Generate Embeddings:**\n",
        "    * Iterate through your dataset and generate embeddings for each text document/sentence/paragraph using the loaded Sentence Transformer model.\n",
        "    * Store the generated embeddings in a NumPy array. Ensure the data type is `float32` for FAISS compatibility.\n",
        "\n",
        "3.  **Inspect Embeddings:**\n",
        "    * Print the shape of the resulting embeddings array (e.g., `(num_samples, embedding_dimension)`).\n",
        "    * Display a few sample embeddings (e.g., the first 5 embeddings) to observe their structure.\n",
        "    * Discuss the dimensionality of the embeddings and its implications."
      ],
      "metadata": {
        "id": "jLVOha1M2oIu"
      },
      "id": "jLVOha1M2oIu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PPbdh2I_2oIv"
      },
      "outputs": [],
      "source": [
        "# Your code for loading the Sentence Transformer model and generating embeddings here.\n",
        "# Include model justification and embedding inspection."
      ],
      "id": "PPbdh2I_2oIv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: FAISS Index Creation and Population (30 Marks)\n",
        "\n",
        "1.  **Choose FAISS Index Type:**\n",
        "    * Select an appropriate FAISS index type for your needs. For this assignment, start with a simple index:\n",
        "        * `faiss.IndexFlatL2` (Exact L2 distance search - good for small datasets and understanding basics)\n",
        "        * Alternatively, `faiss.IndexFlatIP` (Exact Inner Product search if using normalized embeddings)\n",
        "    * Briefly explain your chosen index type and its characteristics.\n",
        "\n",
        "2.  **Initialize and Add Embeddings to Index:**\n",
        "    * Initialize the FAISS index with the correct embedding dimension.\n",
        "    * Add your generated embeddings to the FAISS index.\n",
        "    * Report the total number of vectors added to the index.\n",
        "\n",
        "3.  **Index Persistence (Optional, for extra credit):**\n",
        "    * Implement saving and loading the FAISS index to/from disk using `faiss.write_index` and `faiss.read_index`.\n",
        "    * Demonstrate saving and then loading the index."
      ],
      "metadata": {
        "id": "Zf_y1edx2oIv"
      },
      "id": "Zf_y1edx2oIv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Fnc4XrYg2oIv"
      },
      "outputs": [],
      "source": [
        "# Your code for FAISS index creation and population here.\n",
        "# Include explanations for your chosen index type."
      ],
      "id": "Fnc4XrYg2oIv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Similarity Search and Evaluation (20 Marks)\n",
        "\n",
        "1.  **Formulate Query:**\n",
        "    * Choose at least **3 distinct text queries** that are relevant to your dataset. These queries should *not* be directly present in your indexed documents, but semantically related.\n",
        "        * For example, if your dataset is movie plots, a query could be: \"A film about space exploration and finding new life.\"\n",
        "\n",
        "2.  **Generate Query Embeddings:**\n",
        "    * Generate embeddings for each of your query sentences using the *same* Sentence Transformer model used for your document embeddings.\n",
        "        * Ensure the query embeddings have the correct shape (e.g., `(1, embedding_dimension)` for a single query).\n",
        "\n",
        "3.  **Perform Similarity Search:**\n",
        "        * Use the `search` method of your FAISS index to find the top `k` most similar documents for each query.\n",
        "        * Experiment with different values of `k` (e.g., `k=3`, `k=5`, `k=10`) and observe the results.\n",
        "\n",
        "4.  **Display Results and Analysis:**\n",
        "    * For each query and selected `k` value:\n",
        "        * Print the query.\n",
        "        * Print the distances/similarity scores of the retrieved documents.\n",
        "        * Print the original text content of the retrieved documents (if available from your dataset).\n",
        "    * Qualitatively analyze the retrieved results. Are the top `k` documents relevant to your query? Are there any surprising or irrelevant results? Discuss potential reasons for good/bad retrieval."
      ],
      "metadata": {
        "id": "hfSWHJlu2oIv"
      },
      "id": "hfSWHJlu2oIv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zjg8xA1g2oIw"
      },
      "outputs": [],
      "source": [
        "# Your code for query formulation, embedding generation, similarity search, and result analysis here.\n",
        "# Include your queries, retrieved documents, and qualitative analysis."
      ],
      "id": "zjg8xA1g2oIw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Reflection and Future Work (Bonus - 5 Marks)\n",
        "\n",
        "1.  **Challenges Faced:**\n",
        "    * Describe any challenges you encountered during this assignment and how you overcame them.\n",
        "\n",
        "2.  **Potential Improvements:**\n",
        "    * Suggest ways to improve the embedding store or the similarity search process. Consider:\n",
        "        * Using different Sentence Transformer models.\n",
        "        * Exploring advanced FAISS index types (e.g., `IVFFlat`, `HNSW`) for larger datasets.\n",
        "        * Preprocessing techniques for text data.\n",
        "        * Re-ranking retrieved results.\n",
        "\n",
        "3.  **Learnings:**\n",
        "    * Summarize your key learnings from building this embedding store with FAISS and Sentence Transformers."
      ],
      "metadata": {
        "id": "rNqW-04U2oIw"
      },
      "id": "rNqW-04U2oIw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "* Submit this Jupyter Notebook (.ipynb file) with all cells executed and outputs visible.\n",
        "* Ensure your code is well-commented and easy to understand.\n",
        "* Provide a `requirements.txt` file.\n",
        "* Include a brief `README.md` file (optional but recommended) explaining how to run your code and any specific instructions.\n",
        "* Make sure your notebook runs without errors in the specified environment."
      ],
      "metadata": {
        "id": "HEBwqkax2oIw"
      },
      "id": "HEBwqkax2oIw"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}