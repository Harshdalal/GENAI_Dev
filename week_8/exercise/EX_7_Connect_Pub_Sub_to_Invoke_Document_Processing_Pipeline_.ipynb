{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Connect Pub/Sub to Invoke Document Processing Pipeline\n",
        "\n",
        "\n",
        "## Objective\n",
        "This assignment focuses on building an event-driven document processing pipeline using Google Cloud Pub/Sub. You will learn to publish messages to a Pub/Sub topic and trigger a Cloud Function (or a similar serverless compute service) that simulates a document processing task. This pattern is essential for scalable and decoupled architectures in real-world data pipelines."
      ],
      "metadata": {
        "id": "qcIrZb_-6CHE"
      },
      "id": "qcIrZb_-6CHE"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Google Cloud Project Setup (20 Marks)\n",
        "\n",
        "1.  **GCP Project Setup:**\n",
        "    * Ensure you have an active Google Cloud Platform (GCP) project. If not, create a new one.\n",
        "    * Make sure billing is enabled for your project.\n",
        "    * Install and configure the `gcloud CLI` on your local machine if you haven't already.\n",
        "    * Show the `gcloud auth login` and `gcloud config set project [YOUR_PROJECT_ID]` commands with successful output.\n",
        "\n",
        "2.  **Enable APIs:**\n",
        "    * Enable the following APIs in your GCP project:\n",
        "        * Cloud Pub/Sub API\n",
        "        * Cloud Functions API\n",
        "        * Cloud Build API (for deploying Cloud Functions)\n",
        "        * Cloud Logging API\n",
        "    * Provide `gcloud services enable` commands for each required API."
      ],
      "metadata": {
        "id": "pOwj2d8I6CHF"
      },
      "id": "pOwj2d8I6CHF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2yfYPAQi6CHG"
      },
      "outputs": [],
      "source": [
        "# Your GCP CLI commands for project setup and API enablement here.\n",
        "# Provide screenshots or text output confirming successful API enablement."
      ],
      "id": "2yfYPAQi6CHG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Pub/Sub Topic and Publisher (30 Marks)\n",
        "\n",
        "1.  **Create a Pub/Sub Topic:**\n",
        "    * Create a new Pub/Sub topic. Name it meaningfully (e.g., `document-processing-requests`).\n",
        "    * Use the `gcloud pubsub topics create` command.\n",
        "    * Provide the command and confirm its successful creation.\n",
        "\n",
        "2.  **Develop a Python Publisher Script:**\n",
        "    * Write a Python script (`publisher.py`) that:\n",
        "        * Imports the `google.cloud.pubsub_v1` library.\n",
        "        * Initializes a Pub/Sub Publisher client.\n",
        "        * Publishes at least **3 distinct messages** to your created topic.\n",
        "        * Each message should simulate a document processing request. For example, it could be a JSON string containing a `document_id` and a `file_path` (e.g., `gs://my-bucket/documents/doc1.pdf`).\n",
        "        * Ensure to encode the message data to bytes.\n",
        "        * Include error handling for publishing messages.\n",
        "    * Provide the full Python code for `publisher.py`.\n",
        "\n",
        "3.  **Run the Publisher and Verify (via Console):**\n",
        "    * Run your `publisher.py` script locally.\n",
        "    * Go to the Pub/Sub topic in the GCP Console.\n",
        "    * Check the \"Messages\" tab (or create a temporary subscription to pull messages) to verify that your messages were published successfully.\n",
        "    * Provide a screenshot of the Pub/Sub console showing published messages or pull results."
      ],
      "metadata": {
        "id": "nTOX8MHu6CHG"
      },
      "id": "nTOX8MHu6CHG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQOAo6Xk6CHG"
      },
      "outputs": [],
      "source": [
        "# Your gcloud command for creating the Pub/Sub topic.\n",
        "# Full Python code for `publisher.py`.\n",
        "# Screenshot of GCP Console verifying published messages."
      ],
      "id": "UQOAo6Xk6CHG"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Cloud Function for Document Processing (40 Marks)\n",
        "\n",
        "1.  **Create Cloud Function Code:**\n",
        "    * Create a new directory (e.g., `document_processor_function`).\n",
        "    * Inside this directory, create two files:\n",
        "        * `main.py`: Contains your Cloud Function logic.\n",
        "        * `requirements.txt`: Lists any Python dependencies for your function (e.g., `functions-framework`).\n",
        "    * In `main.py`, write a Python function that:\n",
        "        * Is triggered by a Pub/Sub message.\n",
        "        * Takes `event` and `context` arguments (standard for Pub/Sub triggered Cloud Functions).\n",
        "        * Decodes the incoming Pub/Sub message data.\n",
        "        * Parses the `document_id` and `file_path` from the message.\n",
        "        * Simulates a document processing task (e.g., print a message like \"Processing document [ID] from [Path]\", simulate a delay with `time.sleep()`, or perform a simple string manipulation).\n",
        "        * Logs the received data and the simulated processing steps to standard output (which Cloud Logging will capture).\n",
        "    * Provide the full Python code for `main.py` and `requirements.txt`.\n",
        "\n",
        "2.  **Deploy the Cloud Function:**\n",
        "    * Deploy your Cloud Function using the `gcloud functions deploy` command.\n",
        "    * Configure it to be triggered by your Pub/Sub topic.\n",
        "    * Specify a runtime (e.g., `python39` or `python310`).\n",
        "    * Allow unauthenticated invocations (if setting up for testing, though Pub/Sub triggers are usually authenticated).\n",
        "    * Show the `gcloud functions deploy` command and its successful output.\n",
        "\n",
        "3.  **Test the Pipeline:**\n",
        "    * Re-run your `publisher.py` script to send new messages to the Pub/Sub topic.\n",
        "    * Go to the Cloud Functions console, navigate to your deployed function.\n",
        "    * Check the \"Logs\" tab of your Cloud Function to verify that it was triggered and processed the messages successfully.\n",
        "    * Provide a screenshot of the Cloud Function logs showing the processing of your messages.\n",
        "\n",
        "4.  **Error Handling (Bonus - 5 Marks):**\n",
        "    * Modify your Cloud Function to handle potential errors in message parsing or processing (e.g., `try-except` blocks).\n",
        "    * Demonstrate triggering an error (e.g., by sending a malformed message) and show how it appears in the Cloud Function logs."
      ],
      "metadata": {
        "id": "hg8T9z306CHH"
      },
      "id": "hg8T9z306CHH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RbqLZwr_6CHH"
      },
      "outputs": [],
      "source": [
        "# Full Python code for Cloud Function `main.py` and `requirements.txt`.\n",
        "# gcloud command for deploying the Cloud Function.\n",
        "# Screenshot of Cloud Function logs showing successful processing (and error handling if bonus applied)."
      ],
      "id": "RbqLZwr_6CHH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Reflection and Clean-up (10 Marks)\n",
        "\n",
        "1.  **Benefits of Event-Driven Architecture:**\n",
        "    * Discuss the advantages of using Pub/Sub for invoking a document processing pipeline (e.g., decoupling, scalability, reliability, asynchronous processing).\n",
        "    * How does this pattern help in building robust data pipelines?\n",
        "\n",
        "2.  **Challenges Faced:**\n",
        "    * Describe any challenges you encountered during this assignment (e.g., IAM permissions, message encoding/decoding, debugging Cloud Functions) and how you resolved them.\n",
        "\n",
        "3.  **Clean Up Resources:**\n",
        "    * After completing the assignment, delete the Pub/Sub topic and the Cloud Function to avoid incurring unnecessary costs.\n",
        "    * Provide the `gcloud pubsub topics delete` and `gcloud functions delete` commands."
      ],
      "metadata": {
        "id": "PJdQao_D6CHH"
      },
      "id": "PJdQao_D6CHH"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "* Submit this Jupyter Notebook (.ipynb file) with all cells executed and outputs visible.\n",
        "* Include all necessary Python files (`publisher.py`, `document_processor_function/main.py`, `document_processor_function/requirements.txt`).\n",
        "* Provide `requirements.txt` files for both your local environment and the Cloud Function.\n",
        "* Ensure your code is well-commented and easy to understand.\n",
        "* All `gcloud` commands and screenshots should be clearly presented as requested.\n",
        "* Make sure your pipeline is functional and demonstrable."
      ],
      "metadata": {
        "id": "1KjY5CAb6CHI"
      },
      "id": "1KjY5CAb6CHI"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}