{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Log GPU Usage and Model Performance for Tuning\n",
        "\n",
        "## Objective\n",
        "This assignment focuses on instrumenting a machine learning training process to monitor and log GPU resource utilization (memory, compute) alongside traditional model performance metrics. This is crucial for optimizing model training, especially for large models or when working with limited hardware resources, enabling efficient hyperparameter tuning."
      ],
      "metadata": {
        "id": "u-sg-IRCD0oc"
      },
      "id": "u-sg-IRCD0oc"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Environment Setup and Basic Model Training (30 Marks)\n",
        "\n",
        "1.  **Environment Setup:**\n",
        "    * Create a new Python virtual environment.\n",
        "    * Install necessary libraries: `torch` (or `tensorflow`), `torchvision` (for common datasets), `scikit-learn`, `pandas`, `numpy`, `matplotlib`, `psutil` (for CPU/RAM), `pynvml` (for NVIDIA GPU metrics, if available), `GPUtil` (alternative/additional GPU library), `tqdm` (for progress bars), `csv` (for logging).\n",
        "        * Provide a `requirements.txt` file.\n",
        "    * **Important:** This assignment highly benefits from a GPU. If you don't have one, specify that you'll focus on CPU usage logging and theoretical GPU considerations.\n",
        "\n",
        "2.  **Dataset and DataLoader:**\n",
        "    * Load a common image classification dataset (e.g., CIFAR-10, FashionMNIST) using `torchvision.datasets`.\n",
        "    * Create `DataLoader` instances for training and validation sets.\n",
        "    * Print dataset sizes and batch sizes.\n",
        "\n",
        "3.  **Simple Neural Network Model:**\n",
        "    * Define a simple Convolutional Neural Network (CNN) using `torch.nn.Module` (or `tf.keras.Model`).\n",
        "        * It should have at least 2-3 convolutional layers and 1-2 fully connected layers.\n",
        "    * Move the model to the appropriate device (GPU if available, else CPU).\n",
        "    * Print the model summary (if using PyTorch, maybe use `torchsummary` if installed, or just print the model structure).\n",
        "\n",
        "4.  **Basic Training Loop:**\n",
        "    * Implement a standard training loop (e.g., 5-10 epochs) that:\n",
        "        * Iterates through batches.\n",
        "        * Performs forward pass, loss calculation, backward pass, and optimizer step.\n",
        "        * Calculates and prints epoch-level training loss and validation accuracy at the end of each epoch.\n",
        "    * Use a standard loss function (e.g., `CrossEntropyLoss`) and optimizer (e.g., `Adam`).\n",
        "    * Demonstrate that your model can train and show its basic performance."
      ],
      "metadata": {
        "id": "sPmKIC3VD0od"
      },
      "id": "sPmKIC3VD0od"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uilIX0P8D0oe"
      },
      "outputs": [],
      "source": [
        "# Your code for environment setup, dataset/dataloader, model definition, and basic training loop.\n",
        "# Provide `requirements.txt`.\n",
        "# Confirm GPU availability (or note CPU-only).\n",
        "# Show sample training output (losses, accuracies)."
      ],
      "id": "uilIX0P8D0oe"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: GPU/CPU Usage Logging (40 Marks)\n",
        "\n",
        "1.  **Resource Monitor Class/Function:**\n",
        "    * Create a Python class or a set of functions (e.g., `ResourceMonitor`) that can:\n",
        "        * **For GPU (if available):**\n",
        "            * Initialize `pynvml` (or `GPUtil`).\n",
        "            * Periodically (e.g., every few seconds or every N batches) query and record:\n",
        "                * GPU utilization (e.g., `utilization.gpu` from `pynvml`).\n",
        "                * GPU memory usage (e.g., `memory.used` from `pynvml`).\n",
        "            * Handle cases where `pynvml` is not installed or no NVIDIA GPU is found gracefully (e.g., print a warning and skip GPU logging).\n",
        "        * **For CPU/RAM (always):**\n",
        "            * Use `psutil` to query and record:\n",
        "                * CPU utilization (`psutil.cpu_percent`).\n",
        "                * System RAM usage (`psutil.virtual_memory().percent`).\n",
        "\n",
        "2.  **Integrate Monitoring into Training Loop:**\n",
        "    * Modify your training loop from Part 1 to integrate the `ResourceMonitor`.\n",
        "    * The monitor should:\n",
        "        * Start before training begins.\n",
        "        * Log resource usage at regular intervals (e.g., every 10-50 batches, or at fixed time intervals).\n",
        "        * Stop monitoring after training completes.\n",
        "    * Store the collected resource data (e.g., timestamps, GPU/CPU usage, memory) in a list of dictionaries.\n",
        "\n",
        "3.  **Save Logs to CSV:**\n",
        "    * After training, save the collected resource usage data to a CSV file (e.g., `resource_logs.csv`).\n",
        "    * The CSV should have columns for `timestamp`, `epoch`, `batch`, `gpu_util_percent`, `gpu_mem_used_mb`, `cpu_util_percent`, `ram_util_percent` (and `N/A` for GPU fields if no GPU).\n",
        "\n",
        "4.  **Visualize Resource Usage:**\n",
        "    * Load the `resource_logs.csv` into a Pandas DataFrame.\n",
        "    * Create at least **two plots** using `matplotlib` or `seaborn`:\n",
        "        * Plot of GPU/CPU Utilization (%) over time/batches during training.\n",
        "        * Plot of GPU/RAM Memory Usage (MB or %) over time/batches during training.\n",
        "    * Analyze the plots: Do you see expected patterns (e.g., high GPU usage during forward/backward pass, memory increasing)? Are there any bottlenecks?"
      ],
      "metadata": {
        "id": "TDPwkyfHD0of"
      },
      "id": "TDPwkyfHD0of"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X7GoJoaWD0of"
      },
      "outputs": [],
      "source": [
        "# Your Python code for `ResourceMonitor` class/functions and its integration into the training loop.\n",
        "# Code for saving logs to CSV and plotting.\n",
        "# Include the generated plots and your analysis."
      ],
      "id": "X7GoJoaWD0of"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Model Performance and Tuning (30 Marks)\n",
        "\n",
        "1.  **Model Complexity Experiment:**\n",
        "    * Create **two distinct configurations** for your neural network model (from Part 1):\n",
        "        * **Configuration A (Simpler):** Fewer layers, fewer channels/neurons.\n",
        "        * **Configuration B (More Complex):** More layers, more channels/neurons.\n",
        "    * For each configuration:\n",
        "        * Train the model for the same number of epochs.\n",
        "        * Log both resource usage (as in Part 2) and epoch-level training/validation metrics (loss, accuracy).\n",
        "        * Save resource logs to separate CSVs (e.g., `resource_logs_A.csv`, `resource_logs_B.csv`).\n",
        "        * Save training/validation metrics to separate JSON or CSV files (e.g., `metrics_A.csv`, `metrics_B.csv`).\n",
        "\n",
        "2.  **Compare Performance & Resource Usage:**\n",
        "    * Load and compare the training/validation metrics of Configuration A vs. Configuration B. Which model performs better on validation accuracy?\n",
        "    * Load and compare the resource usage plots (GPU/CPU/RAM) for Configuration A vs. Configuration B.\n",
        "    * Analyze: How does model complexity impact resource utilization and training time? Is there a trade-off between performance and resource efficiency for your specific task/dataset?\n",
        "\n",
        "3.  **Discussion for Tuning:**\n",
        "    * How can logging GPU/CPU usage guide your hyperparameter tuning efforts (e.g., choosing batch size, model architecture, optimizer)?\n",
        "    * Imagine you have limited GPU memory. How would the logs from this assignment help you identify potential memory bottlenecks and suggest solutions (e.g., gradient accumulation, mixed precision training, model pruning)?\n",
        "    * What other metrics (beyond accuracy/loss) might be valuable to log for a more comprehensive model evaluation (e.g., inference speed, model size)?"
      ],
      "metadata": {
        "id": "rdfiAP2SD0og"
      },
      "id": "rdfiAP2SD0og"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7H4M76iD0og"
      },
      "outputs": [],
      "source": [
        "# Your code for implementing two model configurations and running training for each.\n",
        "# Code for saving metrics and resource logs for both configurations.\n",
        "# Include plots comparing resource usage and model performance.\n",
        "# Your discussion and analysis."
      ],
      "id": "S7H4M76iD0og"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "* Submit this Jupyter Notebook (.ipynb file) with all cells executed and outputs visible.\n",
        "        * Ensure your code is well-commented and easy to understand.\n",
        "* Provide a `requirements.txt` file listing all dependencies.\n",
        "* Include all generated plots and log outputs directly in the notebook.\n",
        "* Clearly explain your observations and analysis for each part.\n",
        "* If you lack a GPU, clearly state this and explain how your approach adapts to CPU-only logging."
      ],
      "metadata": {
        "id": "j9I2_ohHD0og"
      },
      "id": "j9I2_ohHD0og"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}