{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FK0eGwy62zaA"
      },
      "source": [
        "#  Python Assignment: LSTM for Stock Price Prediction\n",
        "\n",
        "This assignment challenges you to build and evaluate a Long Short-Term Memory (LSTM) neural network for time-series forecasting, specifically applied to **stock price prediction**. LSTMs, a type of Recurrent Neural Network (RNN), are well-suited for sequence prediction due to their ability to learn long-term dependencies in data. You will acquire real-world stock data, preprocess it, construct an LSTM model, train it, and assess its forecasting accuracy for future stock prices."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mww_54IG2zaC"
      },
      "source": [
        "## Part 1: Data Acquisition and Preprocessing (35 points)\n",
        "\n",
        "You'll acquire historical stock data, handle potential issues, normalize the data, and transform it into the sequential format required by LSTMs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hNerm6cu2zaC"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "import yfinance as yf # A library to download financial data\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore') # Suppress warnings for cleaner output\n",
        "np.random.seed(42) # for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# 1.1 Acquire Stock Data\n",
        "#    Use the `yfinance` library to download historical stock data for a chosen ticker symbol (e.g., 'AAPL' for Apple, 'GOOG' for Google, 'RELIANCE.NS' for Reliance Industries on NSE).\n",
        "#    Download at least 3-5 years of daily data.\n",
        "#    Focus on the 'Close' price as your target variable.\n",
        "\n",
        "ticker_symbol = 'AAPL' # You can change this to another stock\n",
        "start_date = '2019-01-01'\n",
        "end_date = '2024-12-31'\n",
        "\n",
        "print(f\"\\n--- Acquiring Stock Data for {ticker_symbol} ---\")\n",
        "# TODO: Download stock data using yfinance\n",
        "# stock_data = yf.download(ticker_symbol, start=start_date, end=end_date)\n",
        "\n",
        "# Select the target variable\n",
        "# target_series = stock_data['Close'].copy()\n",
        "\n",
        "print(\"Raw Data Head:\\n\", stock_data.head())\n",
        "print(\"\\nTarget Series Info:\\n\", target_series.info())\n",
        "\n",
        "# 1.2 Handle Missing Values (if any)\n",
        "#    While yfinance usually returns clean data, check for any NaNs and handle them (e.g., with forward fill `ffill()`).\n",
        "\n",
        "print(\"\\n--- Handling Missing Values ---\")\n",
        "# TODO: Fill NaNs if present\n",
        "# target_series_cleaned = target_series.ffill().bfill() # ffill then bfill for leading NaNs\n",
        "print(f\"NaNs after cleaning: {target_series_cleaned.isnull().sum()}\")\n",
        "\n",
        "# 1.3 Data Normalization\n",
        "#    Normalize the `target_series_cleaned` data using `MinMaxScaler` to values between 0 and 1.\n",
        "#    **Store the scaler object**; you'll need it to inverse transform predictions back to the original price scale.\n",
        "\n",
        "print(\"\\n--- Normalizing Data ---\")\n",
        "# TODO: Initialize and fit MinMaxScaler\n",
        "# scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "# scaled_data = scaler.fit_transform(target_series_cleaned.values.reshape(-1, 1))\n",
        "print(f\"Scaled data shape: {scaled_data.shape}\")\n",
        "\n",
        "# 1.4 Create Sequences for LSTM\n",
        "#    Implement a function to create input-output sequences for the LSTM.\n",
        "#    - `n_steps_in`: Number of past daily closing prices to use as input features (e.g., 60 days).\n",
        "#    - `n_steps_out`: Number of future daily closing prices to predict (e.g., 1 for next day).\n",
        "#    The input X should be `(samples, n_steps_in, 1)` and output y should be `(samples, n_steps_out)`.\n",
        "\n",
        "def create_sequences(data, n_steps_in, n_steps_out):\n",
        "    X, y = [], []\n",
        "    for i in range(len(data) - n_steps_in - n_steps_out + 1):\n",
        "        # TODO: Define input sequence (X_seq)\n",
        "        # X_seq = data[i:(i + n_steps_in), 0]\n",
        "        # TODO: Define output sequence (y_seq)\n",
        "        # y_seq = data[(i + n_steps_in):(i + n_steps_in + n_steps_out), 0]\n",
        "\n",
        "        # X.append(X_seq)\n",
        "        # y.append(y_seq)\n",
        "    return np.array(X), np.array(y)\n",
        "\n",
        "n_steps_in = 60 # Use 60 past days to predict\n",
        "n_steps_out = 1 # Predict next 1 day\n",
        "\n",
        "X_seq, y_seq = create_sequences(scaled_data, n_steps_in, n_steps_out)\n",
        "\n",
        "print(f\"Input sequences (X_seq) shape: {X_seq.shape}\")\n",
        "print(f\"Output sequences (y_seq) shape: {y_seq.shape}\")\n",
        "\n",
        "# Reshape X for LSTM input: (samples, timesteps, features)\n",
        "X_seq = X_seq.reshape(X_seq.shape[0], X_seq.shape[1], 1)\n",
        "print(f\"Reshaped X_seq for LSTM: {X_seq.shape}\")\n",
        "\n",
        "# 1.5 Train-Test Split\n",
        "#    Split the sequential data into training and testing sets. **Crucially, maintain temporal order.**\n",
        "#    (e.g., 80% train, 20% test, no shuffling).\n",
        "\n",
        "train_size = int(len(X_seq) * 0.8)\n",
        "X_train, X_test = X_seq[:train_size], X_seq[train_size:]\n",
        "y_train, y_test = y_seq[:train_size], y_seq[train_size:]\n",
        "\n",
        "print(f\"Train set: {X_train.shape}, {y_train.shape}\")\n",
        "print(f\"Test set: {X_test.shape}, {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKrO5RB82zaE"
      },
      "source": [
        "## Part 2: Building the LSTM Model (25 points)\n",
        "\n",
        "You'll design and compile a simple LSTM neural network using Keras."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OrfiAsC42zaE"
      },
      "outputs": [],
      "source": [
        "# 2.1 Define the LSTM Architecture\n",
        "#    Create a `tf.keras.Sequential` model with:\n",
        "#    - One or more `LSTM` layers. The first LSTM layer needs `input_shape=(n_steps_in, 1)`.\n",
        "#      Consider using `return_sequences=True` for stacked LSTMs and `return_sequences=False` for the last LSTM layer before Dense.\n",
        "#    - `Dropout` layers to prevent overfitting (e.g., 0.2-0.3).\n",
        "#    - One or more `Dense` layers, with the final output layer having `n_steps_out` neurons (no activation for regression).\n",
        "\n",
        "print(\"\\n--- Building LSTM Model ---\")\n",
        "# TODO: Build the Sequential LSTM model\n",
        "# model = keras.Sequential([\n",
        "#     layers.LSTM(50, activation='relu', input_shape=(n_steps_in, 1)), # Example: 50 LSTM units\n",
        "#     layers.Dropout(0.2),\n",
        "#     layers.Dense(n_steps_out) # Output layer for n_steps_out predictions\n",
        "# ])\n",
        "\n",
        "# 2.2 Compile the Model\n",
        "#    Configure the model for training:\n",
        "#    - `optimizer`: Choose `'adam'`.\n",
        "#    - `loss`: Use `'mse'` (Mean Squared Error) for regression.\n",
        "#    - `metrics`: Monitor `['mae']` (Mean Absolute Error) for interpretability.\n",
        "\n",
        "# TODO: Compile the model\n",
        "# model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n",
        "\n",
        "# 2.3 Display Model Summary\n",
        "#    Print the model summary to see the layers, output shapes, and parameter counts.\n",
        "\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wj9wG-Ma2zaF"
      },
      "source": [
        "## Part 3: Training and Evaluation (30 points)\n",
        "\n",
        "Train your LSTM model and evaluate its performance on the test set, visualizing the predictions against actual values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aIgF_lvL2zaF"
      },
      "outputs": [],
      "source": [
        "# 3.1 Train the Model\n",
        "#    Use `model.fit()` to train the LSTM.\n",
        "#    - `epochs`: Choose a sufficient number (e.g., 50-100, or more if needed).\n",
        "#    - `batch_size`: Choose a common batch size (e.g., 32, 64).\n",
        "#    - `validation_split`: Use a portion of the training data for validation (e.g., 0.1 or 0.2).\n",
        "#    - (Optional) Add `EarlyStopping` and `ModelCheckpoint` callbacks to prevent overfitting and save the best model.\n",
        "#    Store the returned `history` object.\n",
        "\n",
        "epochs = 50\n",
        "batch_size = 64\n",
        "\n",
        "# Optional Callbacks\n",
        "# early_stopping = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
        "# model_checkpoint = keras.callbacks.ModelCheckpoint('best_lstm_model.h5', monitor='val_loss', save_best_only=True)\n",
        "\n",
        "print(f\"\\n--- Training LSTM Model for {epochs} epochs with batch size {batch_size} ---\")\n",
        "# TODO: Train the model\n",
        "# history = model.fit(X_train, y_train,\n",
        "#                     epochs=epochs,\n",
        "#                     batch_size=batch_size,\n",
        "#                     validation_split=0.1, # Using a split from training data for simplicity\n",
        "#                     # callbacks=[early_stopping, model_checkpoint], # Uncomment if using callbacks\n",
        "#                     verbose=1)\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 3.2 Plot Training History\n",
        "#    Plot the training and validation loss (MSE) and MAE over epochs.\n",
        "\n",
        "history_dict = history.history\n",
        "loss_values = history_dict['loss']\n",
        "val_loss_values = history_dict['val_loss']\n",
        "mae_values = history_dict['mae']\n",
        "val_mae_values = history_dict['val_mae']\n",
        "\n",
        "epochs_trained = len(loss_values)\n",
        "epochs_range = range(1, epochs_trained + 1)\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "# TODO: Plot training and validation loss\n",
        "# plt.plot(epochs_range, loss_values, 'bo', label='Training Loss (MSE)')\n",
        "# plt.plot(epochs_range, val_loss_values, 'b', label='Validation Loss (MSE)')\n",
        "# plt.title('Training and Validation Loss')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('Loss')\n",
        "# plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "# TODO: Plot training and validation MAE\n",
        "# plt.plot(epochs_range, mae_values, 'bo', label='Training MAE')\n",
        "# plt.plot(epochs_range, val_mae_values, 'b', label='Validation MAE')\n",
        "# plt.title('Training and Validation MAE')\n",
        "# plt.xlabel('Epochs')\n",
        "# plt.ylabel('MAE')\n",
        "# plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 3.3 Evaluate on Test Data\n",
        "#    Use `model.evaluate()` on your `X_test` and `y_test`.\n",
        "\n",
        "print(\"\\n--- Evaluating Model on Test Data ---\")\n",
        "# TODO: Evaluate the model\n",
        "# test_loss, test_mae = model.evaluate(X_test, y_test, verbose=2)\n",
        "\n",
        "print(f\"Test Loss (MSE): {test_loss:.4f}\")\n",
        "print(f\"Test MAE: {test_mae:.4f}\")\n",
        "\n",
        "# 3.4 Make Predictions and Inverse Transform\n",
        "#    Generate predictions on the `X_test` set.\n",
        "#    Inverse transform both the predictions and the actual `y_test` back to their original scale using your `scaler`.\n",
        "\n",
        "print(\"\\n--- Making Predictions and Inverse Transforming ---\")\n",
        "# TODO: Make predictions\n",
        "# y_pred_scaled = model.predict(X_test)\n",
        "\n",
        "# TODO: Inverse transform predictions and actuals\n",
        "# y_pred = scaler.inverse_transform(y_pred_scaled)\n",
        "# y_actual = scaler.inverse_transform(y_test)\n",
        "\n",
        "# 3.5 Visualize Actual vs. Predicted Values\n",
        "#    Plot a segment of the actual stock prices from the test set against the model's predictions.\n",
        "#    (e.g., the last 100-200 predictions for clarity).\n",
        "\n",
        "plot_start_idx = len(y_actual) - 200 # Adjust to visualize a clear segment, e.g., last 200 days\n",
        "plot_end_idx = len(y_actual)\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "# TODO: Plot actuals and predictions\n",
        "# plt.plot(y_actual[plot_start_idx:plot_end_idx], label='Actual Stock Price', color='blue')\n",
        "# plt.plot(y_pred[plot_start_idx:plot_end_idx], label='Predicted Stock Price', color='red', linestyle='--')\n",
        "# plt.title(f'Actual vs. Predicted Stock Price for {ticker_symbol} (Test Set)')\n",
        "# plt.xlabel('Time Step (Days)')\n",
        "# plt.ylabel('Stock Price ($)')\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "# 3.6 Calculate RMSE and MAE on Original Scale\n",
        "#    Compute RMSE and MAE using the inverse-transformed actuals and predictions to get interpretable errors in currency units.\n",
        "\n",
        "rmse_orig_scale = np.sqrt(mean_squared_error(y_actual, y_pred))\n",
        "mae_orig_scale = mean_absolute_error(y_actual, y_pred)\n",
        "\n",
        "print(f\"\\nRMSE on original scale: {rmse_orig_scale:.4f} \") # Currency unit (e.g., USD, INR)\n",
        "print(f\"MAE on original scale: {mae_orig_scale:.4f} \")   # Currency unit (e.g., USD, INR)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FPYmlaWq2zaG"
      },
      "source": [
        "## Part 4: Reflection and Further Exploration (10 points)\n",
        "\n",
        "Answer the following questions based on your understanding and observations from this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxzgI2ip2zaG"
      },
      "source": [
        "### Your Answers to Reflection Questions:\n",
        "\n",
        "1.  **Explain why stock price prediction is considered a particularly challenging time-series forecasting problem.** What factors make it harder than, say, predicting power consumption or temperature?\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "2.  **What is the significance of maintaining temporal order when splitting time-series data into training and test sets? Why can't you just use `train_test_split` with `shuffle=True`?**\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "3.  **How would you justify your choice of `n_steps_in` for stock price prediction? What are the trade-offs of using a very short vs. a very long input sequence length?**\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "4.  **Suggest two ways to potentially improve the performance of this LSTM model for stock price prediction.** Consider additional data sources (beyond just 'Close' price) or different model complexities.\n",
        "\n",
        "    * **Improvement Idea 1:** _(Name and brief explanation)_\n",
        "    * **Improvement Idea 2:** _(Name and brief explanation)_\n",
        "\n",
        "5.  **In a real-world financial context, what are the ethical considerations or risks of relying solely on an LSTM model for making trading decisions?**\n",
        "\n",
        "    _(Your answer here)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBzbqscl2zaH"
      },
      "source": [
        "## Deliverables:\n",
        "\n",
        "1.  This completed Jupyter Notebook (`lstm_stock_prediction_assignment.ipynb`) with all code cells executed and reflection questions answered.\n",
        "2.  Ensure all plots are clearly visible and well-labeled within the notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}