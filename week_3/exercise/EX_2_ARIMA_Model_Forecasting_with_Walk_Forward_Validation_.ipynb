{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GYeIn1MwjHp"
      },
      "source": [
        "# Python Assignment: ARIMA Model Forecasting with Walk-Forward Validation\n",
        "\n",
        "This assignment delves into advanced time series forecasting by combining the robust ARIMA (AutoRegressive Integrated Moving Average) model with the critical evaluation technique of walk-forward validation. You will prepare time series data, select appropriate ARIMA orders, implement a walk-forward forecasting loop, and thoroughly evaluate your model's real-world performance. This approach is essential for building reliable forecasting systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMWBXNtZwjHr"
      },
      "source": [
        "## Part 1: Data Preparation and Exploratory Analysis (30 points)\n",
        "\n",
        "You will start by loading or generating a suitable time series dataset and conducting initial exploratory analysis, including checking for stationarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdQGhM6YwjHs"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.stattools import adfuller\n",
        "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") # Suppress warnings for cleaner output\n",
        "np.random.seed(42) # for reproducibility\n",
        "\n",
        "# 1.1 Load/Generate Time Series Data\n",
        "#    Load a real-world time series dataset (e.g., from `statsmodels.datasets` or Kaggle).\n",
        "#    *Recommendation: Use `statsmodels.datasets.co2.load().data` or `statsmodels.datasets.airquality.load().data` after some cleaning.*\n",
        "#    Alternatively, generate a synthetic one with trend and seasonality.\n",
        "#    Ensure your data is a Pandas Series with a DatetimeIndex.\n",
        "#    Select a single column if loading a DataFrame with multiple.\n",
        "\n",
        "# Example for CO2 data (uncomment and use if you prefer this)\n",
        "try:\n",
        "    from statsmodels.datasets import co2\n",
        "    data = co2.load().data\n",
        "    ts_data = data.resample('MS').mean().ffill() # Resample to monthly, forward fill missing\n",
        "    ts_data = ts_data['co2'] # Select the 'co2' column\n",
        "    print(\"Loaded CO2 dataset.\")\n",
        "except Exception as e:\n",
        "    print(f\"Could not load CO2 data, generating synthetic data: {e}\")\n",
        "    # Fallback to synthetic data if real data loading fails\n",
        "    n_points = 200 # Roughly 16 years of monthly data\n",
        "    dates = pd.date_range(start='2000-01-01', periods=n_points, freq='MS')\n",
        "\n",
        "    trend = np.linspace(0, 50, n_points) # Increasing trend\n",
        "    seasonality = 10 * np.sin(np.linspace(0, 3 * np.pi, n_points)) # Annual seasonality\n",
        "    noise = np.random.normal(0, 2, n_points)\n",
        "\n",
        "    ts_data = pd.Series(trend + seasonality + noise, index=dates)\n",
        "\n",
        "print(\"Time Series Data Head:\\n\", ts_data.head())\n",
        "print(\"Time Series Data Info:\")\n",
        "ts_data.info()\n",
        "\n",
        "# 1.2 Plot the Raw Time Series\n",
        "#    Visualize the raw time series to observe initial trends, seasonality, and noise.\n",
        "\n",
        "plt.figure(figsize=(15, 6))\n",
        "# TODO: Plot the time series\n",
        "# plt.plot(ts_data)\n",
        "# plt.title(\"Raw Time Series Data\")\n",
        "# plt.xlabel(\"Date\")\n",
        "# plt.ylabel(\"Value\")\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "# 1.3 Check for Stationarity (ADF Test)\n",
        "#    Perform the Augmented Dickey-Fuller (ADF) test on the `ts_data`.\n",
        "#    Interpret the p-value and critical values to determine if the series is stationary.\n",
        "\n",
        "print(\"\\n--- ADF Test on Raw Data ---\")\n",
        "# TODO: Perform ADF test\n",
        "# result = adfuller(ts_data.dropna())\n",
        "# print(f'ADF Statistic: {result[0]:.4f}')\n",
        "# print(f'p-value: {result[1]:.4f}')\n",
        "# print('Critical Values:')\n",
        "# for key, value in result[4].items():\n",
        "#     print(f'  {key}: {value:.4f}')\n",
        "# if result[1] <= 0.05:\n",
        "#     print(\"Conclusion: Data is likely stationary (reject H0).\")\n",
        "# else:\n",
        "#     print(\"Conclusion: Data is likely non-stationary (fail to reject H0).\")\n",
        "\n",
        "# 1.4 Differencing for Stationarity (if needed)\n",
        "#    If the ADF test indicates non-stationarity, apply first-order differencing.\n",
        "#    Re-run the ADF test on the differenced series and plot it.\n",
        "#    Keep track of the number of differences (`d` parameter for ARIMA).\n",
        "\n",
        "d_order = 0 # Initialize differencing order\n",
        "stationary_ts = ts_data.copy()\n",
        "\n",
        "if result[1] > 0.05: # If not stationary, apply differencing\n",
        "    print(\"\\n--- Applying First-Order Differencing ---\")\n",
        "    # TODO: Apply differencing\n",
        "    # stationary_ts = ts_data.diff().dropna()\n",
        "    # d_order = 1\n",
        "\n",
        "    plt.figure(figsize=(15, 6))\n",
        "    # TODO: Plot differenced series\n",
        "    # plt.plot(stationary_ts)\n",
        "    # plt.title(\"Differenced Time Series Data (d=1)\")\n",
        "    # plt.xlabel(\"Date\")\n",
        "    # plt.ylabel(\"Differenced Value\")\n",
        "    # plt.grid(True)\n",
        "    # plt.show()\n",
        "\n",
        "    print(\"\\n--- ADF Test on Differenced Data ---\")\n",
        "    # TODO: Re-run ADF test on differenced data\n",
        "    # result_diff = adfuller(stationary_ts)\n",
        "    # print(f'ADF Statistic: {result_diff[0]:.4f}')\n",
        "    # print(f'p-value: {result_diff[1]:.4f}')\n",
        "    # if result_diff[1] <= 0.05:\n",
        "    #     print(\"Conclusion: Data is now likely stationary.\")\n",
        "    # else:\n",
        "    #     print(\"Conclusion: Data still non-stationary, consider more differencing or seasonal differencing.\")\n",
        "\n",
        "print(f\"Selected differencing order (d): {d_order}\")\n",
        "\n",
        "# 1.5 Plot ACF and PACF\n",
        "#    Plot the Autocorrelation Function (ACF) and Partial Autocorrelation Function (PACF) of the *stationary* series.\n",
        "#    These plots will help you determine the `p` (AR order) and `q` (MA order) parameters for ARIMA.\n",
        "\n",
        "plt.figure(figsize=(16, 8))\n",
        "ax1 = plt.subplot(211)\n",
        "# TODO: Plot ACF\n",
        "# plot_acf(stationary_ts, ax=ax1, lags=40, title='Autocorrelation Function (ACF)')\n",
        "ax2 = plt.subplot(212)\n",
        "# TODO: Plot PACF\n",
        "# plot_pacf(stationary_ts, ax=ax2, lags=40, title='Partial Autocorrelation Function (PACF)')\n",
        "# plt.tight_layout()\n",
        "# plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_ULb79iwjHu"
      },
      "source": [
        "## Part 2: ARIMA Model Selection (20 points)\n",
        "\n",
        "Based on the ACF and PACF plots, you'll propose ARIMA orders. For a tougher challenge, you can also explore `pmdarima`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bM_3tamqwjHv"
      },
      "outputs": [],
      "source": [
        "# 2.1 Manual ARIMA Order Selection\n",
        "#    Based on the ACF and PACF plots from Part 1.5, propose values for `p` and `q`.\n",
        "#    Remember:\n",
        "#    - `p`: Lag order of AR part (from PACF, where it cuts off)\n",
        "#    - `q`: Lag order of MA part (from ACF, where it cuts off)\n",
        "#    The `d` order was determined in Part 1.4.\n",
        "\n",
        "p_order = 0 # TODO: Your proposed p value\n",
        "q_order = 0 # TODO: Your proposed q value\n",
        "\n",
        "print(f\"Proposed ARIMA orders: ({p_order}, {d_order}, {q_order})\")\n",
        "\n",
        "### Justification for p and q:\n",
        "*(Write your reasoning here for choosing `p` and `q` based on the ACF/PACF plots. E.g., \"PACF shows a significant spike at lag X and then cuts off, suggesting p=X. ACF tails off, suggesting AR component. ACF shows a significant spike at lag Y and then cuts off, suggesting q=Y. PACF tails off, suggesting MA component.\")*\n",
        "\n",
        "\n",
        "# 2.2 (Optional - Bonus) Auto-ARIMA for Optimal Orders\n",
        "#    Install `pmdarima` (`!pip install pmdarima`).\n",
        "#    Use `pmdarima.auto_arima` to find the optimal ARIMA orders for your `ts_data`.\n",
        "#    Compare these auto-detected orders with your manual selection.\n",
        "\n",
        "try:\n",
        "    from pmdarima import auto_arima\n",
        "    print(\"\\n--- Running Auto-ARIMA (Optional) ---\")\n",
        "    # TODO: Run auto_arima\n",
        "    # auto_model = auto_arima(ts_data, seasonal=False, # Set seasonal=True if you suspect seasonality not handled by differencing\n",
        "    #                       trace=True, error_action='ignore', suppress_warnings=True,\n",
        "    #                       stepwise=True)\n",
        "    # print(\"Auto-ARIMA Best Parameters:\", auto_model.order)\n",
        "    # print(auto_model.summary())\n",
        "except ImportError:\n",
        "    print(\"pmdarima not installed. Skipping Auto-ARIMA.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dk5Ahl1jwjHv"
      },
      "source": [
        "## Part 3: Walk-Forward Validation Implementation (35 points)\n",
        "\n",
        "This is the core of the assignment. You will implement a walk-forward validation scheme to evaluate your ARIMA model's performance on a rolling basis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tKMcqXlpwjHv"
      },
      "outputs": [],
      "source": [
        "# 3.1 Define Walk-Forward Validation Parameters\n",
        "#    - `n_train_initial`: The number of observations in the initial training set.\n",
        "#    - `n_forecast_steps`: The number of steps to forecast in each iteration (typically 1 for true walk-forward).\n",
        "\n",
        "n_train_initial = int(len(ts_data) * 0.7) # Start with 70% of data for initial training\n",
        "n_forecast_steps = 1 # Forecast one step at a time\n",
        "\n",
        "print(f\"Total data points: {len(ts_data)}\")\n",
        "print(f\"Initial training set size: {n_train_initial}\")\n",
        "print(f\"Number of forecast iterations: {len(ts_data) - n_train_initial}\")\n",
        "\n",
        "history = [x for x in ts_data[:n_train_initial]] # Initial training data\n",
        "predictions = list() # To store all 1-step forecasts\n",
        "actuals = list() # To store all actual values corresponding to forecasts\n",
        "\n",
        "print(\"\\n--- Starting Walk-Forward Validation ---\")\n",
        "\n",
        "# 3.2 Implement the Walk-Forward Validation Loop\n",
        "#    Iterate through the remaining data points (the test set).\n",
        "#    In each iteration:\n",
        "#    - Train an ARIMA model using the `history` (current training data) and your chosen `(p, d, q)` orders.\n",
        "#    - Make a 1-step forecast (or `n_forecast_steps`).\n",
        "#    - Store the forecast and the actual value.\n",
        "#    - Append the actual value from the test set to `history` to expand the training window for the next iteration.\n",
        "\n",
        "for t in range(n_train_initial, len(ts_data)):\n",
        "    # TODO: Train ARIMA model\n",
        "    # model = ARIMA(history, order=(p_order, d_order, q_order))\n",
        "    # model_fit = model.fit()\n",
        "\n",
        "    # TODO: Make forecast\n",
        "    # yhat = model_fit.forecast(steps=n_forecast_steps)[0] # Get the first forecast for 1-step\n",
        "    # predictions.append(yhat)\n",
        "\n",
        "    # Get actual value\n",
        "    # obs = ts_data[t]\n",
        "    # actuals.append(obs)\n",
        "\n",
        "    # Add actual observation to history for next iteration\n",
        "    # history.append(obs)\n",
        "\n",
        "    # Print progress (optional)\n",
        "    # if (t - n_train_initial) % 50 == 0 or t == len(ts_data) - 1:\n",
        "    #     print(f'  Iteration {t - n_train_initial + 1}/{len(ts_data) - n_train_initial}: Predicted={yhat:.2f}, Actual={obs:.2f}')\n",
        "\n",
        "print(\"\\nWalk-Forward Validation Complete.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DPsHLqwlwjHw"
      },
      "source": [
        "## Part 4: Evaluation and Visualization (10 points)\n",
        "\n",
        "Visualize the forecasts against actuals and calculate key performance metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IAPSi5PhwjHw"
      },
      "outputs": [],
      "source": [
        "# Convert lists to Pandas Series for easier plotting and indexing\n",
        "forecast_index = ts_data.index[n_train_initial:]\n",
        "predictions_series = pd.Series(predictions, index=forecast_index)\n",
        "actuals_series = pd.Series(actuals, index=forecast_index)\n",
        "\n",
        "# 4.1 Plot Actual vs. Forecasted Values\n",
        "#    Plot the original time series, then overlay the forecasted values and the actual test set values.\n",
        "\n",
        "plt.figure(figsize=(15, 7))\n",
        "# TODO: Plot original data (up to test set start)\n",
        "# plt.plot(ts_data[:n_train_initial], label='Training Data', color='blue')\n",
        "# TODO: Plot actuals from the test set\n",
        "# plt.plot(actuals_series, label='Actual Test Data', color='green')\n",
        "# TODO: Plot predictions from walk-forward validation\n",
        "# plt.plot(predictions_series, label='ARIMA Forecasts (Walk-Forward)', color='red', linestyle='--')\n",
        "\n",
        "# plt.title(\"ARIMA Walk-Forward Forecast vs. Actuals\")\n",
        "# plt.xlabel(\"Date\")\n",
        "# plt.ylabel(\"Value\")\n",
        "# plt.legend()\n",
        "# plt.grid(True)\n",
        "# plt.show()\n",
        "\n",
        "# 4.2 Calculate Performance Metrics\n",
        "#    Calculate Root Mean Squared Error (RMSE) and Mean Absolute Error (MAE) between the actuals and forecasts.\n",
        "#    (Optional: Calculate Mean Absolute Percentage Error (MAPE) if applicable to your data).\n",
        "\n",
        "# TODO: Calculate RMSE\n",
        "rmse = # ...\n",
        "# TODO: Calculate MAE\n",
        "mae = # ...\n",
        "\n",
        "print(f\"\\n--- Forecast Evaluation Metrics ---\")\n",
        "print(f\"RMSE: {rmse:.4f}\")\n",
        "print(f\"MAE: {mae:.4f}\")\n",
        "\n",
        "# Optional: MAPE calculation\n",
        "def mean_absolute_percentage_error(y_true, y_pred):\n",
        "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
        "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
        "\n",
        "# mape = mean_absolute_percentage_error(actuals_series, predictions_series)\n",
        "# print(f\"MAPE: {mape:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3pfNVPqwjHw"
      },
      "source": [
        "## Part 5: Reflection and Advanced Topics (5 points)\n",
        "\n",
        "Reflect on the assignment and consider advanced aspects of time series forecasting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aEfs00yDwjHx"
      },
      "source": [
        "### Your Answers to Reflection Questions:\n",
        "\n",
        "1.  **Explain the primary benefits of using walk-forward validation for time series forecasting compared to a single train-test split.** What are its drawbacks (e.g., computational cost)?\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "2.  **Based on your model's performance, what are some potential next steps you would take to improve the forecasting accuracy?** (Consider different models, feature engineering, etc.)\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "3.  **When might a simple ARIMA model be insufficient for a time series, and what other factors or models would you consider then?** (e.g., multiple seasonalities, exogenous variables, non-linear patterns).\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "4.  **(Bonus for Seasonal Data):** If your data showed strong *seasonal* patterns that weren't fully captured by differencing, how would you extend the ARIMA model (i.e., what type of model and parameters would you look into)?\n",
        "\n",
        "    _(Your answer here)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fACB_-5cwjHx"
      },
      "source": [
        "## Deliverables:\n",
        "\n",
        "1.  This completed Jupyter Notebook (`arima_walk_forward_assignment.ipynb`) with all code cells executed and reflection questions answered.\n",
        "2.  Ensure all plots are clearly visible and well-labeled within the notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}