{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VZDUzgbV4XVS"
      },
      "source": [
        "#  Python Assignment: Serialize and Deploy a Deep Learning Model using `tf.saved_model`\n",
        "\n",
        "This assignment focuses on the crucial steps of serializing (saving) a trained deep learning model using TensorFlow's `tf.saved_model` format and then loading it for deployment. This process is fundamental for moving models from research and development to production environments, enabling efficient inference without needing the original training code. You will train a simple image classifier, save it, inspect the `SavedModel` structure, and finally load it to perform predictions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssvITaSK4XVU"
      },
      "source": [
        "## Part 1: Model Training and Initial Saving (30 points)\n",
        "\n",
        "You'll train a basic image classification model on the Fashion MNIST dataset, which is a common starting point for demonstrating deep learning concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "srGacm_a4XVU"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import shutil # For removing directories\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings('ignore') # Suppress warnings for cleaner output\n",
        "np.random.seed(42) # for reproducibility\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "# Define a path for saving the model later\n",
        "SAVED_MODEL_DIR = 'my_fashion_mnist_model'\n",
        "\n",
        "# 1.1 Load and Preprocess the Fashion MNIST Dataset\n",
        "#    Load the dataset using `tf.keras.datasets.fashion_mnist.load_data()`.\n",
        "#    Normalize the pixel values to be between 0 and 1.\n",
        "#    Reshape the images to include a channel dimension if necessary (e.g., (batch, height, width, 1)).\n",
        "\n",
        "print(\"\\n--- Loading and Preprocessing Fashion MNIST Dataset ---\")\n",
        "# TODO: Load Fashion MNIST data\n",
        "# (X_train_raw, y_train_raw), (X_test_raw, y_test_raw) = keras.datasets.fashion_mnist.load_data()\n",
        "\n",
        "# TODO: Normalize pixel values\n",
        "# X_train_norm = X_train_raw / 255.0\n",
        "# X_test_norm = X_test_raw / 255.0\n",
        "\n",
        "# Reshape for CNN (add channel dimension)\n",
        "# X_train_reshaped = X_train_norm[..., np.newaxis]\n",
        "# X_test_reshaped = X_test_norm[..., np.newaxis]\n",
        "\n",
        "print(f\"Training data shape: {X_train_reshaped.shape}\")\n",
        "print(f\"Test data shape: {X_test_reshaped.shape}\")\n",
        "\n",
        "# Define class names for better visualization\n",
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
        "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\n",
        "\n",
        "# 1.2 Build a Simple Classification Model\n",
        "#    Create a `tf.keras.Sequential` model for image classification.\n",
        "#    - An `InputLayer` or specify `input_shape` in the first layer.\n",
        "#    - At least one `Conv2D` layer with `relu` activation.\n",
        "#    - A `MaxPooling2D` layer.\n",
        "#    - A `Flatten` layer.\n",
        "#    - One `Dense` hidden layer with `relu` activation.\n",
        "#    - An output `Dense` layer with 10 neurons and `softmax` activation.\n",
        "\n",
        "print(\"\\n--- Building Keras Model ---\")\n",
        "# TODO: Build the Sequential model\n",
        "# model = keras.Sequential([\n",
        "#     layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
        "#     layers.MaxPooling2D((2, 2)),\n",
        "#     layers.Flatten(),\n",
        "#     layers.Dense(64, activation='relu'),\n",
        "#     layers.Dense(10, activation='softmax')\n",
        "# ])\n",
        "\n",
        "# 1.3 Compile the Model\n",
        "#    Configure the model with `optimizer='adam'`, `loss='sparse_categorical_crossentropy'`, and `metrics=['accuracy']`.\n",
        "\n",
        "# TODO: Compile the model\n",
        "# model.compile(optimizer='adam',\n",
        "#               loss='sparse_categorical_crossentropy',\n",
        "#               metrics=['accuracy'])\n",
        "\n",
        "model.summary()\n",
        "\n",
        "# 1.4 Train the Model\n",
        "#    Train the model for a few epochs (e.g., 5-10) using `model.fit()`.\n",
        "\n",
        "epochs = 5\n",
        "print(f\"\\n--- Training Model for {epochs} epochs ---\")\n",
        "# TODO: Train the model\n",
        "# history = model.fit(X_train_reshaped, y_train_raw, epochs=epochs, validation_split=0.1, verbose=1)\n",
        "\n",
        "print(\"Training complete.\")\n",
        "\n",
        "# 1.5 Evaluate the Trained Model\n",
        "#    Evaluate the model on the test set.\n",
        "\n",
        "print(\"\\n--- Evaluating Trained Model ---\")\n",
        "# TODO: Evaluate the model\n",
        "# test_loss, test_acc = model.evaluate(X_test_reshaped, y_test_raw, verbose=2)\n",
        "# print(f\"Trained Model Test Accuracy: {test_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Xx7-5gG4XVW"
      },
      "source": [
        "## Part 2: Saving the Model using `tf.saved_model` (25 points)\n",
        "\n",
        "This section focuses on using `tf.saved_model.save()` to export your trained Keras model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpVHg-8H4XVW"
      },
      "outputs": [],
      "source": [
        "# Clean up previous saved model directory if it exists\n",
        "if os.path.exists(SAVED_MODEL_DIR):\n",
        "    shutil.rmtree(SAVED_MODEL_DIR)\n",
        "    print(f\"Cleaned up existing directory: {SAVED_MODEL_DIR}\")\n",
        "\n",
        "# 2.1 Save the Model\n",
        "#    Use `tf.saved_model.save()` to save your trained Keras model to the `SAVED_MODEL_DIR`.\n",
        "#    Specify the model object and the export path.\n",
        "\n",
        "print(f\"\\n--- Saving Model to {SAVED_MODEL_DIR} ---\")\n",
        "# TODO: Save the model\n",
        "# tf.saved_model.save(model, SAVED_MODEL_DIR)\n",
        "\n",
        "print(\"Model saved successfully!\")\n",
        "\n",
        "# 2.2 Inspect the SavedModel Directory Structure\n",
        "#    List the contents of the `SAVED_MODEL_DIR` to understand the standard `SavedModel` format:\n",
        "#    - `saved_model.pb` (or `saved_model.pbtxt`)\n",
        "#    - `variables/` directory\n",
        "#    - `assets/` directory (if any)\n",
        "\n",
        "print(f\"\\n--- Contents of {SAVED_MODEL_DIR} ---\")\n",
        "for root, dirs, files in os.walk(SAVED_MODEL_DIR):\n",
        "    level = root.replace(SAVED_MODEL_DIR, '').count(os.sep)\n",
        "    indent = ' ' * 4 * (level)\n",
        "    print(f'{indent}{os.path.basename(root)}/')\n",
        "    subindent = ' ' * 4 * (level + 1)\n",
        "    for f in files:\n",
        "        print(f'{subindent}{f}')\n",
        "\n",
        "\n",
        "# 2.3 Examine Signatures (Optional but good for understanding deployment)\n",
        "#    Use the `saved_model_cli` tool (via a shell command in Jupyter) to inspect the model's signature definitions.\n",
        "#    This shows how the model expects inputs and what outputs it provides.\n",
        "#    Command example: `!saved_model_cli show --dir {SAVED_MODEL_DIR} --tag_set serve --signature_def serving_default`\n",
        "\n",
        "print(\"\\n--- Inspecting Model Signatures (requires TensorFlow installation) ---\")\n",
        "print(\"Run the following command in a new cell:\")\n",
        "print(f\"!saved_model_cli show --dir {SAVED_MODEL_DIR} --tag_set serve --signature_def serving_default\")\n",
        "\n",
        "# Example of running the command (uncomment to execute)\n",
        "# !saved_model_cli show --dir {SAVED_MODEL_DIR} --tag_set serve --signature_def serving_default\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giFKoiuz4XVX"
      },
      "source": [
        "## Part 3: Loading and Deploying the Model (35 points)\n",
        "\n",
        "Now, you'll load the saved model and use it to make predictions, simulating a deployment scenario."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WfUS8Cp74XVX"
      },
      "outputs": [],
      "source": [
        "# 3.1 Load the SavedModel\n",
        "#    Use `tf.saved_model.load()` to load the model from the `SAVED_MODEL_DIR`.\n",
        "\n",
        "print(\"\\n--- Loading SavedModel ---\")\n",
        "# TODO: Load the model\n",
        "# loaded_model = tf.saved_model.load(SAVED_MODEL_DIR)\n",
        "print(\"Model loaded successfully!\")\n",
        "\n",
        "# 3.2 Verify Loaded Model Type and Input Signature\n",
        "#    Check the type of the loaded object. It's typically a `tf.function` or `tf.Module`.\n",
        "#    Access its default serving signature to confirm input/output names.\n",
        "\n",
        "print(f\"\\nType of loaded_model: {type(loaded_model)}\")\n",
        "# print(\"Loaded model serving signature:\\n\", loaded_model.signatures['serving_default'])\n",
        "\n",
        "# 3.3 Prepare Sample Data for Prediction\n",
        "#    Take a few samples from the *test set* of the original Fashion MNIST data.\n",
        "#    Remember to preprocess them in the exact same way as the training data (normalize and reshape).\n",
        "\n",
        "print(\"\\n--- Preparing Sample Data for Prediction ---\")\n",
        "num_samples = 5\n",
        "sample_images = X_test_reshaped[:num_samples]\n",
        "sample_labels = y_test_raw[:num_samples]\n",
        "\n",
        "print(f\"Sample images shape: {sample_images.shape}\")\n",
        "print(f\"Sample true labels: {sample_labels}\")\n",
        "\n",
        "# 3.4 Make Predictions using the Loaded Model\n",
        "#    Call the `serving_default` signature of the `loaded_model` to make predictions.\n",
        "#    The input should be a dictionary matching the signature's input name.\n",
        "\n",
        "print(\"\\n--- Making Predictions with Loaded Model ---\")\n",
        "# TODO: Make predictions using the loaded model's serving_default signature\n",
        "# predictions_logits = loaded_model.signatures['serving_default'](tf.constant(sample_images, dtype=tf.float32))\n",
        "# # The output might be a dictionary if multiple outputs are defined, e.g., {'dense_1': <tf.Tensor>}\n",
        "# predictions_probs = tf.nn.softmax(predictions_logits['dense_1']).numpy() # Adjust key based on signature\n",
        "# predicted_classes = np.argmax(predictions_probs, axis=1)\n",
        "\n",
        "print(f\"Predicted probabilities for first sample: {predictions_probs[0]}\")\n",
        "print(f\"Predicted classes: {predicted_classes}\")\n",
        "\n",
        "# 3.5 Visualize Predictions\n",
        "#    Plot the sample images and display their true labels and the predicted labels.\n",
        "#    Highlight correct/incorrect predictions.\n",
        "\n",
        "plt.figure(figsize=(12, 6))\n",
        "for i in range(num_samples):\n",
        "    plt.subplot(1, num_samples, i + 1)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.grid(False)\n",
        "    plt.imshow(X_test_raw[i], cmap=plt.cm.binary)\n",
        "\n",
        "    true_label = class_names[sample_labels[i]]\n",
        "    pred_label = class_names[predicted_classes[i]]\n",
        "\n",
        "    color = 'green' if predicted_classes[i] == sample_labels[i] else 'red'\n",
        "    plt.xlabel(f\"True: {true_label}\\nPred: {pred_label}\", color=color)\n",
        "plt.suptitle(\"Loaded Model Predictions (Green=Correct, Red=Incorrect)\")\n",
        "plt.tight_layout(rect=[0, 0.03, 1, 0.9])\n",
        "plt.show()\n",
        "\n",
        "# 3.6 Evaluate Loaded Model (Optional - to confirm consistency)\n",
        "#    Run the same evaluation on the full test set using the `loaded_model` (via its serving signature).\n",
        "#    Compare its accuracy to the evaluation of the original trained model.\n",
        "\n",
        "print(\"\\n--- Evaluating Loaded Model on Full Test Set ---\")\n",
        "# It's a bit more involved to evaluate a loaded `tf.function` directly like `model.evaluate()`\n",
        "# A common approach is to manually calculate metrics or convert back to Keras model.\n",
        "# For simplicity, we can do predictions on a batch and check accuracy.\n",
        "\n",
        "# To properly evaluate, you'd typically:\n",
        "# 1. Iterate through test batches\n",
        "# 2. Call `loaded_model.signatures['serving_default'](batch_input)`\n",
        "# 3. Calculate metrics based on the output\n",
        "\n",
        "print(\"\\nNote: Full evaluation of loaded `tf.function` requires manual loop or re-wrapping.\")\n",
        "print(\"The initial evaluation (Part 1.5) serves as the primary metric for training success.\")\n",
        "print(\"This section primarily validates the loading and inference process.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R4zA2m3A4XVY"
      },
      "source": [
        "## Part 4: Reflection and Further Exploration (10 points)\n",
        "\n",
        "Answer the following questions based on your understanding and experience in this assignment."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j32aTv914XVY"
      },
      "source": [
        "### Your Answers to Reflection Questions:\n",
        "\n",
        "1.  **What is the primary advantage of saving a TensorFlow model in the `tf.saved_model` format compared to saving just the model weights (e.g., as a `.h5` file)?**\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "2.  **Describe the role of the `saved_model.pb` file and the `variables/` directory within the `SavedModel` format. What information does each contain?**\n",
        "\n",
        "    * **`saved_model.pb`:** _(Your answer here)_\n",
        "    * **`variables/`:** _(Your answer here)_\n",
        "\n",
        "3.  **When you load a `SavedModel` using `tf.saved_model.load()`, what kind of object is typically returned? How does this object allow you to perform inference, and what are its key components (e.g., `signatures`)?**\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "4.  **Imagine you're deploying this model to a cloud service (e.g., TensorFlow Serving, Google Cloud AI Platform). Why is the `SavedModel` format the preferred way to deploy, and what benefits does it offer in such an environment?**\n",
        "\n",
        "    _(Your answer here)_\n",
        "\n",
        "5.  **What are 'signatures' in the context of `SavedModel`, and why are they important for deployment?**\n",
        "\n",
        "    _(Your answer here)_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irTNiBKH4XVd"
      },
      "source": [
        "## Deliverables:\n",
        "\n",
        "1.  This completed Jupyter Notebook (`saved_model_deployment_assignment.ipynb`) with all code cells executed and reflection questions answered.\n",
        "2.  The `my_fashion_mnist_model/` directory containing your saved model (ensure it's created and present after running the notebook).\n",
        "3.  Ensure all plots are clearly visible and well-labeled within the notebook."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}