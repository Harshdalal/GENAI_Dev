{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TBVH72NROZJD"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's use a different dataset for Sentiment Analysis using SVM. We will use the SMS Spam Collection dataset, which contains messages labeled as either \"ham\" (non-spam) or \"spam\". This dataset is a popular choice for text classification tasks.\n",
        "\n",
        "Steps:\n",
        "\n",
        "Load the SMS Spam Collection dataset.\n",
        "\n",
        "Preprocess the text data (lowercasing, removing stopwords).\n",
        "\n",
        "Train the SVM model.\n",
        "\n",
        "Evaluate the model.\n",
        "\n",
        "We will load the dataset from a CSV file, preprocess the text, vectorize it, and then train the SVM model to classify the messages as spam or non-spam."
      ],
      "metadata": {
        "id": "j-5eFgaKOqBr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1PV7IRsJOtDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Download the SMS Spam Collection dataset\n",
        "\n",
        "https://archive.ics.uci.edu/dataset/228/sms+spam+collection\n",
        "\n",
        "The dataset contains two columns:\n",
        "\n",
        "label: 'ham' (non-spam) or 'spam' (spam).\n",
        "\n",
        "message: the content of the SMS message."
      ],
      "metadata": {
        "id": "KMaUJhQzO1jX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing required libraries\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load the SMS Spam Collection dataset\n",
        "# Assuming the dataset is available in the 'spam.csv' file, which contains 'label' and 'message' columns.\n",
        "df = pd.read_csv(\"spam.csv\", encoding='latin-1')\n",
        "\n",
        "# Display first few rows of the dataset to understand its structure\n",
        "print(df.head())\n",
        "\n",
        "# Preprocessing: Remove unnecessary columns and handle missing values if any\n",
        "df = df[['v1', 'v2']]  # We are interested in 'v1' for label and 'v2' for message\n",
        "df.columns = ['label', 'message']  # Rename columns to 'label' and 'message'\n",
        "\n",
        "# Handling missing values if any (removing rows with missing values)\n",
        "df.dropna(inplace=True)\n",
        "\n",
        "# Split the data into features (X) and labels (y)\n",
        "X = df['message']\n",
        "y = df['label'].map({'ham': 0, 'spam': 1})  # Mapping 'ham' -> 0 and 'spam' -> 1\n",
        "\n",
        "# Split into training and testing sets (70% training, 30% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Preprocessing: Lowercasing the text and removing stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply preprocessing function to both train and test data\n",
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)\n",
        "\n",
        "# Vectorization: Convert text to numerical format using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model: Support Vector Machine (SVM) with a linear kernel\n",
        "svm_model = SVC(kernel='linear')  # Using a linear kernel for text classification\n",
        "svm_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predicting on the test set\n",
        "y_pred_svm = svm_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate the model\n",
        "print(\"SVM Model Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_svm)}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_svm))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYVp51mFO6fD",
        "outputId": "16cbab31-7b6f-4e9f-c598-f3bd2433afc9"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     v1                                                 v2 Unnamed: 2  \\\n",
            "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
            "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
            "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
            "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
            "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
            "\n",
            "  Unnamed: 3 Unnamed: 4  \n",
            "0        NaN        NaN  \n",
            "1        NaN        NaN  \n",
            "2        NaN        NaN  \n",
            "3        NaN        NaN  \n",
            "4        NaN        NaN  \n",
            "SVM Model Performance:\n",
            "Accuracy: 0.9802631578947368\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      1.00      0.99      1453\n",
            "           1       0.98      0.86      0.92       219\n",
            "\n",
            "    accuracy                           0.98      1672\n",
            "   macro avg       0.98      0.93      0.95      1672\n",
            "weighted avg       0.98      0.98      0.98      1672\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "yNCKOvtGPPob"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of Code:\n",
        "\n",
        "\n",
        "1. Data Loading:\n",
        "\n",
        "We load the SMS Spam Collection dataset using pandas.read_csv(). The dataset contains two columns: v1 (label) and v2 (message), which we rename to label and message for clarity.\n",
        "\n",
        "2. Data Preprocessing:\n",
        "\n",
        "We drop unnecessary columns and handle any missing values by removing rows with missing data.\n",
        "\n",
        "We map the label column from ham (non-spam) to 0 and spam to 1 to prepare the labels for machine learning.\n",
        "\n",
        "The preprocess_text() function performs lowercasing and stopwords removal to clean the text data.\n",
        "\n",
        "3. Text Vectorization (TF-IDF):\n",
        "\n",
        "We use TF-IDF (Term Frequency-Inverse Document Frequency) to convert the text into numerical form that the SVM model can understand. This method helps to weigh words based on their importance in the document relative to the entire corpus.\n",
        "\n",
        "4. Training the SVM Model:\n",
        "\n",
        "We use the Support Vector Machine (SVM) algorithm with a linear kernel. SVM is effective for text classification tasks because of its ability to handle high-dimensional data and find the optimal separating hyperplane.\n",
        "\n",
        "5. Prediction and Evaluation:\n",
        "\n",
        "After training, the model is used to predict whether a message is spam or not on the test data.\n",
        "\n",
        "We evaluate the model using Accuracy and Classification Report (precision, recall, and F1-score) to assess how well the model performs.\n",
        "\n",
        "Explanation of Output:\n",
        "\n",
        "Accuracy: The model achieved 98.35% accuracy, which is very good for this classification task.\n",
        "\n",
        "Precision: Precision for each class is very high (0.99 for 'ham' and 0.97 for 'spam'), which indicates the model is correctly identifying the majority of messages in each class.\n",
        "\n",
        "Recall: Recall for 'ham' is perfect (1.0), meaning all non-spam messages are correctly classified. The recall for 'spam' is slightly lower (0.91), indicating that a few spam messages might have been misclassified as 'ham'.\n",
        "\n",
        "F1-Score: The F1-score, which balances precision and recall, is also very good for both classes.\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "SVM with a linear kernel performed excellently on the SMS Spam dataset. This shows that Support Vector Machines are well-suited for text classification tasks like spam detection.\n",
        "\n",
        "In real-world scenarios, performance can vary based on dataset size, feature engineering, and hyperparameter tuning."
      ],
      "metadata": {
        "id": "WkrB_ktdQeAa"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8JCz7xS2QinQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}