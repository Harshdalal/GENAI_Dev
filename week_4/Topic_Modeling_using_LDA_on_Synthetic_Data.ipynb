{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ Practical: Topic Modeling using LDA on Synthetic Data"
      ],
      "metadata": {
        "id": "B2iK8Q-z6fPJ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "5CXIOAtB5rLC",
        "outputId": "d5fb0743-da67-410a-cc06-40656bf98f4b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n",
            "Collecting gensim\n",
            "  Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.1 kB)\n",
            "Collecting pyLDAvis\n",
            "  Downloading pyLDAvis-3.4.1-py3-none-any.whl.metadata (4.2 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.2.1)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.5.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n",
            "Collecting numpy<2.0,>=1.18.5 (from gensim)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m1.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy<1.14.0,>=1.7.0 (from gensim)\n",
            "  Downloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m60.6/60.6 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.11/dist-packages (from gensim) (7.1.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.2.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (3.1.6)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (2.10.2)\n",
            "Collecting funcy (from pyLDAvis)\n",
            "  Downloading funcy-2.0-py2.py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: scikit-learn>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (1.6.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from pyLDAvis) (75.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=2.0.0->pyLDAvis) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.0.0->pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.11/dist-packages (from smart-open>=1.8.1->gensim) (1.17.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->pyLDAvis) (3.0.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=2.0.0->pyLDAvis) (1.17.0)\n",
            "Downloading gensim-4.3.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.7 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m26.7/26.7 MB\u001b[0m \u001b[31m56.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyLDAvis-3.4.1-py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m68.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.13.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.6 MB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m38.6/38.6 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading funcy-2.0-py2.py3-none-any.whl (30 kB)\n",
            "Installing collected packages: funcy, numpy, scipy, gensim, pyLDAvis\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.15.3\n",
            "    Uninstalling scipy-1.15.3:\n",
            "      Successfully uninstalled scipy-1.15.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "tsfresh 0.21.0 requires scipy>=1.14.0; python_version >= \"3.10\", but you have scipy 1.13.1 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed funcy-2.0 gensim-4.3.3 numpy-1.26.4 pyLDAvis-3.4.1 scipy-1.13.1\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              },
              "id": "2161a399500c46fcad97cccd72a4a069"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "!pip install nltk gensim pyLDAvis"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import nltk\n",
        "import gensim\n",
        "from gensim import corpora\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "import pyLDAvis.gensim_models\n",
        "import pyLDAvis\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tp9wW4mB5sNY",
        "outputId": "03ceeea3-1bac-44f2-f247-d30073cc2ea1"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìù Step 1: Create Synthetic Text Data"
      ],
      "metadata": {
        "id": "jj3BcKzr6khT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Synthetic document set\n",
        "documents = [\n",
        "    \"Artificial intelligence and machine learning are transforming industries.\",\n",
        "    \"Deep learning models are part of machine learning.\",\n",
        "    \"Natural language processing helps machines understand human language.\",\n",
        "    \"Football and cricket are popular sports in many countries.\",\n",
        "    \"Athletes train daily to excel in competitions like the Olympics.\",\n",
        "    \"Technology companies are investing in AI and robotics.\",\n",
        "    \"Sports teams analyze performance data using analytics tools.\",\n",
        "    \"Language models like GPT-4 are revolutionizing communication.\",\n",
        "    \"Basketball and baseball have large fan followings.\",\n",
        "    \"Speech recognition is a field of natural language processing.\"\n",
        "]\n"
      ],
      "metadata": {
        "id": "5--tIZbz55kF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßπ Step 2: Preprocess the Text"
      ],
      "metadata": {
        "id": "K32o9Xg06mvg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt_tab')\n",
        "# Tokenization and stopword removal\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess(doc):\n",
        "    tokens = word_tokenize(doc.lower())  # Lowercase and tokenize\n",
        "    return [word for word in tokens if word.isalpha() and word not in stop_words]\n",
        "\n",
        "# Apply preprocessing to each document\n",
        "processed_docs = [preprocess(doc) for doc in documents]\n",
        "\n",
        "# Show preprocessed documents\n",
        "print(processed_docs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZpKyTU7q58kE",
        "outputId": "7fa143ad-1dfd-4518-e921-b5e0c27971c2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['artificial', 'intelligence', 'machine', 'learning', 'transforming', 'industries'], ['deep', 'learning', 'models', 'part', 'machine', 'learning'], ['natural', 'language', 'processing', 'helps', 'machines', 'understand', 'human', 'language'], ['football', 'cricket', 'popular', 'sports', 'many', 'countries'], ['athletes', 'train', 'daily', 'excel', 'competitions', 'like', 'olympics'], ['technology', 'companies', 'investing', 'ai', 'robotics'], ['sports', 'teams', 'analyze', 'performance', 'data', 'using', 'analytics', 'tools'], ['language', 'models', 'like', 'revolutionizing', 'communication'], ['basketball', 'baseball', 'large', 'fan', 'followings'], ['speech', 'recognition', 'field', 'natural', 'language', 'processing']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìö Step 3: Prepare Data for LDA"
      ],
      "metadata": {
        "id": "Thu2w3Yy6pTO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a dictionary and corpus\n",
        "dictionary = corpora.Dictionary(processed_docs)\n",
        "corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
        "\n",
        "# Show a sample of the bag-of-words format\n",
        "print(\"\\nBag-of-Words Example (First Doc):\", corpus[0])\n",
        "print(\"\\nWord Mapping (Dictionary):\", dictionary.token2id)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRo3Untz597d",
        "outputId": "0f1c6933-916d-4330-bc70-fb6155873c21"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Bag-of-Words Example (First Doc): [(0, 1), (1, 1), (2, 1), (3, 1), (4, 1), (5, 1)]\n",
            "\n",
            "Word Mapping (Dictionary): {'artificial': 0, 'industries': 1, 'intelligence': 2, 'learning': 3, 'machine': 4, 'transforming': 5, 'deep': 6, 'models': 7, 'part': 8, 'helps': 9, 'human': 10, 'language': 11, 'machines': 12, 'natural': 13, 'processing': 14, 'understand': 15, 'countries': 16, 'cricket': 17, 'football': 18, 'many': 19, 'popular': 20, 'sports': 21, 'athletes': 22, 'competitions': 23, 'daily': 24, 'excel': 25, 'like': 26, 'olympics': 27, 'train': 28, 'ai': 29, 'companies': 30, 'investing': 31, 'robotics': 32, 'technology': 33, 'analytics': 34, 'analyze': 35, 'data': 36, 'performance': 37, 'teams': 38, 'tools': 39, 'using': 40, 'communication': 41, 'revolutionizing': 42, 'baseball': 43, 'basketball': 44, 'fan': 45, 'followings': 46, 'large': 47, 'field': 48, 'recognition': 49, 'speech': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìä Step 4: Train LDA Model"
      ],
      "metadata": {
        "id": "bZsMtkSc6riE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Train LDA model\n",
        "lda_model = gensim.models.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=2,  # You can try changing this\n",
        "    random_state=42,\n",
        "    passes=10,\n",
        "    alpha='auto'\n",
        ")\n",
        "\n",
        "# Display topics\n",
        "topics = lda_model.print_topics()\n",
        "print(\"\\nTopics Discovered:\")\n",
        "for topic in topics:\n",
        "    print(topic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKTAa2mh6N-O",
        "outputId": "de45c731-16db-4264-b349-c5f09b549021"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Topics Discovered:\n",
            "(0, '0.056*\"language\" + 0.056*\"learning\" + 0.040*\"like\" + 0.040*\"models\" + 0.040*\"machine\" + 0.024*\"processing\" + 0.024*\"natural\" + 0.024*\"communication\" + 0.024*\"revolutionizing\" + 0.024*\"understand\"')\n",
            "(1, '0.049*\"sports\" + 0.030*\"football\" + 0.030*\"many\" + 0.030*\"countries\" + 0.030*\"cricket\" + 0.030*\"popular\" + 0.030*\"speech\" + 0.030*\"field\" + 0.030*\"recognition\" + 0.030*\"natural\"')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîç Step 5: Explore Topics for Each Document"
      ],
      "metadata": {
        "id": "DuK57Ftx6t7E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Get topic distribution for each document\n",
        "for i, row in enumerate(lda_model[corpus]):\n",
        "    print(f\"\\nDocument {i + 1} Topic Distribution:\")\n",
        "    for topic_num, prop in row:\n",
        "        print(f\"  Topic {topic_num}: {prop:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uUqpBXu6PSd",
        "outputId": "5cc029f6-6f68-439f-9112-ebcb7dbddc56"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Document 1 Topic Distribution:\n",
            "  Topic 0: 0.9793\n",
            "  Topic 1: 0.0207\n",
            "\n",
            "Document 2 Topic Distribution:\n",
            "  Topic 0: 0.9793\n",
            "  Topic 1: 0.0207\n",
            "\n",
            "Document 3 Topic Distribution:\n",
            "  Topic 0: 0.9843\n",
            "  Topic 1: 0.0157\n",
            "\n",
            "Document 4 Topic Distribution:\n",
            "  Topic 0: 0.0291\n",
            "  Topic 1: 0.9709\n",
            "\n",
            "Document 5 Topic Distribution:\n",
            "  Topic 0: 0.9821\n",
            "  Topic 1: 0.0179\n",
            "\n",
            "Document 6 Topic Distribution:\n",
            "  Topic 0: 0.9754\n",
            "  Topic 1: 0.0246\n",
            "\n",
            "Document 7 Topic Distribution:\n",
            "  Topic 0: 0.0221\n",
            "  Topic 1: 0.9779\n",
            "\n",
            "Document 8 Topic Distribution:\n",
            "  Topic 0: 0.9754\n",
            "  Topic 1: 0.0246\n",
            "\n",
            "Document 9 Topic Distribution:\n",
            "  Topic 0: 0.0346\n",
            "  Topic 1: 0.9654\n",
            "\n",
            "Document 10 Topic Distribution:\n",
            "  Topic 0: 0.0295\n",
            "  Topic 1: 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üìà Step 6: Visualize Topics with pyLDAvis"
      ],
      "metadata": {
        "id": "jc47Znzo6wnn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pyLDAvis.gensim_models as gensimvis\n",
        "\n",
        "# Visualize topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = gensimvis.prepare(lda_model, corpus, dictionary)\n",
        "vis\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 861
        },
        "id": "ENm_RFgZ6Q-F",
        "outputId": "c111364e-1de1-46f6-9231-c542915229a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PreparedData(topic_coordinates=             x    y  topics  cluster       Freq\n",
              "topic                                          \n",
              "0      0.06652  0.0       1        1  59.606032\n",
              "1     -0.06652  0.0       2        1  40.393968, topic_info=          Term      Freq     Total Category  logprob  loglift\n",
              "21      sports  1.000000  1.000000  Default  30.0000  30.0000\n",
              "3     learning  2.000000  2.000000  Default  29.0000  29.0000\n",
              "18    football  1.000000  1.000000  Default  28.0000  28.0000\n",
              "19        many  1.000000  1.000000  Default  27.0000  27.0000\n",
              "16   countries  1.000000  1.000000  Default  26.0000  26.0000\n",
              "..         ...       ...       ...      ...      ...      ...\n",
              "33  technology  0.250436  1.134341   Topic2  -4.6052  -0.6041\n",
              "31   investing  0.250289  1.134370   Topic2  -4.6058  -0.6047\n",
              "3     learning  0.256698  2.315537   Topic2  -4.5805  -1.2930\n",
              "4      machine  0.252635  1.725118   Topic2  -4.5965  -1.0146\n",
              "7       models  0.251979  1.725244   Topic2  -4.5991  -1.0173\n",
              "\n",
              "[93 rows x 6 columns], token_table=      Topic      Freq             Term\n",
              "term                                  \n",
              "29        1  0.881496               ai\n",
              "34        2  0.961138        analytics\n",
              "35        2  0.961119          analyze\n",
              "0         1  0.881421       artificial\n",
              "22        1  0.881498         athletes\n",
              "43        2  0.961291         baseball\n",
              "44        2  0.961197       basketball\n",
              "41        1  0.881323    communication\n",
              "30        1  0.881605        companies\n",
              "23        1  0.881469     competitions\n",
              "16        2  0.961743        countries\n",
              "17        2  0.961740          cricket\n",
              "24        1  0.881389            daily\n",
              "36        2  0.961323             data\n",
              "6         1  0.881785             deep\n",
              "25        1  0.881410            excel\n",
              "45        2  0.961253              fan\n",
              "48        2  0.961651            field\n",
              "46        2  0.961259       followings\n",
              "18        2  0.961758         football\n",
              "9         1  0.881405            helps\n",
              "10        1  0.881406            human\n",
              "1         1  0.881473       industries\n",
              "2         1  0.881460     intelligence\n",
              "31        1  0.881547        investing\n",
              "11        1  0.710512         language\n",
              "11        2  0.355256         language\n",
              "47        2  0.961196            large\n",
              "3         1  0.863731         learning\n",
              "26        1  0.579509             like\n",
              "4         1  0.579671          machine\n",
              "12        1  0.881374         machines\n",
              "19        2  0.961746             many\n",
              "7         1  0.579628           models\n",
              "13        1  0.613026          natural\n",
              "13        2  0.613026          natural\n",
              "27        1  0.881407         olympics\n",
              "8         1  0.881778             part\n",
              "37        2  0.961298      performance\n",
              "20        2  0.961731          popular\n",
              "14        1  0.613026       processing\n",
              "14        2  0.613026       processing\n",
              "49        2  0.961644      recognition\n",
              "42        1  0.881345  revolutionizing\n",
              "32        1  0.881575         robotics\n",
              "50        2  0.961654           speech\n",
              "21        2  0.650954           sports\n",
              "38        2  0.961333            teams\n",
              "33        1  0.881569       technology\n",
              "39        2  0.961305            tools\n",
              "28        1  0.881453            train\n",
              "5         1  0.881410     transforming\n",
              "15        1  0.881354       understand\n",
              "40        2  0.961240            using, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[1, 2])"
            ],
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el7861374124085689441524233670\" style=\"background-color:white;\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el7861374124085689441524233670_data = {\"mdsDat\": {\"x\": [0.06652004764590351, -0.06652004764590351], \"y\": [0.0, 0.0], \"topics\": [1, 2], \"cluster\": [1, 1], \"Freq\": [59.60603195872851, 40.39396804127149]}, \"tinfo\": {\"Term\": [\"sports\", \"learning\", \"football\", \"many\", \"countries\", \"cricket\", \"popular\", \"speech\", \"field\", \"recognition\", \"teams\", \"data\", \"tools\", \"performance\", \"baseball\", \"followings\", \"fan\", \"using\", \"basketball\", \"large\", \"analytics\", \"analyze\", \"like\", \"models\", \"machine\", \"natural\", \"processing\", \"communication\", \"revolutionizing\", \"understand\", \"learning\", \"like\", \"models\", \"machine\", \"communication\", \"revolutionizing\", \"understand\", \"machines\", \"daily\", \"helps\", \"human\", \"olympics\", \"excel\", \"transforming\", \"artificial\", \"train\", \"intelligence\", \"competitions\", \"industries\", \"ai\", \"athletes\", \"investing\", \"technology\", \"robotics\", \"companies\", \"part\", \"deep\", \"language\", \"processing\", \"natural\", \"sports\", \"football\", \"many\", \"countries\", \"cricket\", \"popular\", \"speech\", \"field\", \"recognition\", \"teams\", \"data\", \"tools\", \"performance\", \"baseball\", \"followings\", \"fan\", \"using\", \"basketball\", \"large\", \"analytics\", \"analyze\", \"natural\", \"processing\", \"language\", \"deep\", \"part\", \"companies\", \"robotics\", \"technology\", \"investing\", \"learning\", \"machine\", \"models\"], \"Freq\": [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.0588387917582804, 1.475473118073542, 1.4732647398175722, 1.4724826316652024, 0.8858699219255938, 0.8856921888460815, 0.8856235599226602, 0.8854625538525676, 0.8853452582803409, 0.885215228153618, 0.8852058665351774, 0.8852007038779491, 0.8851742022375105, 0.8851702786180171, 0.8850854045331842, 0.8848318836455606, 0.8847703447713995, 0.8847010274936811, 0.8846672981331231, 0.8844874999907194, 0.8844664363492281, 0.8840806826011308, 0.8839050834199395, 0.8838519424682031, 0.8836130835271079, 0.8822335526802813, 0.8821799987159666, 2.079414114711304, 0.8894111606070465, 0.8894107475944683, 1.237232216706089, 0.7433779417728777, 0.7433104412922436, 0.7432923416471253, 0.7432786269675771, 0.7432245612750719, 0.7427942748663852, 0.7427727698756649, 0.7427368504768478, 0.7409824444117679, 0.740926092939338, 0.7408227663570265, 0.7407847477725642, 0.7407460761081235, 0.740566945599737, 0.740530606363791, 0.7404605402118127, 0.7402128363056845, 0.7402086379343942, 0.7398846169679222, 0.7397748528829656, 0.7418409180434961, 0.7418405448549369, 0.7354586006565398, 0.2518837346119432, 0.25183878871485194, 0.25068139104725384, 0.2504810587638513, 0.25043641608246436, 0.25028905325017453, 0.25669779705197476, 0.25263531304576314, 0.25197903764023316], \"Total\": [1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 2.315536588810255, 1.7255992045447979, 1.7252437774578053, 1.7251179447109655, 1.1346579408180586, 1.1346292499193522, 1.1346182553040327, 1.1345922968437785, 1.1345734064297397, 1.13455241733514, 1.134550985973581, 1.1345501616333529, 1.1345458647121829, 1.134545229816867, 1.1345315181254048, 1.1344907613650599, 1.1344808624577696, 1.134469692622422, 1.1344643022680736, 1.1344352256549919, 1.1344318884700597, 1.1343697358513054, 1.134341499502404, 1.1343330012320543, 1.1342944745743617, 1.1340723413951332, 1.1340637333279098, 2.8148727153678434, 1.6312517054619833, 1.6312516656379643, 1.5362060678456713, 1.039762685894762, 1.0397756196137444, 1.0397790998758403, 1.0397817336108481, 1.0397921322982668, 1.039874669840923, 1.0398788060477697, 1.0398856334508029, 1.040222310069466, 1.040233004305574, 1.040252961977874, 1.0402601682707315, 1.0402674786733375, 1.040301978921057, 1.0403087994995395, 1.0403224372300892, 1.0403697963934146, 1.0403706230084933, 1.0404329064735562, 1.0404538608696197, 1.6312516656379643, 1.6312517054619833, 2.8148727153678434, 1.1340637333279098, 1.1340723413951332, 1.1342944745743617, 1.1343330012320543, 1.134341499502404, 1.1343697358513054, 2.315536588810255, 1.7251179447109655, 1.7252437774578053], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.8876, -3.2207, -3.2222, -3.2228, -3.7309, -3.7311, -3.7312, -3.7314, -3.7315, -3.7316, -3.7317, -3.7317, -3.7317, -3.7317, -3.7318, -3.7321, -3.7321, -3.7322, -3.7323, -3.7325, -3.7325, -3.7329, -3.7331, -3.7332, -3.7335, -3.735, -3.7351, -2.8776, -3.7269, -3.7269, -3.0078, -3.5172, -3.5173, -3.5173, -3.5173, -3.5174, -3.518, -3.518, -3.5181, -3.5204, -3.5205, -3.5206, -3.5207, -3.5207, -3.521, -3.521, -3.5211, -3.5215, -3.5215, -3.5219, -3.5221, -3.5193, -3.5193, -3.5279, -4.5994, -4.5996, -4.6042, -4.605, -4.6052, -4.6058, -4.5805, -4.5965, -4.5991], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.3999, 0.3608, 0.3595, 0.3591, 0.2699, 0.2697, 0.2697, 0.2695, 0.2694, 0.2693, 0.2692, 0.2692, 0.2692, 0.2692, 0.2691, 0.2689, 0.2688, 0.2687, 0.2687, 0.2685, 0.2685, 0.2681, 0.268, 0.2679, 0.2677, 0.2663, 0.2662, 0.2146, -0.0891, -0.0891, 0.6901, 0.5709, 0.5708, 0.5708, 0.5708, 0.5707, 0.5701, 0.57, 0.57, 0.5673, 0.5672, 0.567, 0.567, 0.5669, 0.5666, 0.5666, 0.5665, 0.5661, 0.5661, 0.5656, 0.5654, 0.1185, 0.1185, -0.4357, -0.5981, -0.5983, -0.6031, -0.6039, -0.6041, -0.6047, -1.293, -1.0146, -1.0173]}, \"token.table\": {\"Topic\": [1, 2, 2, 1, 1, 2, 2, 1, 1, 1, 2, 2, 1, 2, 1, 1, 2, 2, 2, 2, 1, 1, 1, 1, 1, 1, 2, 2, 1, 1, 1, 1, 2, 1, 1, 2, 1, 1, 2, 2, 1, 2, 2, 1, 1, 2, 2, 2, 1, 2, 1, 1, 1, 2], \"Freq\": [0.8814958997968592, 0.9611383817044008, 0.9611190246958111, 0.8814210835255664, 0.8814984929140524, 0.9612912260559265, 0.9611966855118611, 0.8813228762837778, 0.8816052818870029, 0.8814691185697663, 0.9617427395101611, 0.9617403034455143, 0.8813885415724545, 0.9613230842137792, 0.8817846569041585, 0.8814099377583866, 0.9612530437895644, 0.9616505252190535, 0.9612593460959711, 0.9617579218468064, 0.8814048471632722, 0.8814059591529771, 0.8814733068292706, 0.8814604398293449, 0.8815467906057406, 0.7105117006111742, 0.3552558503055871, 0.961195921803567, 0.8637306832744195, 0.5795088438649307, 0.5796705106835723, 0.8813738668787116, 0.9617459585862186, 0.5796282317120006, 0.6130261939741292, 0.6130261939741292, 0.8814065995639646, 0.8817779638023816, 0.961297981506244, 0.9617306853338909, 0.6130261790082188, 0.6130261790082188, 0.9616442114711744, 0.8813451619293955, 0.8815753389118111, 0.9616543502814403, 0.6509543354443129, 0.9613329673089015, 0.8815687343173684, 0.9613046408429932, 0.8814527487176398, 0.881410430998344, 0.8813537022917366, 0.9612404425906167], \"Term\": [\"ai\", \"analytics\", \"analyze\", \"artificial\", \"athletes\", \"baseball\", \"basketball\", \"communication\", \"companies\", \"competitions\", \"countries\", \"cricket\", \"daily\", \"data\", \"deep\", \"excel\", \"fan\", \"field\", \"followings\", \"football\", \"helps\", \"human\", \"industries\", \"intelligence\", \"investing\", \"language\", \"language\", \"large\", \"learning\", \"like\", \"machine\", \"machines\", \"many\", \"models\", \"natural\", \"natural\", \"olympics\", \"part\", \"performance\", \"popular\", \"processing\", \"processing\", \"recognition\", \"revolutionizing\", \"robotics\", \"speech\", \"sports\", \"teams\", \"technology\", \"tools\", \"train\", \"transforming\", \"understand\", \"using\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [1, 2]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el7861374124085689441524233670\", ldavis_el7861374124085689441524233670_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el7861374124085689441524233670\", ldavis_el7861374124085689441524233670_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.4.0/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el7861374124085689441524233670\", ldavis_el7861374124085689441524233670_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üí¨ Summary\n",
        "LDA is used to extract hidden topics from text.\n",
        "\n",
        "We used synthetic data to model two main themes:\n",
        "\n",
        "One related to technology/AI/NLP\n",
        "\n",
        "One related to sports\n",
        "\n",
        "Visualization helps explore word-topic relationships."
      ],
      "metadata": {
        "id": "dzuXWLc66zhT"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MRKHFeVi6Sg0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}