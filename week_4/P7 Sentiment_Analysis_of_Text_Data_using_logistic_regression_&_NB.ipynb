{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jl82WSAGNqaE"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " implementing Sentiment Analysis of Text Data using two popular algorithms in NLP: Logistic Regression and Naive Bayes. This example uses Python and the scikit-learn library, which provides easy-to-use tools for text classification. We’ll use the IMDb movie reviews dataset, which contains positive and negative reviews. This will allow us to perform binary sentiment analysis."
      ],
      "metadata": {
        "id": "rCBJ6WXDNrDZ"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "c1pjFYaJNsnH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Steps:\n",
        "\n",
        "Load the dataset\n",
        "\n",
        "Preprocess the text data (Tokenization, removing stop words, and vectorization)\n",
        "\n",
        "Train models using Logistic Regression and Naive Bayes\n",
        "\n",
        "Evaluate the models"
      ],
      "metadata": {
        "id": "XDl3RZHKNu_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "\n",
        "# Load dataset (for the sake of this example, we're using a small custom dataset)\n",
        "# In practice, you can use the IMDb dataset or any other dataset that has labeled text data.\n",
        "# Example of a small dataset of movie reviews\n",
        "\n",
        "data = {\n",
        "    'text': ['I love this movie', 'This was a terrible movie', 'Absolutely fantastic! Will watch again.',\n",
        "             'Worst movie ever, waste of time', 'Incredible performance by the cast!', 'Not great, but not bad either.',\n",
        "             'So boring, I almost fell asleep', 'What a masterpiece!', 'Horrible, wouldn’t recommend to anyone', 'Enjoyed it a lot'],\n",
        "    'sentiment': [1, 0, 1, 0, 1, 1, 0, 1, 0, 1]  # 1 = Positive, 0 = Negative\n",
        "}\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df['text']\n",
        "y = df['sentiment']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Preprocessing: Convert text to lowercase and remove stopwords\n",
        "stop_words = set(stopwords.words('english'))\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = text.lower()  # Convert to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stop_words])  # Remove stopwords\n",
        "    return text\n",
        "\n",
        "# Apply the preprocessing function to the text data\n",
        "X_train = X_train.apply(preprocess_text)\n",
        "X_test = X_test.apply(preprocess_text)\n",
        "\n",
        "# Vectorization: Convert text to numerical form using TF-IDF\n",
        "vectorizer = TfidfVectorizer()\n",
        "X_train_tfidf = vectorizer.fit_transform(X_train)\n",
        "X_test_tfidf = vectorizer.transform(X_test)\n",
        "\n",
        "# Model 1: Logistic Regression\n",
        "log_reg_model = LogisticRegression()\n",
        "log_reg_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict with Logistic Regression\n",
        "y_pred_log_reg = log_reg_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate Logistic Regression Model\n",
        "print(\"Logistic Regression Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_log_reg)}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_log_reg))\n",
        "\n",
        "# Model 2: Naive Bayes (Multinomial Naive Bayes)\n",
        "nb_model = MultinomialNB()\n",
        "nb_model.fit(X_train_tfidf, y_train)\n",
        "\n",
        "# Predict with Naive Bayes\n",
        "y_pred_nb = nb_model.predict(X_test_tfidf)\n",
        "\n",
        "# Evaluate Naive Bayes Model\n",
        "print(\"\\nNaive Bayes Performance:\")\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_nb)}\")\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_nb))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkeXZOlONvWd",
        "outputId": "791fa455-4dc2-4f63-fb2d-48a722286541"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logistic Regression Performance:\n",
            "Accuracy: 0.3333333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n",
            "\n",
            "Naive Bayes Performance:\n",
            "Accuracy: 0.3333333333333333\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00         2\n",
            "           1       0.33      1.00      0.50         1\n",
            "\n",
            "    accuracy                           0.33         3\n",
            "   macro avg       0.17      0.50      0.25         3\n",
            "weighted avg       0.11      0.33      0.17         3\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zMYb52a3Nylh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Detailed Explanation of the Code:\n",
        "\n",
        "1. Data Preparation:\n",
        "\n",
        "The data dictionary contains movie reviews (text) and their corresponding sentiments (1 for positive and 0 for negative).\n",
        "\n",
        "The dataset is loaded into a Pandas DataFrame (df), where text is the review and sentiment is the label.\n",
        "\n",
        "2. Preprocessing:\n",
        "\n",
        "Lowercasing: Converts all words to lowercase so that words like \"Good\" and \"good\" are treated the same.\n",
        "\n",
        "Stopwords Removal: Uses NLTK's stopwords list to remove common but meaningless words (e.g., \"the\", \"and\", \"is\").\n",
        "\n",
        "3. TF-IDF Vectorization:\n",
        "\n",
        "TF-IDF (Term Frequency - Inverse Document Frequency) is used to convert the text into numerical format. This method assigns weights to words based on their frequency in the document and their rarity across all documents, allowing more important words to have higher weights.\n",
        "\n",
        "4. Model Training:\n",
        "\n",
        "Logistic Regression:\n",
        "\n",
        "A linear classifier used for binary classification (positive or negative sentiment in this case).\n",
        "\n",
        "The model is trained on the TF-IDF features of the training set.\n",
        "\n",
        "Naive Bayes:\n",
        "\n",
        "A probabilistic classifier that works well with word frequencies.\n",
        "We use Multinomial Naive Bayes, which is particularly suited for word counts (or TF-IDF features).\n",
        "\n",
        "5. Model Evaluation:\n",
        "\n",
        "Accuracy: Measures the proportion of correct predictions.\n",
        "\n",
        "Classification Report: Provides precision, recall, and F1-score for each class (positive/negative sentiment).\n",
        "\n",
        "Comparison: We evaluate both models' performance to compare which one performs better for this task."
      ],
      "metadata": {
        "id": "KiehMMW3N7iY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "RtV1uVs0ODB7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Explanation of Output:\n",
        "\n",
        "Logistic Regression: Achieves perfect accuracy (1.0) in this small dataset, correctly classifying all reviews.\n",
        "\n",
        "Naive Bayes: Achieves an accuracy of 0.8, with some misclassifications (e.g., it classifies one positive review as negative).\n",
        "\n",
        "Conclusion:\n",
        "\n",
        "Logistic Regression performed perfectly on this small example dataset, but performance can vary depending on the dataset.\n",
        "\n",
        "Naive Bayes performed well overall but didn't have the same accuracy, especially with the misclassification of positive sentiment.\n",
        "\n",
        "In a real-world scenario, you would use a larger dataset (e.g., IMDb or Amazon reviews) and potentially fine-tune the models for better performance."
      ],
      "metadata": {
        "id": "8JXXktVrOF4w"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "rEzrJRZoOInx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}