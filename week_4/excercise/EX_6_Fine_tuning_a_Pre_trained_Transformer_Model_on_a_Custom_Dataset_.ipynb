{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HU5IiUL-1sV7"
      },
      "source": [
        "# Fine-tuning a Pre-trained Transformer Model on a Custom Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7wOAUXNY1sWB"
      },
      "source": [
        "## Introduction\n",
        "In modern Natural Language Processing (NLP), **fine-tuning** pre-trained transformer models is the most common and effective approach to achieve state-of-the-art results on various downstream tasks. Instead of training a model from scratch, we take a large language model (like BERT, RoBERTa, etc.) that has already learned rich language representations on massive text corpora, and then adapt it to a specific task (e.g., text classification, question answering, named entity recognition) using a smaller, task-specific dataset.\n",
        "\n",
        "This process leverages **transfer learning**, allowing us to achieve high performance with significantly less labeled data and computational resources compared to training from zero.\n",
        "\n",
        "In this assignment, you will fine-tune a pre-trained BERT model for a simple binary text classification task using a small custom dataset, utilizing the powerful **HuggingFace Transformers library** and its convenient `Trainer` API.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KvRdvXtz1sWD"
      },
      "source": [
        "## Learning Objectives\n",
        "Upon completion of this assignment, you should be able to:\n",
        "- Understand the fine-tuning paradigm for transformer models.\n",
        "- Prepare a custom text classification dataset using HuggingFace `Datasets`.\n",
        "- Load and apply a pre-trained tokenizer to custom text data.\n",
        "- Initialize a pre-trained model for sequence classification.\n",
        "- Define and compute relevant evaluation metrics for classification.\n",
        "- Use the HuggingFace `Trainer` API to fine-tune a model efficiently.\n",
        "- Evaluate the performance of a fine-tuned model.\n",
        "- Perform inference with the fine-tuned model on new data.\n",
        "- Discuss the advantages, challenges, and strategies for improving fine-tuning.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EYUb50o1sWE"
      },
      "source": [
        "## Setup and Prerequisites\n",
        "Ensure you have the necessary libraries installed. If not, uncomment and run the following cells:\n",
        "\n",
        "```bash\n",
        "# pip install transformers datasets accelerate evaluate scikit-learn torch\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JLtoZN01sWG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from datasets import Dataset, DatasetDict\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, TrainingArguments, Trainer, DataCollatorWithPadding\n",
        "import evaluate\n",
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"Transformers Version: {transformers.__version__}\")\n",
        "print(f\"Datasets Version: {datasets.__version__}\")\n",
        "print(f\"Evaluate Version: {evaluate.__version__}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hI772rIm1sWM"
      },
      "source": [
        "## Assignment Questions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YFS6VQcO1sWO"
      },
      "source": [
        "### Question 1: Dataset Preparation\n",
        "For this assignment, we'll create a *very small* custom dataset in-memory for a binary text classification task (e.g., positive/negative reviews). In a real-world scenario, you would load this from a CSV, JSON, or other file format.\n",
        "\n",
        "1.  **Define Custom Data:** Create a Python list of dictionaries, where each dictionary represents an example with at least two keys: `\"text\"` (for the input sentence) and `\"label\"` (for the class ID, e.g., 0 for negative, 1 for positive).\n",
        "    * Aim for around 10-20 examples total.\n",
        "    * Ensure some examples for both classes.\n",
        "2.  **Create HuggingFace `Dataset`:** Convert your list of dictionaries into a `datasets.Dataset` object.\n",
        "3.  **Split Data:** Split the `Dataset` into `train` and `validation` sets using `dataset.train_test_split()`. Use a `test_size` of 0.2-0.3 and a `seed` for reproducibility.\n",
        "4.  **Inspect:** Print the number of examples in the training and validation splits. Print one example from the training split to show its structure.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cWQ1bl1p1sWQ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yuV5WSSb1sWR"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "koklR9j11sWT"
      },
      "source": [
        "### Question 2: Tokenization and Data Collator\n",
        "Transformer models require numerical inputs (token IDs, attention masks, token type IDs). The `AutoTokenizer` handles this.\n",
        "\n",
        "1.  **Load Tokenizer:** Load a pre-trained tokenizer compatible with BERT (e.g., `'bert-base-uncased'`).\n",
        "2.  **Define Tokenization Function:** Create a function `tokenize_function(examples)` that takes a dictionary of examples (as provided by `dataset.map()`) and returns the tokenized inputs. Ensure it handles `truncation=True` and `padding='max_length'` or `'longest'` (for dynamic padding with `DataCollator`).\n",
        "3.  **Apply Tokenization:** Apply this function to both your training and validation `Dataset` splits using the `.map()` method.\n",
        "4.  **Data Collator:** Initialize a `DataCollatorWithPadding` using your tokenizer. Explain why `DataCollatorWithPadding` is preferred over padding all sequences to `max_length` upfront for training efficiency.\n",
        "5.  **Inspect Tokenized Data:** Print a single tokenized example from the training set to see its `input_ids`, `attention_mask`, and `labels`.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4IkzjqMv1sWV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FFgAXtLE1sWW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SorXsjdY1sWX"
      },
      "source": [
        "### Question 3: Model Loading\n",
        "Now, load the pre-trained model for your specific task: sequence classification.\n",
        "\n",
        "1.  **Load Model:** Load `AutoModelForSequenceClassification` from the same pre-trained checkpoint as your tokenizer (e.g., `'bert-base-uncased'`).\n",
        "2.  **Specify Number of Labels:** Crucially, pass `num_labels` parameter to the model constructor, matching the number of unique classes in your dataset (e.g., 2 for binary classification).\n",
        "3.  **Move to Device:** Move the model to your `device` (GPU/CPU).\n",
        "4.  **Inspect Model:** Print the model's configuration (e.g., `model.config`) and verify that `num_labels` is set correctly.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8HiNCVX01sWd"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8rv4MEeJ1sWd"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lw3uSJJx1sWe"
      },
      "source": [
        "### Question 4: Define Evaluation Metrics\n",
        "For classification tasks, beyond just accuracy, metrics like precision, recall, and F1-score are vital, especially for imbalanced datasets. The `Trainer` API expects a `compute_metrics` function.\n",
        "\n",
        "1.  **Load Metrics:** Use `evaluate.load()` to load the necessary metrics (e.g., `'accuracy'`, `'f1'`, `'precision'`, `'recall'`).\n",
        "2.  **`compute_metrics` Function:** Create a function `compute_metrics(eval_pred)` that:\n",
        "    * Takes `EvalPrediction` object (which contains predictions and labels).\n",
        "    * Converts predictions to class IDs (e.g., `np.argmax(logits, axis=1)`).\n",
        "    * Calculates accuracy, precision, recall, and F1-score.\n",
        "    * Returns a dictionary where keys are metric names and values are their scores.\n",
        "    * *Hint:* For precision, recall, F1, you might need to specify `average='weighted'` or `average='binary'` depending on your dataset and problem.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i5VuUkLp1sWf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8HdqnRgH1sWg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u7vVvdXv1sWg"
      },
      "source": [
        "### Question 5: Fine-tuning with `Trainer` API\n",
        "The `Trainer` class in HuggingFace simplifies the training loop significantly.\n",
        "\n",
        "1.  **`TrainingArguments`:** Define `TrainingArguments`:\n",
        "    * `output_dir`: A path to save checkpoints and logs.\n",
        "    * `num_train_epochs`: A small number (e.g., 3-5) as fine-tuning converges quickly.\n",
        "    * `per_device_train_batch_size`, `per_device_eval_batch_size`: Small batch sizes (e.g., 8-16) for custom datasets.\n",
        "    * `learning_rate`: A small learning rate (e.g., 2e-5 or 5e-5) is common for fine-tuning.\n",
        "    * `evaluation_strategy`: `'epoch'` (evaluate at the end of each epoch).\n",
        "    * `logging_dir`, `logging_strategy`: For tracking training progress.\n",
        "    * `save_strategy`: `'epoch'`.\n",
        "    * `load_best_model_at_end`: `True`.\n",
        "    * `metric_for_best_model`: Choose a metric to monitor for best model saving (e.g., `'f1'` or `'accuracy'`).\n",
        "    * `greater_is_better`: `True`.\n",
        "2.  **Initialize `Trainer`:** Create a `Trainer` instance, passing in:\n",
        "    * `model`\n",
        "    * `args` (your `TrainingArguments`)\n",
        "    * `train_dataset`, `eval_dataset` (your tokenized datasets)\n",
        "    * `tokenizer`\n",
        "    * `data_collator`\n",
        "    * `compute_metrics`\n",
        "    \n",
        "3.  **Train Model:** Start the training process using `trainer.train()`.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5aaxjICn1sWn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1TGISWs-1sWp"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HhcdCtAh1sWq"
      },
      "source": [
        "### Question 6: Model Evaluation\n",
        "After training, evaluate the model's performance on the validation set.\n",
        "\n",
        "1.  **Evaluate:** Use `trainer.evaluate()` to get the final evaluation metrics on the validation set.\n",
        "2.  **Print Results:** Print the evaluation results.\n",
        "3.  **Discussion:** Based on your metrics, how well did your model perform on this small custom dataset? Given the size of the dataset, are these results expected? What do the precision, recall, and F1-score tell you about the model's performance on each class?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FUJyYEbp1sWr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kbmw9J6O1sWr"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shoTcwXb1sWs"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "81SAn3_L1sWt"
      },
      "source": [
        "### Question 7: Inference with Fine-tuned Model\n",
        "Test your fine-tuned model on a brand new, unseen sentence.\n",
        "\n",
        "1.  **New Sentence:** Define a new sentence that was *not* part of your training or validation set.\n",
        "2.  **Prepare Input:** Tokenize the new sentence. Ensure it's returned as PyTorch tensors (`return_tensors=\"pt\"`) and moved to the `device`.\n",
        "3.  **Predict:** Pass the tokenized input through your `model` (which should now be the fine-tuned one). Remember to use `model.eval()` and `torch.no_grad()`.\n",
        "4.  **Interpret Output:** The model will output `logits`. Convert these logits into probabilities (e.g., using `torch.softmax`) and then determine the predicted class label (0 or 1).\n",
        "5.  **Print Prediction:** Print the original new sentence and its predicted class label.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DjKEBcSZ1sWt"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LrIFvX-q1sWu"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hR260By1sWu"
      },
      "source": [
        "### Question 8: Discussion and Challenges\n",
        "1.  **Advantages of Fine-tuning:** What are the primary advantages of fine-tuning a pre-trained transformer model compared to training a traditional machine learning model (like Logistic Regression + TF-IDF) or a neural network from scratch for text classification?\n",
        "2.  **Challenges/Considerations:** What are some common challenges or important considerations when fine-tuning transformer models on custom datasets? (Think about data size, quality, hyperparameter tuning, computational resources, and potential overfitting).\n",
        "3.  **Improving Performance:** If your model's performance was not satisfactory, what steps would you take to try and improve it? Suggest at least three actionable strategies.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-52Wiq51sWu"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKdZMZLv1sWv"
      },
      "source": [
        "## Submission Guidelines\n",
        "- Ensure your notebook runs without errors from top to bottom.\n",
        "- Save your notebook as `your_name_finetuning_assignment.ipynb`.\n",
        "- Clearly answer all questions and provide explanations where requested in Markdown cells.\n",
        "- Feel free to add additional code cells or markdown cells for clarity or experimentation.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}