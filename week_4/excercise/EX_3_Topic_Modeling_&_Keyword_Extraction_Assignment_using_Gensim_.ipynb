{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qa8-d8hFvHCe"
      },
      "source": [
        "# Topic Modeling & Keyword Extraction Assignment using Gensim"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yi51lt0evHCg"
      },
      "source": [
        "## Introduction\n",
        "This assignment delves into **Topic Modeling** and **Keyword Extraction**, two powerful techniques in Natural Language Processing (NLP) for uncovering hidden thematic structures and identifying important terms within a collection of documents. You'll primarily use the **Gensim** library, a robust open-source library for unsupervised topic modeling and natural language understanding.\n",
        "\n",
        "**Topic modeling** helps us discover abstract \"topics\" that occur in a collection of documents. **Keyword extraction** focuses on identifying the most representative words or phrases from a single document or a set of documents.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJoyI6GJvHCh"
      },
      "source": [
        "## Learning Objectives\n",
        "By completing this assignment, you should be able to:\n",
        "- Load and preprocess text data effectively for topic modeling.\n",
        "- Create a Gensim dictionary and corpus from a collection of documents.\n",
        "- Apply Latent Dirichlet Allocation (LDA) using Gensim to discover topics.\n",
        "- Interpret the topics generated by an LDA model.\n",
        "- Implement basic keyword extraction techniques.\n",
        "- Discuss the challenges and applications of topic modeling and keyword extraction.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fduxCM2jvHCh"
      },
      "source": [
        "## Dataset\n",
        "For this assignment, we'll use a collection of news articles or abstracts. A suitable dataset would be a subset of the **20 Newsgroups dataset** or a collection of research paper abstracts.\n",
        "\n",
        "**Assumption:** We'll assume you have a list of text documents. If you have a CSV, you might need to load it and extract a text column. We'll use a small, built-in example dataset for demonstration purposes if a file isn't provided.\n",
        "\n",
        "**If you need a real dataset, consider downloading a small subset of:**\n",
        "- **20 Newsgroups Dataset:** Available via scikit-learn (`from sklearn.datasets import fetch_20newsgroups`). It has various categories, which can be useful for seeing how well LDA uncovers them.\n",
        "- **Abstracts from ArXiv:** Often available as JSON or CSV files.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lj2i1n3uvHCi"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from gensim import corpora\n",
        "from gensim.models.ldamodel import LdaModel\n",
        "from gensim.models.coherencemodel import CoherenceModel\n",
        "from gensim.summarization import keywords # For TextRank keywords\n",
        "\n",
        "import re\n",
        "import string\n",
        "\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore') # Ignore warnings, especially about gensim.summarization being deprecated\n",
        "\n",
        "\n",
        "# Download NLTK data (if not already downloaded)\n",
        "try:\n",
        "    nltk.data.find('corpora/stopwords')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('stopwords')\n",
        "try:\n",
        "    nltk.data.find('corpora/wordnet')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('wordnet')\n",
        "try:\n",
        "    nltk.data.find('corpora/omw-1.4')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('omw-1.4') # Required for WordNetLemmatizer\n",
        "try:\n",
        "    nltk.data.find('tokenizers/punkt')\n",
        "except nltk.downloader.DownloadError:\n",
        "    nltk.download('punkt')\n",
        "\n",
        "\n",
        "# --- Sample Data (if you don't have a specific dataset) ---\n",
        "documents = [\n",
        "    \"The quick brown fox jumps over the lazy dog. Dogs are loyal pets.\",\n",
        "    \"Machine learning is a fascinating field. Neural networks are a type of machine learning algorithm.\",\n",
        "    \"Artificial intelligence is rapidly advancing. AI models are becoming more sophisticated.\",\n",
        "    \"Computers process data very quickly. Data science involves analyzing large datasets.\",\n",
        "    \"Space exploration is a huge endeavor. Astronauts explore the cosmos and discover new planets.\",\n",
        "    \"Deep learning, a subset of machine learning, has revolutionized image recognition.\",\n",
        "    \"Robotics combine engineering and computer science to build intelligent machines.\",\n",
        "    \"The stock market saw a surge in tech stocks. Investors are optimistic about future growth.\",\n",
        "    \"Climate change impacts the environment. Scientists are studying global warming.\",\n",
        "    \"Genetics research explores DNA and heredity. The human genome project was a landmark study.\",\n",
        "    \"The new smartphone has an amazing camera and long battery life. Users love the features.\",\n",
        "    \"Cryptocurrency values are volatile. Blockchain technology underpins many digital currencies.\",\n",
        "    \"Travel to distant galaxies is currently science fiction, but inspiring for astronomy.\",\n",
        "    \"Big data analytics helps businesses make informed decisions from vast amounts of information.\"\n",
        "]\n",
        "\n",
        "print(\"Sample documents loaded. Total documents:\", len(documents))\n",
        "print(\"\\nFirst document example:\\n\", documents[0])\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1S7VuslvHCk"
      },
      "source": [
        "## Assignment Questions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSXD9m5AvHCk"
      },
      "source": [
        "### Question 1: Text Preprocessing for Topic Modeling\n",
        "Topic models perform best on clean, well-processed text. Create a function `preprocess_text(text)` that performs the following steps:\n",
        "1.  **Convert to Lowercase:** Convert the entire text to lowercase.\n",
        "2.  **Remove Punctuation:** Remove all punctuation marks.\n",
        "3.  **Remove Numbers:** Remove all numerical digits.\n",
        "4.  **Remove Extra Whitespace:** Replace multiple spaces with a single space and strip leading/trailing whitespace.\n",
        "5.  **Tokenization:** Tokenize the text into individual words.\n",
        "6.  **Remove Stop Words:** Remove common English stop words using NLTK's `stopwords` corpus.\n",
        "7.  **Lemmatization:** Apply lemmatization to each token using NLTK's `WordNetLemmatizer`. (For simplicity, you can assume default POS tag `'n'` or `'v'` for better results).\n",
        "8.  **Filter Short/Long Words:** Remove words that are too short (e.g., length < 3) or too long (e.g., length > 15) as they might be noise or not meaningful.\n",
        "\n",
        "Apply this `preprocess_text` function to each document in your `documents` list. Store the result as a list of lists of tokens (e.g., `[['word1', 'word2'], ['wordA', 'wordB']]`). Print the preprocessed version of the first document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NXJZmI_KvHCl"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a_VaY3rBvHCl"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBYnJMXPvHCl"
      },
      "source": [
        "### Question 2: Create Gensim Dictionary and Corpus\n",
        "Gensim's LDA model requires input in a specific format: a dictionary (mapping words to IDs) and a corpus (a list of documents represented as bags-of-words).\n",
        "\n",
        "1.  **Create a Dictionary:** Use `gensim.corpora.Dictionary` to create a dictionary from your list of preprocessed documents (from Question 1).\n",
        "2.  **Filter Extremes (Optional but Recommended):** Filter out words that appear too frequently or too infrequently. This can help remove very common words (even if not stop words) and very rare words that don't contribute much to topic identification. Use `dictionary.filter_extremes()` (e.g., `no_below=5`, `no_above=0.5`).\n",
        "3.  **Create a Corpus:** Use the `dictionary.doc2bow()` method to convert each preprocessed document into a bag-of-words (list of `(word_id, count)` tuples). Store this as your Gensim corpus.\n",
        "4.  Print the dictionary size and the bag-of-words representation of the first document in your corpus."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Yt-DP_SyvHCm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6uqDLV0vHCm"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYazXh8vvHCm"
      },
      "source": [
        "### Question 3: Train an LDA Model\n",
        "Now, let's train the LDA model to discover topics within your document collection.\n",
        "\n",
        "1.  **Initialize and Train LDA Model:** Use `gensim.models.LdaModel`.\n",
        "    * Set `num_topics` to a reasonable number (e.g., 3-5 for our small sample, or 10-20 for larger datasets). Experiment if you like!\n",
        "    * Pass your `corpus` and `dictionary`.\n",
        "    * Set `passes` (number of training iterations) to a value like 10-20.\n",
        "    * Set `random_state` for reproducibility.\n",
        "2.  **Print Topics:** Print the top 10 most significant words for each discovered topic. Use `lda_model.print_topics()`.\n",
        "3.  **Interpret Topics:** Based on the words associated with each topic, try to assign a descriptive name or theme to each topic. Discuss what each topic appears to be about."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N46pa3BMvHCm"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zx30grGjvHCm"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPpxBN5NvHCn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kBz0eFwPvHCn"
      },
      "source": [
        "### Question 4: Evaluate Topic Coherence (Optional/Bonus)\n",
        "Topic coherence measures how interpretable and meaningful the topics are to humans. A higher coherence score generally indicates better topics.\n",
        "\n",
        "1.  **Calculate Coherence Score:** Use `gensim.models.CoherenceModel`.\n",
        "    * Set `model` to your trained `lda_model`.\n",
        "    * Set `texts` to your preprocessed documents (list of lists of tokens from Q1).\n",
        "    * Set `dictionary` to your Gensim dictionary.\n",
        "    * Set `coherence='c_v'` (a common and robust coherence measure).\n",
        "2.  Print the coherence score.\n",
        "3.  Briefly explain what this score indicates about your topics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cwJUP4revHCn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9CXCZ2aYvHCn"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dPDa418NvHCn"
      },
      "source": [
        "### Question 5: Assign Topics to Documents\n",
        "After training the LDA model, you can determine the dominant topic(s) for each document.\n",
        "\n",
        "1.  Iterate through your `corpus` (bag-of-words documents).\n",
        "2.  For each document, use `lda_model.get_document_topics()` to get the topic distribution.\n",
        "3.  Identify the dominant topic (the one with the highest probability) for at least the first 5 documents.\n",
        "4.  Print the original document and its dominant topic (including its ID and probability)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmY_z3KuvHCn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3LF3DlFvHCo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zqT9TjBVvHCo"
      },
      "source": [
        "### Question 6: Keyword Extraction (using Gensim's `keywords` module - TextRank)\n",
        "Gensim provides a simple way to extract keywords from text, often using a TextRank-like algorithm. This is different from the important words in LDA topics, as it focuses on single document salience.\n",
        "\n",
        "1.  Choose one of your original `documents` (e.g., `documents[0]`).\n",
        "2.  Use `gensim.summarization.keywords()` to extract keywords from this document.\n",
        "3.  Print the original document and the extracted keywords.\n",
        "4.  Discuss whether the extracted keywords accurately represent the main themes of the document. How do these compare to the words you saw in the LDA topics?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2QwUd9j-vHCo"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sxh75JSlvHCo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbufVdJjvHCo"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i83dpn0CvHCo"
      },
      "source": [
        "### Question 7: Discussion and Applications\n",
        "Reflect on your experience with topic modeling and keyword extraction.\n",
        "\n",
        "1.  **Challenges of Topic Modeling:** What were some challenges or ambiguities you faced when interpreting the LDA topics? (e.g., overlapping topics, vague words).\n",
        "2.  **Applications:** Describe two real-world scenarios (different from news articles) where topic modeling and/or keyword extraction could be highly beneficial. Explain *how* they would be used in each scenario.\n",
        "3.  **Limitations of Simple Keyword Extraction:** What are some limitations of simple keyword extraction methods like the one used in Q6 (TextRank-like)? How might they struggle with context or nuance?\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9GLkrn7LvHCo"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOg_Ld0HvHCp"
      },
      "source": [
        "## Submission Guidelines\n",
        "- Ensure your notebook runs without errors from top to bottom.\n",
        "- Save your notebook as `your_name_topic_modeling_assignment.ipynb`.\n",
        "- Clearly answer all questions and provide explanations where requested in Markdown cells.\n",
        "- Feel free to add additional code cells or markdown cells for clarity or experimentation.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}