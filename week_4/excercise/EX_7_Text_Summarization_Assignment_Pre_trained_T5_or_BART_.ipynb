{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ubq8vfNKyYZN"
      },
      "source": [
        "# Text Summarization Assignment: Pre-trained T5 or BART with HuggingFace Transformers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hnJVHcj4yYZP"
      },
      "source": [
        "## Introduction\n",
        "**Text summarization** is the task of creating a short, concise, and coherent summary of a longer text while retaining its main points. There are two main types:\n",
        "1.  **Extractive Summarization:** Identifies and extracts key sentences or phrases directly from the original text.\n",
        "2.  **Abstractive Summarization:** Generates new sentences and phrases that capture the essence of the original text, potentially using words and structures not present in the source.\n",
        "\n",
        "Modern Transformer models, particularly **T5 (Text-to-Text Transfer Transformer)** and **BART (Bidirectional and Auto-Regressive Transformers)**, excel at abstractive summarization. They are trained as sequence-to-sequence models, capable of taking a text sequence as input and generating a new, summarized text sequence as output.\n",
        "\n",
        "The **HuggingFace Transformers library** provides an incredibly easy way to load and use these pre-trained models for various NLP tasks, including summarization.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_IkJ90LyYZQ"
      },
      "source": [
        "## Learning Objectives\n",
        "Upon completion of this assignment, you should be able to:\n",
        "- Understand the concept of abstractive text summarization.\n",
        "- Load pre-trained T5 or BART models and their tokenizers using HuggingFace Transformers.\n",
        "- Prepare input text for summarization (including T5's specific prefix).\n",
        "- Generate summaries from single and multiple documents using `model.generate()`.\n",
        "- Control summary generation parameters like `max_length`, `min_length`, and `num_beams`.\n",
        "- Qualitatively evaluate the quality, coherence, and relevance of generated summaries.\n",
        "- Discuss the strengths, weaknesses, and real-world applications of abstractive summarization models.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fS8SDfaeyYZQ"
      },
      "source": [
        "## Setup and Prerequisites\n",
        "Ensure you have the necessary libraries installed. If not, uncomment and run the following cells:\n",
        "\n",
        "```bash\n",
        "# pip install transformers torch # or tensorflow\n",
        "# pip install sentencepiece # Required for T5 tokenizer\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ynG1CUosyYZR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import AutoTokenizer, AutoModelForSeq2SeqLM\n",
        "\n",
        "print(f\"PyTorch Version: {torch.__version__}\")\n",
        "print(f\"Transformers Version: {transformers.__version__}\")\n",
        "\n",
        "# Check if GPU is available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- Sample Long Texts for Summarization ---\n",
        "sample_long_texts = [\n",
        "    \"The Amazon rainforest is the largest rainforest in the world, covering an area of approximately 5.5 million square kilometers. It spans across nine South American countries: Brazil, Peru, Colombia, Ecuador, Bolivia, Guyana, Suriname, French Guiana, and Venezuela. The Amazon is incredibly biodiverse, housing around 10% of the world's known species, including numerous unique plants, insects, birds, and mammals. It plays a crucial role in regulating the Earth's climate by absorbing vast amounts of carbon dioxide, earning it the nickname 'the lungs of the Earth'. However, the rainforest faces severe threats from deforestation, primarily due to agricultural expansion, logging, and mining. Conservation efforts are underway to protect this vital ecosystem.\",\n",
        "\n",
        "    \"Artificial intelligence (AI) is rapidly transforming various industries, from healthcare to finance and transportation. Machine learning, a subset of AI, enables systems to learn from data without explicit programming. Deep learning, in turn, is a specialized form of machine learning that uses neural networks with multiple layers to uncover intricate patterns in data. Recent advancements in AI have led to breakthroughs in areas such as natural language processing, computer vision, and autonomous driving. While AI offers immense potential for innovation and efficiency, it also raises ethical concerns regarding job displacement, privacy, and algorithmic bias. Researchers and policymakers are actively working on addressing these challenges to ensure responsible AI development.\",\n",
        "\n",
        "    \"Climate change refers to long-term shifts in temperatures and weather patterns. These shifts may be natural, but since the 1800s, human activities have been the main driver of climate change, primarily due to the burning of fossil fuels (like coal, oil, and gas) which produces heat-trapping gases. The consequences of climate change include rising global temperatures, more frequent and intense heatwaves, melting glaciers and ice sheets leading to sea-level rise, altered precipitation patterns, and an increase in the intensity of extreme weather events such as floods, droughts, wildfires, and storms. Mitigating climate change requires a global effort to reduce greenhouse gas emissions, transition to renewable energy sources, and implement sustainable land use practices. Adaptation strategies are also crucial to cope with the unavoidable impacts of a changing climate.\"\n",
        "]\n",
        "\n",
        "print(\"Sample long texts loaded. Total texts:\", len(sample_long_texts))\n",
        "print(\"\\nFirst sample text for summarization:\\n\", sample_long_texts[0][:200], \"...\") # Print first 200 chars\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWjZ1A07yYZS"
      },
      "source": [
        "## Assignment Questions\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "civxs_75yYZT"
      },
      "source": [
        "### Question 1: Model and Tokenizer Loading (T5 or BART)\n",
        "Choose one of the following pre-trained models for summarization:\n",
        "- **T5:** `t5-small`, `t5-base`, `t5-large` (e.g., `'t5-small'`) - *Note: T5 models require a specific prefix for summarization.*\n",
        "- **BART:** `facebook/bart-large-cnn`, `sshleifer/distilbart-cnn-12-6` (e.g., `'facebook/bart-large-cnn'`)\n",
        "\n",
        "1.  **Select Model Name:** Choose your preferred model name (e.g., `'t5-small'`).\n",
        "2.  **Load Tokenizer:** Load the corresponding tokenizer using `AutoTokenizer.from_pretrained()`.\n",
        "3.  **Load Model:** Load the model for sequence-to-sequence tasks using `AutoModelForSeq2SeqLM.from_pretrained()`. Move the model to your `device` (GPU if available, otherwise CPU).\n",
        "4.  **Inspect:** Print the type of the loaded tokenizer and model. Print a small part of the model's architecture (e.g., `model.config` or `model.encoder.block[0]`) to confirm it loaded correctly.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E2QspT6pyYZT"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oglo32D8yYZT"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9lWIvSmhyYZU"
      },
      "source": [
        "### Question 2: Single Document Summarization\n",
        "Let's summarize the first `sample_long_texts` document.\n",
        "\n",
        "1.  **Prepare Input:** Take `sample_long_texts[0]`.\n",
        "    * **If using T5:** Prepend the text with `\"summarize: \"` (e.g., `\"summarize: \" + text`).\n",
        "    * **If using BART:** No special prefix needed.\n",
        "    Tokenize this prepared text, ensuring `return_tensors=\"pt\"` and moving the tensors to your `device`.\n",
        "2.  **Generate Summary:** Use `model.generate()` to produce the summary.\n",
        "    * Set `max_length` (e.g., 50-100 tokens, experiment based on text length).\n",
        "    * Set `min_length` (e.g., 10-20 tokens).\n",
        "    * Set `num_beams` (e.g., 4 or 5) for beam search to get better quality.\n",
        "    * Set `early_stopping=True`.\n",
        "3.  **Decode and Print:** Decode the generated token IDs back to human-readable text using `tokenizer.decode()`. Print the original text and the generated summary.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYnHlZ5YyYZU"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVNaKuQhyYZU"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2njOFyVlyYZU"
      },
      "source": [
        "### Question 3: Controlling Summary Length and Quality\n",
        "The parameters in `model.generate()` significantly influence the summary's characteristics.\n",
        "\n",
        "1.  **Experiment with `max_length`:** Summarize `sample_long_texts[1]` (the AI text) twice:\n",
        "    * Once with a `max_length` of 30 tokens.\n",
        "    * Once with a `max_length` of 80 tokens.\n",
        "    Keep other parameters (like `num_beams`, `min_length`) consistent.\n",
        "    Print both summaries.\n",
        "2.  **Experiment with `num_beams`:** Summarize `sample_long_texts[2]` (the climate change text) twice:\n",
        "    * Once with `num_beams=1` (greedy decoding).\n",
        "    * Once with `num_beams=5` (standard beam search).\n",
        "    Keep `max_length` and `min_length` consistent.\n",
        "    Print both summaries.\n",
        "3.  **Discussion:** Based on your observations, explain how `max_length` and `num_beams` impact the generated summaries in terms of length, coherence, and overall quality.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsZmBNemyYZV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "popG9sFayYZV"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V8-vrsy0yYZV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oFMLYsCyYZV"
      },
      "source": [
        "### Question 4: Batch Summarization\n",
        "To efficiently summarize multiple documents, you can pass them as a batch to the tokenizer and then to the model.\n",
        "\n",
        "1.  **Prepare Batch Input:** Take the entire `sample_long_texts` list.\n",
        "    * **If using T5:** Prepend each text with `\"summarize: \"`.\n",
        "    Tokenize the list. Remember to set `padding=True` and `truncation=True` to handle varying lengths, and `return_tensors=\"pt\"`. Move tensors to `device`.\n",
        "2.  **Generate Batch Summaries:** Pass the batched input to `model.generate()`. Use reasonable `max_length` and `num_beams` values.\n",
        "3.  **Decode and Print:** Iterate through the generated summaries, decode each one, and print the original text alongside its corresponding summary for all documents in the batch.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A9ij2RPdyYZV"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTbmyapyyYZV"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rFQlz9OCyYZW"
      },
      "source": [
        "### Question 5: Qualitative Analysis and Limitations\n",
        "Reflect on the summaries generated by the T5/BART model.\n",
        "\n",
        "1.  **Abstractive vs. Extractive:** Based on your observations, are the summaries primarily abstractive (rewording) or extractive (copying sentences)? Provide examples.\n",
        "2.  **Quality Assessment:** Do the summaries capture the main points of the original texts? Are there any instances of factual inaccuracies (hallucinations) or grammatical errors/awkward phrasing? Discuss.\n",
        "3.  **Limitations:** What are some inherent limitations of using these pre-trained general-purpose summarization models (like T5/BART fine-tuned on CNN/DailyMail) for arbitrary text? Consider aspects like domain specificity, very long documents, or factual consistency.\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyf4in4iyYZW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5tyuE3ryYZW"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XKuniEHeyYZW"
      },
      "source": [
        "### Question 6: Potential Applications and Extensions\n",
        "1.  **Real-world Applications:** List at least three distinct real-world applications where text summarization could be highly beneficial. Explain how it would be used in each scenario.\n",
        "2.  **Model Improvements/Adaptations:** How could you potentially improve the quality of the summaries for a specific domain or use case? Consider methods beyond just adjusting `generate` parameters (e.g., fine-tuning, different models, post-processing).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "poPUNuNbyYZW"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27kggqhayYZX"
      },
      "source": [
        "## Submission Guidelines\n",
        "- Ensure your notebook runs without errors from top to bottom.\n",
        "- Save your notebook as `your_name_text_summarization_assignment.ipynb`.\n",
        "- Clearly answer all questions and provide explanations where requested in Markdown cells.\n",
        "- Feel free to add additional code cells or markdown cells for clarity or experimentation.\n",
        "\n",
        "---"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}