{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Develop Reusable Prompt Templates with Input Variables\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "4kJ6KPmFD1--"
      },
      "id": "4kJ6KPmFD1--"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment aims to teach you how to **design and implement reusable prompt templates** for Large Language Models (LLMs) using **input variables**. You will learn to create flexible prompts that can generate diverse outputs based on dynamic inputs, enhancing efficiency and consistency in LLM interactions."
      ],
      "metadata": {
        "id": "ggME3h5_D1_B"
      },
      "id": "ggME3h5_D1_B"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "8va6XUsjD1_C"
      },
      "id": "8va6XUsjD1_C"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **LLM Access**: You'll need access to an LLM for this assignment (e.g., Google's Gemini, OpenAI's GPT-4, Anthropic's Claude). You can use their web interfaces or API if you have access.\n",
        "2.  **Jupyter Notebook**: All your work, including **prompt templates**, **input variables**, **generated outputs**, **observations**, and **explanations**, must be documented in this Jupyter Notebook.\n",
        "3.  **Template Definition**: For each task, clearly define your prompt template using a placeholder notation (e.g., `{variable_name}`).\n",
        "4.  **Input Examples**: Provide at least **two different sets of input variables** for each template to demonstrate its reusability.\n",
        "5.  **Generated Output**: Copy and paste the LLM's response for each input set.\n",
        "6.  **Analysis**: Critically analyze the LLM's output for each task, discussing how the template performed and any challenges encountered.\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VERXBPF0D1_D"
      },
      "id": "VERXBPF0D1_D"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Fundamentals of Prompt Templates\n",
        "In this section, you'll create basic templates with simple variable insertion and role assignment."
      ],
      "metadata": {
        "id": "Ec_bE46kD1_E"
      },
      "id": "Ec_bE46kD1_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: Simple Variable Insertion for Content Generation\n",
        "Create a template for generating short product descriptions."
      ],
      "metadata": {
        "id": "lopdsJfSD1_E"
      },
      "id": "lopdsJfSD1_E"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Template Goal**: Generate a concise, engaging product description.\n",
        "* **Input Variables**: `{product_name}`, `{key_feature_1}`, `{key_feature_2}`, `{target_audience}`.\n",
        "* **Prompt Template Example (Your template may vary)**:\n",
        "    ```\n",
        "    \"Write a 2-3 sentence product description for a new item called '{product_name}'. Highlight its main features: '{key_feature_1}' and '{key_feature_2}'. This product is designed for '{target_audience}'.\"\n",
        "    ```"
      ],
      "metadata": {
        "id": "VOwsP8xqD1_F"
      },
      "id": "VOwsP8xqD1_F"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your prompt template string here.\n",
        "template_1_1 = \"Write a 2-3 sentence product description for a new item called '{product_name}'. Highlight its main features: '{key_feature_1}' and '{key_feature_2}'. This product is designed for '{target_audience}'.\"\n",
        "\n",
        "# --- Input Set 1 ---\n",
        "input_set_1_1 = {\n",
        "    \"product_name\": \"Eco-Smart Water Bottle\",\n",
        "    \"key_feature_1\": \"self-purifying filter\",\n",
        "    \"key_feature_2\": \"temperature insulation\",\n",
        "    \"target_audience\": \"outdoor enthusiasts and daily commuters\"\n",
        "}\n",
        "\n",
        "prompt_1_1_set_1 = template_1_1.format(**input_set_1_1)\n",
        "print(\"\\n--- Prompt for Input Set 1 ---\")\n",
        "print(prompt_1_1_set_1)\n",
        "\n",
        "# --- Input Set 2 ---\n",
        "input_set_1_2 = {\n",
        "    \"product_name\": \"Quantum Leap Gaming Headset\",\n",
        "    \"key_feature_1\": \"immersive 7.1 surround sound\",\n",
        "    \"key_feature_2\": \"customizable RGB lighting\",\n",
        "    \"target_audience\": \"competitive gamers and streamers\"\n",
        "}\n",
        "\n",
        "prompt_1_1_set_2 = template_1_1.format(**input_set_1_2)\n",
        "print(\"\\n--- Prompt for Input Set 2 ---\")\n",
        "print(prompt_1_1_set_2)\n",
        "\n",
        "\n",
        "# --- Paste LLM Responses Below ---\n",
        "\n",
        "# LLM Output for Input Set 1:\n",
        "# [Paste LLM output here]\n",
        "\n",
        "# LLM Output for Input Set 2:\n",
        "# [Paste LLM output here]"
      ],
      "outputs": [],
      "metadata": {
        "id": "t4AV9ZYND1_F"
      },
      "id": "t4AV9ZYND1_F",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 1.1:\n",
        "* Did the LLM correctly substitute all variables?\n",
        "* How well did it adhere to the length constraint (2-3 sentences)?\n",
        "* Was the generated description engaging and relevant to the target audience for both sets of inputs?"
      ],
      "metadata": {
        "id": "-2wAe6VxD1_H"
      },
      "id": "-2wAe6VxD1_H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Role/Persona-Based Template\n",
        "Create a template that assigns a persona to the LLM and asks it to generate content from that perspective."
      ],
      "metadata": {
        "id": "C7WKVnw6D1_H"
      },
      "id": "C7WKVnw6D1_H"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Template Goal**: Get the LLM to provide advice/information from a specific role.\n",
        "* **Input Variables**: `{persona}`, `{topic}`.\n",
        "* **Prompt Template Example**:\n",
        "    ```\n",
        "    \"Act as a professional {persona}. Explain the concept of {topic} to a beginner in a clear and concise manner. Keep it under 150 words.\"\n",
        "    ```"
      ],
      "metadata": {
        "id": "qH9KSgx_D1_H"
      },
      "id": "qH9KSgx_D1_H"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your prompt template string here.\n",
        "template_1_2 = \"Act as a professional {persona}. Explain the concept of {topic} to a beginner in a clear and concise manner. Keep it under 150 words.\"\n",
        "\n",
        "# --- Input Set 1 ---\n",
        "input_set_2_1 = {\n",
        "    \"persona\": \"data scientist\",\n",
        "    \"topic\": \"machine learning overfitting\"\n",
        "}\n",
        "prompt_1_2_set_1 = template_1_2.format(**input_set_2_1)\n",
        "print(\"\\n--- Prompt for Input Set 1 ---\")\n",
        "print(prompt_1_2_set_1)\n",
        "\n",
        "# --- Input Set 2 ---\n",
        "input_set_2_2 = {\n",
        "    \"persona\": \"financial advisor\",\n",
        "    \"topic\": \"compound interest\"\n",
        "}\n",
        "prompt_1_2_set_2 = template_1_2.format(**input_set_2_2)\n",
        "print(\"\\n--- Prompt for Input Set 2 ---\")\n",
        "print(prompt_1_2_set_2)\n",
        "\n",
        "\n",
        "# --- Paste LLM Responses Below ---\n",
        "\n",
        "# LLM Output for Input Set 1:\n",
        "# [Paste LLM output here]\n",
        "\n",
        "# LLM Output for Input Set 2:\n",
        "# [Paste LLM output here]"
      ],
      "outputs": [],
      "metadata": {
        "id": "JEUcjguVD1_I"
      },
      "id": "JEUcjguVD1_I",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 1.2:\n",
        "* Did the LLM successfully adopt the specified persona?\n",
        "* Was the explanation appropriate for a beginner and within the word limit?\n",
        "* Compare the tone and explanation style between the two personas."
      ],
      "metadata": {
        "id": "m5L_sy0oD1_I"
      },
      "id": "m5L_sy0oD1_I"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "S3u6KdvOD1_J"
      },
      "id": "S3u6KdvOD1_J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Advanced Template Features\n",
        "This section explores more complex template features like conditional logic and list processing."
      ],
      "metadata": {
        "id": "Gx14oH3rD1_J"
      },
      "id": "Gx14oH3rD1_J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: Conditional Logic in Templates\n",
        "Create a template that adjusts its output based on a boolean or categorical input variable."
      ],
      "metadata": {
        "id": "CWl4lDI4D1_J"
      },
      "id": "CWl4lDI4D1_J"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Template Goal**: Generate a recipe suggestion, optionally including dietary restrictions.\n",
        "* **Input Variables**: `{dish_type}`, `{main_ingredient}`, `{is_vegetarian}` (True/False).\n",
        "* **Prompt Template Example (You'll need to embed the conditional logic in how you construct the prompt string in Python)**:\n",
        "    ```\n",
        "    \"Suggest a {dish_type} recipe using {main_ingredient}.\"\n",
        "    \"[IF is_vegetarian is True] Ensure the recipe is suitable for vegetarians.\"\n",
        "    \"Provide a brief ingredient list and simple steps.\"\n",
        "    ```"
      ],
      "metadata": {
        "id": "nlpU-SAID1_J"
      },
      "id": "nlpU-SAID1_J"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your base prompt template string here.\n",
        "base_template_2_1 = \"Suggest a {dish_type} recipe using {main_ingredient}. Provide a brief ingredient list and simple steps.\"\n",
        "\n",
        "# --- Input Set 1 (Vegetarian) ---\n",
        "input_set_3_1 = {\n",
        "    \"dish_type\": \"dinner\",\n",
        "    \"main_ingredient\": \"lentils\",\n",
        "    \"is_vegetarian\": True\n",
        "}\n",
        "\n",
        "prompt_2_1_set_1 = base_template_2_1.format(dish_type=input_set_3_1['dish_type'], main_ingredient=input_set_3_1['main_ingredient'])\n",
        "if input_set_3_1['is_vegetarian']:\n",
        "    prompt_2_1_set_1 += \" Ensure the recipe is suitable for vegetarians.\"\n",
        "print(\"\\n--- Prompt for Input Set 1 (Vegetarian) ---\")\n",
        "print(prompt_2_1_set_1)\n",
        "\n",
        "# --- Input Set 2 (Non-Vegetarian) ---\n",
        "input_set_3_2 = {\n",
        "    \"dish_type\": \"lunch\",\n",
        "    \"main_ingredient\": \"chicken\",\n",
        "    \"is_vegetarian\": False\n",
        "}\n",
        "\n",
        "prompt_2_1_set_2 = base_template_2_1.format(dish_type=input_set_3_2['dish_type'], main_ingredient=input_set_3_2['main_ingredient'])\n",
        "if input_set_3_2['is_vegetarian']:\n",
        "    prompt_2_1_set_2 += \" Ensure the recipe is suitable for vegetarians.\"\n",
        "print(\"\\n--- Prompt for Input Set 2 (Non-Vegetarian) ---\")\n",
        "print(prompt_2_1_set_2)\n",
        "\n",
        "\n",
        "# --- Paste LLM Responses Below ---\n",
        "\n",
        "# LLM Output for Input Set 1 (Vegetarian):\n",
        "# [Paste LLM output here]\n",
        "\n",
        "# LLM Output for Input Set 2 (Non-Vegetarian):\n",
        "# [Paste LLM output here]"
      ],
      "outputs": [],
      "metadata": {
        "id": "23oCdPi2D1_K"
      },
      "id": "23oCdPi2D1_K",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 2.1:\n",
        "* Did the LLM correctly interpret and apply the conditional instruction (vegetarian vs. non-vegetarian)?\n",
        "* How robust is this approach for more complex conditional logic?\n",
        "* Discuss scenarios where direct string concatenation for conditionals might be cumbersome."
      ],
      "metadata": {
        "id": "9roJqgXYD1_K"
      },
      "id": "9roJqgXYD1_K"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.2: List/Iterative Content Generation\n",
        "Create a template that iterates over a list of items to generate structured content for each."
      ],
      "metadata": {
        "id": "td_B-pQ2D1_L"
      },
      "id": "td_B-pQ2D1_L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Template Goal**: Generate a brief summary/explanation for each item in a list of topics.\n",
        "* **Input Variables**: `{main_subject}`, `{topics_list}` (a Python list of strings).\n",
        "* **Prompt Template Example (You'll likely use a loop in Python to build the prompt)**:\n",
        "    ```\n",
        "    \"For the main subject '{main_subject}', provide a 1-2 sentence explanation for each of the following topics:\\n\n",
        "    - Topic 1: [Explanation]\n",
        "    - Topic 2: [Explanation]\n",
        "    ...\"\n",
        "    ```"
      ],
      "metadata": {
        "id": "h9aaPFD3D1_L"
      },
      "id": "h9aaPFD3D1_L"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your base prompt template string here.\n",
        "base_template_2_2 = \"For the main subject '{main_subject}', provide a 1-2 sentence explanation for each of the following topics:\\n{topics_formatted}\"\n",
        "\n",
        "# --- Input Set 1 ---\n",
        "input_set_4_1 = {\n",
        "    \"main_subject\": \"Artificial Intelligence\",\n",
        "    \"topics_list\": [\"Machine Learning\", \"Deep Learning\", \"Natural Language Processing\"]\n",
        "}\n",
        "\n",
        "topics_formatted_1 = \"\\n\".join([f\"- {topic}:\" for topic in input_set_4_1['topics_list']])\n",
        "prompt_2_2_set_1 = base_template_2_2.format(main_subject=input_set_4_1['main_subject'], topics_formatted=topics_formatted_1)\n",
        "print(\"\\n--- Prompt for Input Set 1 ---\")\n",
        "print(prompt_2_2_set_1)\n",
        "\n",
        "# --- Input Set 2 ---\n",
        "input_set_4_2 = {\n",
        "    \"main_subject\": \"Web Development\",\n",
        "    \"topics_list\": [\"Frontend\", \"Backend\", \"Databases\", \"APIs\"]\n",
        "}\n",
        "\n",
        "topics_formatted_2 = \"\\n\".join([f\"- {topic}:\" for topic in input_set_4_2['topics_list']])\n",
        "prompt_2_2_set_2 = base_template_2_2.format(main_subject=input_set_4_2['main_subject'], topics_formatted=topics_formatted_2)\n",
        "print(\"\\n--- Prompt for Input Set 2 ---\")\n",
        "print(prompt_2_2_set_2)\n",
        "\n",
        "\n",
        "# --- Paste LLM Responses Below ---\n",
        "\n",
        "# LLM Output for Input Set 1:\n",
        "# [Paste LLM output here]\n",
        "\n",
        "# LLM Output for Input Set 2:\n",
        "# [Paste LLM output here]"
      ],
      "outputs": [],
      "metadata": {
        "id": "HOlP4pQQD1_L"
      },
      "id": "HOlP4pQQD1_L",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 2.2:\n",
        "* Did the LLM provide a summary for each topic in the list?\n",
        "* Did it adhere to the length constraint per topic?\n",
        "* Discuss the scalability of this approach for very long lists or deeply nested structures."
      ],
      "metadata": {
        "id": "vsQIV344D1_L"
      },
      "id": "vsQIV344D1_L"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XIO6eqDTD1_M"
      },
      "id": "XIO6eqDTD1_M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Practical Application and Evaluation\n",
        "This section focuses on combining techniques and evaluating template robustness."
      ],
      "metadata": {
        "id": "vFGDYlSiD1_M"
      },
      "id": "vFGDYlSiD1_M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Building a Multi-Purpose Content Generator Template\n",
        "Combine elements from previous tasks (e.g., persona, variable insertion, optional sections) into one comprehensive template."
      ],
      "metadata": {
        "id": "tNgjjWsoD1_M"
      },
      "id": "tNgjjWsoD1_M"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Template Goal**: Generate a blog post outline or short article snippet based on audience, topic, and optional sections.\n",
        "* **Input Variables**: `{audience}`, `{article_topic}`, `{include_introduction}` (True/False), `{include_conclusion}` (True/False).\n",
        "* **Prompt Template Idea**: Structure a prompt that dynamically includes intro/conclusion paragraphs based on the boolean flags, and tailors the tone for the audience."
      ],
      "metadata": {
        "id": "sSpDLb-xD1_M"
      },
      "id": "sSpDLb-xD1_M"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define your comprehensive prompt template string here, constructing it based on variables.\n",
        "def generate_complex_prompt(audience, article_topic, include_introduction, include_conclusion):\n",
        "    prompt = f\"Generate a short article snippet or outline (approx. 200 words) about '{article_topic}' for an audience of '{audience}'.\\n\"\n",
        "    if include_introduction:\n",
        "        prompt += \"\\nInclude a brief introductory paragraph.\"\n",
        "\n",
        "    prompt += \"\\n\\nFocus on 2-3 key points relevant to this topic and audience.\\n\"\n",
        "\n",
        "    if include_conclusion:\n",
        "        prompt += \"\\nInclude a concise concluding paragraph.\"\n",
        "    return prompt\n",
        "\n",
        "# --- Input Set 1 ---\n",
        "prompt_3_1_set_1 = generate_complex_prompt(\n",
        "    audience=\"tech enthusiasts\",\n",
        "    article_topic=\"the future of quantum computing\",\n",
        "    include_introduction=True,\n",
        "    include_conclusion=False\n",
        ")\n",
        "print(\"\\n--- Prompt for Input Set 1 ---\")\n",
        "print(prompt_3_1_set_1)\n",
        "\n",
        "# --- Input Set 2 ---\n",
        "prompt_3_1_set_2 = generate_complex_prompt(\n",
        "    audience=\"small business owners\",\n",
        "    article_topic=\"digital marketing strategies\",\n",
        "    include_introduction=False,\n",
        "    include_conclusion=True\n",
        ")\n",
        "print(\"\\n--- Prompt for Input Set 2 ---\")\n",
        "print(prompt_3_1_set_2)\n",
        "\n",
        "\n",
        "# --- Paste LLM Responses Below ---\n",
        "\n",
        "# LLM Output for Input Set 1:\n",
        "# [Paste LLM output here]\n",
        "\n",
        "# LLM Output for Input Set 2:\n",
        "# [Paste LLM output here]"
      ],
      "outputs": [],
      "metadata": {
        "id": "9tSNWARND1_N"
      },
      "id": "9tSNWARND1_N",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 3.1:\n",
        "* How well did the LLM integrate all the dynamic components (audience, topic, conditional sections)?\n",
        "* Was the output consistent with the requested format and length?\n",
        "* Identify any edge cases or combinations of variables that might lead to less optimal output."
      ],
      "metadata": {
        "id": "RyGjfJUFD1_N"
      },
      "id": "RyGjfJUFD1_N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.2: Template Optimization and Debugging\n",
        "Refine a template that initially produces sub-optimal results due to ambiguity or poor phrasing. Focus on clarifying instructions or variable usage."
      ],
      "metadata": {
        "id": "LkdV3JGID1_N"
      },
      "id": "LkdV3JGID1_N"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Scenario**: You have a template for generating short social media posts, but the LLM sometimes hallucinates hashtags or doesn't match the tone.\n",
        "* **Initial Buggy Template Idea**:\n",
        "    ```\n",
        "    \"Create a social media post about {event_name} on {date}. #events\"\n",
        "    ```\n",
        "* **Steps**:\n",
        "    1.  Define an **initial \"buggy\" template** and show its output for 1-2 inputs.\n",
        "    2.  Analyze why it's \"buggy\" (e.g., tone incorrect, irrelevant hashtags, missing key info).\n",
        "    3.  **Propose and implement a refined template** that addresses the issues (e.g., add explicit tone instructions, specific hashtag guidance, more variables for key details).\n",
        "    4.  Show the output of the refined template with the same inputs.\n",
        "* **Analysis**:\n",
        "    * What specific changes did you make to the template?\n",
        "    * How did these changes improve the output quality?\n",
        "    * Discuss the importance of clear, unambiguous instructions and variable definitions in templates."
      ],
      "metadata": {
        "id": "AwDD3N6KD1_N"
      },
      "id": "AwDD3N6KD1_N"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Initial Buggy Template ---\n",
        "buggy_template = \"Create a social media post about {event_name} happening on {event_date}. #events\"\n",
        "\n",
        "buggy_input = {\"event_name\": \"Local Tech Meetup\", \"event_date\": \"July 15th\"}\n",
        "print(\"\\n--- Buggy Prompt Example ---\")\n",
        "print(buggy_template.format(**buggy_input))\n",
        "\n",
        "# LLM Output (Buggy): [Paste LLM output here]\n",
        "\n",
        "# --- Analysis of Buggy Template ---\n",
        "# [Explain why it's buggy]\n",
        "\n",
        "# --- Refined Template ---\n",
        "refined_template = \"Create a concise social media post (max 280 chars) for {event_name} happening on {event_date}.\\nDescribe the event's main highlight: '{event_highlight}'.\\nInclude 2-3 relevant and specific hashtags. The tone should be enthusiastic and informative.\\nExample: 'Join us for an amazing event! #TechMeetup #Innovation'\"\n",
        "\n",
        "refined_input = {\n",
        "    \"event_name\": \"Local Tech Meetup\",\n",
        "    \"event_date\": \"July 15th\",\n",
        "    \"event_highlight\": \"networking with industry leaders\"\n",
        "}\n",
        "print(\"\\n--- Refined Prompt Example ---\")\n",
        "print(refined_template.format(**refined_input))\n",
        "\n",
        "# LLM Output (Refined): [Paste LLM output here]\n",
        "\n",
        "# --- Analysis of Refined Template ---\n",
        "# [Explain the improvements]"
      ],
      "outputs": [],
      "metadata": {
        "id": "XkxS3tnGD1_O"
      },
      "id": "XkxS3tnGD1_O",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "XS0OjfJ1D1_O"
      },
      "id": "XS0OjfJ1D1_O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Conclusion and Reflection\n",
        "In this markdown cell, provide a comprehensive summary of your findings and reflections based on this assignment."
      ],
      "metadata": {
        "id": "Y7SSardAD1_O"
      },
      "id": "Y7SSardAD1_O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Benefits of Prompt Templates**: Summarize the key advantages of using reusable prompt templates with variables.\n",
        "* **Challenges in Template Design**: What were the most significant challenges you faced when designing or debugging your templates?\n",
        "* **Best Practices for Variable-Driven Prompts**: Based on your experience, what are your top 3-5 best practices for creating effective prompt templates with input variables?\n",
        "* **Future Applications**: How do you envision these templating techniques being used in real-world LLM applications?\n",
        "* **Ethical Considerations**: Are there any ethical implications or biases that could be amplified or mitigated through careful template design?"
      ],
      "metadata": {
        "id": "Ys4QJJc-D1_O"
      },
      "id": "Ys4QJJc-D1_O"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "9aFMmNrbD1_P"
      },
      "id": "9aFMmNrbD1_P"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission:\n",
        "* Ensure all code cells have been executed and their outputs are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Save your Jupyter Notebook as `[YourName]_PromptTemplates_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "qXTbbx27D1_P"
      },
      "id": "qXTbbx27D1_P"
    }
  ]
}