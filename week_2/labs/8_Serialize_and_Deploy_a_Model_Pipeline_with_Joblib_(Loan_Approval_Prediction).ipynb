{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸŽ¯ Objective:\n",
        "Train a model to predict loan approval (binary classification).\n",
        "\n",
        "Create a pipeline with preprocessing and modeling.\n",
        "\n",
        "Serialize using joblib, load the model, and simulate deployment"
      ],
      "metadata": {
        "id": "YfmMoDRlcFP3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“Œ Dataset Used:\n",
        "We'll use the Loan Prediction Dataset (preprocessed) available via a public URL.\n",
        "\n"
      ],
      "metadata": {
        "id": "7Z5Pb-FWcIRe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#âœ… Step-by-Step Practical"
      ],
      "metadata": {
        "id": "gYbBW31pcK0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”§ Step 0: Install Required Libraries"
      ],
      "metadata": {
        "id": "iQn7OA-4cPD5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 0: Setup Google Colab Environment\n",
        "!pip install scikit-learn pandas numpy matplotlib seaborn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKBf6dbkbYwS",
        "outputId": "39138a9f-75ec-4988-f0fc-5edb84e524c0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.10.0)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.3)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.1)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.58.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.2.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“¥ Step 1: Create a Synthetic Loan Application Dataset\n",
        "\n",
        "We'll generate a simple dataset to simulate loan application features and an approval status."
      ],
      "metadata": {
        "id": "o8naMN4IcVfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Create a Synthetic Loan Application Dataset\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Set a random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "# Number of samples\n",
        "n_samples = 1000\n",
        "\n",
        "# Generate synthetic data\n",
        "data = {\n",
        "    'ApplicantIncome': np.random.randint(20000, 100000, n_samples),\n",
        "    'LoanAmount': np.random.randint(50000, 500000, n_samples),\n",
        "    'CreditHistory': np.random.choice([0, 1], n_samples, p=[0.2, 0.8]), # 1 for good, 0 for bad\n",
        "    'Education': np.random.choice(['Graduate', 'Not Graduate'], n_samples),\n",
        "    'SelfEmployed': np.random.choice(['Yes', 'No'], n_samples),\n",
        "    'PropertyArea': np.random.choice(['Urban', 'Semiurban', 'Rural'], n_samples)\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n"
      ],
      "metadata": {
        "id": "6y6TLdk0bdpi"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a target variable 'Loan_Status'\n",
        "# Simple rule: Good credit history + high income + low loan amount -> higher chance of approval\n",
        "df['Loan_Status'] = 0 # Default to Not Approved\n",
        "\n",
        "# Rule 1: Good credit history + high income + reasonable loan\n",
        "df.loc[(df['CreditHistory'] == 1) &\n",
        "       (df['ApplicantIncome'] > 40000) &\n",
        "       (df['LoanAmount'] < 300000), 'Loan_Status'] = 1\n",
        "\n",
        "# Rule 2: Self-employed graduates with good credit history and moderate loan\n",
        "df.loc[(df['CreditHistory'] == 1) &\n",
        "       (df['Education'] == 'Graduate') &\n",
        "       (df['SelfEmployed'] == 'Yes') &\n",
        "       (df['LoanAmount'] < 200000), 'Loan_Status'] = 1\n",
        "\n"
      ],
      "metadata": {
        "id": "Lyu83tPWeK5s"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Introduce some noise/exceptions\n",
        "noise_indices = np.random.choice(df.index, size=int(n_samples * 0.1), replace=False)\n",
        "df.loc[noise_indices, 'Loan_Status'] = 1 - df.loc[noise_indices, 'Loan_Status'] # Flip status for 10%\n",
        "\n",
        "print(\"Synthetic Loan Application Dataset Head:\")\n",
        "print(df.head())\n",
        "print(\"\\nLoan Status Distribution:\")\n",
        "print(df['Loan_Status'].value_counts())\n",
        "print(\"\\nDataset Info:\")\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eXFXmvAGeM1M",
        "outputId": "22bd3b5a-8bbc-46fc-92bd-c1e8b0867ff3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Synthetic Loan Application Dataset Head:\n",
            "   ApplicantIncome  LoanAmount  CreditHistory     Education SelfEmployed  \\\n",
            "0            35795      289690              1  Not Graduate          Yes   \n",
            "1            20860      189649              1  Not Graduate          Yes   \n",
            "2            96820       58070              1  Not Graduate           No   \n",
            "3            74886      176161              1  Not Graduate          Yes   \n",
            "4            26265       58666              0      Graduate          Yes   \n",
            "\n",
            "  PropertyArea  Loan_Status  \n",
            "0        Urban            0  \n",
            "1        Rural            1  \n",
            "2        Rural            1  \n",
            "3        Rural            1  \n",
            "4        Rural            1  \n",
            "\n",
            "Loan Status Distribution:\n",
            "Loan_Status\n",
            "0    629\n",
            "1    371\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Dataset Info:\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 7 columns):\n",
            " #   Column           Non-Null Count  Dtype \n",
            "---  ------           --------------  ----- \n",
            " 0   ApplicantIncome  1000 non-null   int64 \n",
            " 1   LoanAmount       1000 non-null   int64 \n",
            " 2   CreditHistory    1000 non-null   int64 \n",
            " 3   Education        1000 non-null   object\n",
            " 4   SelfEmployed     1000 non-null   object\n",
            " 5   PropertyArea     1000 non-null   object\n",
            " 6   Loan_Status      1000 non-null   int64 \n",
            "dtypes: int64(4), object(3)\n",
            "memory usage: 54.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ“‚ Step 2: Build a Machine Learning Pipeline\n",
        "We'll build a scikit-learn pipeline that includes preprocessing steps for categorical features and a classifier."
      ],
      "metadata": {
        "id": "5hKxZ2t1caAB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Build a Machine Learning Pipeline\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "import joblib # For serialization\n",
        "\n",
        "# Define features (X) and target (y)\n",
        "X = df.drop('Loan_Status', axis=1)\n",
        "y = df['Loan_Status']\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "AzL4Byn1beyK"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Identify numerical and categorical features\n",
        "numerical_features = X.select_dtypes(include=np.number).columns\n",
        "categorical_features = X.select_dtypes(include='object').columns\n",
        "\n",
        "print(f\"\\nNumerical Features: {list(numerical_features)}\")\n",
        "print(f\"Categorical Features: {list(categorical_features)}\")\n",
        "\n",
        "# Create preprocessing pipelines for numerical and categorical features\n",
        "numerical_transformer = StandardScaler() # Scale numerical features\n",
        "categorical_transformer = OneHotEncoder(handle_unknown='ignore') # One-hot encode categorical features\n",
        "\n",
        "# Create a preprocessor using ColumnTransformer\n",
        "# This allows applying different transformers to different columns\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numerical_transformer, numerical_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ikDoKjiLeP0I",
        "outputId": "98d63cc8-089a-4c74-caf4-a6342b0eeb37"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Numerical Features: ['ApplicantIncome', 'LoanAmount', 'CreditHistory']\n",
            "Categorical Features: ['Education', 'SelfEmployed', 'PropertyArea']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the full pipeline: Preprocessing -> Model\n",
        "# For this example, we use Logistic Regression\n",
        "model_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n",
        "                                 ('classifier', LogisticRegression(solver='liblinear', random_state=42))])\n",
        "\n",
        "print(\"\\nMachine Learning Pipeline created successfully.\")\n",
        "print(model_pipeline)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Train the pipeline\n",
        "print(\"\\nTraining the model pipeline...\")\n",
        "model_pipeline.fit(X_train, y_train)\n",
        "print(\"Model pipeline training complete.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vF4FsPrHeDs8",
        "outputId": "26edb55c-1c62-4879-9125-39885da1d2fd"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Machine Learning Pipeline created successfully.\n",
            "Pipeline(steps=[('preprocessor',\n",
            "                 ColumnTransformer(transformers=[('num', StandardScaler(),\n",
            "                                                  Index(['ApplicantIncome', 'LoanAmount', 'CreditHistory'], dtype='object')),\n",
            "                                                 ('cat',\n",
            "                                                  OneHotEncoder(handle_unknown='ignore'),\n",
            "                                                  Index(['Education', 'SelfEmployed', 'PropertyArea'], dtype='object'))])),\n",
            "                ('classifier',\n",
            "                 LogisticRegression(random_state=42, solver='liblinear'))])\n",
            "\n",
            "Training the model pipeline...\n",
            "Model pipeline training complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluate the pipeline (optional, but good practice)\n",
        "y_pred = model_pipeline.predict(X_test)\n",
        "print(f\"\\nPipeline Accuracy on Test Set: {accuracy_score(y_test, y_pred):.4f}\")\n",
        "print(\"\\nClassification Report on Test Set:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ieyMX9zLeFNi",
        "outputId": "f597ca93-3779-467c-c306-79cca4cf9a44"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Pipeline Accuracy on Test Set: 0.8750\n",
            "\n",
            "Classification Report on Test Set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.87      0.94      0.90       126\n",
            "           1       0.88      0.77      0.82        74\n",
            "\n",
            "    accuracy                           0.88       200\n",
            "   macro avg       0.88      0.85      0.86       200\n",
            "weighted avg       0.88      0.88      0.87       200\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Serialize (Save) the Model Pipeline with joblib\n",
        "Saving the entire trained pipeline ensures that both the preprocessing logic and the trained model weights are preserved."
      ],
      "metadata": {
        "id": "8vymuFOadrc7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Serialize (Save) the Model Pipeline with joblib\n",
        "\n",
        "# Define the filename for the saved pipeline\n",
        "pipeline_filename = 'loan_approval_pipeline.pkl'\n",
        "\n",
        "# Save the trained pipeline to a file using joblib.dump()\n",
        "joblib.dump(model_pipeline, pipeline_filename)\n",
        "\n",
        "print(f\"\\nModel pipeline successfully serialized and saved as '{pipeline_filename}'\")\n",
        "print(\"You can verify its presence in the Colab file browser (left sidebar).\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NqAaDm8qbory",
        "outputId": "5ac78302-da97-4b0a-ae3f-3294edf1a4eb"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model pipeline successfully serialized and saved as 'loan_approval_pipeline.pkl'\n",
            "You can verify its presence in the Colab file browser (left sidebar).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Deploy (Load and Use) the Model Pipeline\n",
        "This step simulates the \"deployment\" scenario. We'll load the saved pipeline and use it to make predictions on new, unseen loan applications."
      ],
      "metadata": {
        "id": "ZNKr_jKjdxZa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Deploy (Load and Use) the Model Pipeline\n",
        "\n",
        "# Define the filename of the saved pipeline\n",
        "pipeline_filename = 'loan_approval_pipeline.pkl'\n",
        "\n",
        "# Load the serialized pipeline using joblib.load()\n",
        "try:\n",
        "    loaded_pipeline = joblib.load(pipeline_filename)\n",
        "    print(f\"\\nModel pipeline successfully loaded from '{pipeline_filename}'\")\n",
        "except FileNotFoundError:\n",
        "    print(f\"Error: Pipeline file '{pipeline_filename}' not found. Make sure Step 3 was executed.\")\n",
        "    loaded_pipeline = None # Set to None to prevent errors later\n",
        "\n",
        "if loaded_pipeline:\n",
        "    # Simulate new, unseen loan application data\n",
        "    # IMPORTANT: The columns and their order must match the training data\n",
        "    new_loan_applicants = pd.DataFrame({\n",
        "        'ApplicantIncome': [60000, 35000, 80000, 25000],\n",
        "        'LoanAmount': [200000, 100000, 450000, 70000],\n",
        "        'CreditHistory': [1, 0, 1, 1],\n",
        "        'Education': ['Graduate', 'Not Graduate', 'Graduate', 'Graduate'],\n",
        "        'SelfEmployed': ['No', 'Yes', 'No', 'No'],\n",
        "        'PropertyArea': ['Urban', 'Rural', 'Semiurban', 'Urban']\n",
        "    })\n",
        "\n",
        "    print(\"\\nNew Loan Applicants Data:\")\n",
        "    print(new_loan_applicants)\n",
        "\n",
        "# Make predictions using the loaded pipeline\n",
        "    # The pipeline automatically handles preprocessing of new_loan_applicants\n",
        "    # before feeding it to the classifier.\n",
        "    predictions = loaded_pipeline.predict(new_loan_applicants)\n",
        "    prediction_probabilities = loaded_pipeline.predict_proba(new_loan_applicants)\n",
        "\n",
        "    # Map numerical predictions to meaningful labels\n",
        "    loan_status_map = {0: 'Not Approved', 1: 'Approved'}\n",
        "    predicted_statuses = [loan_status_map[pred] for pred in predictions]\n",
        "\n",
        "    print(\"\\nLoan Approval Predictions for New Applicants:\")\n",
        "    for i, status in enumerate(predicted_statuses):\n",
        "        applicant_income = new_loan_applicants.iloc[i]['ApplicantIncome']\n",
        "        loan_amount = new_loan_applicants.iloc[i]['LoanAmount']\n",
        "        prob_not_approved = prediction_probabilities[i][0] * 100\n",
        "        prob_approved = prediction_probabilities[i][1] * 100\n",
        "\n",
        "        print(f\"  Applicant {i+1} (Income: {applicant_income}, Loan: {loan_amount}):\")\n",
        "        print(f\"    -> Predicted Status: {status}\")\n",
        "        print(f\"    -> Probability (Not Approved): {prob_not_approved:.2f}%\")\n",
        "        print(f\"    -> Probability (Approved): {prob_approved:.2f}%\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilkATb3vdqn4",
        "outputId": "28a65d80-0f77-40bb-8862-2548ead9acac"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model pipeline successfully loaded from 'loan_approval_pipeline.pkl'\n",
            "\n",
            "New Loan Applicants Data:\n",
            "   ApplicantIncome  LoanAmount  CreditHistory     Education SelfEmployed  \\\n",
            "0            60000      200000              1      Graduate           No   \n",
            "1            35000      100000              0  Not Graduate          Yes   \n",
            "2            80000      450000              1      Graduate           No   \n",
            "3            25000       70000              1      Graduate           No   \n",
            "\n",
            "  PropertyArea  \n",
            "0        Urban  \n",
            "1        Rural  \n",
            "2    Semiurban  \n",
            "3        Urban  \n",
            "\n",
            "Loan Approval Predictions for New Applicants:\n",
            "  Applicant 1 (Income: 60000, Loan: 200000):\n",
            "    -> Predicted Status: Approved\n",
            "    -> Probability (Not Approved): 39.08%\n",
            "    -> Probability (Approved): 60.92%\n",
            "  Applicant 2 (Income: 35000, Loan: 100000):\n",
            "    -> Predicted Status: Not Approved\n",
            "    -> Probability (Not Approved): 71.52%\n",
            "    -> Probability (Approved): 28.48%\n",
            "  Applicant 3 (Income: 80000, Loan: 450000):\n",
            "    -> Predicted Status: Not Approved\n",
            "    -> Probability (Not Approved): 90.39%\n",
            "    -> Probability (Approved): 9.61%\n",
            "  Applicant 4 (Income: 25000, Loan: 70000):\n",
            "    -> Predicted Status: Approved\n",
            "    -> Probability (Not Approved): 25.40%\n",
            "    -> Probability (Approved): 74.60%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-CpUlclpeTF4"
      },
      "execution_count": 13,
      "outputs": []
    }
  ]
}