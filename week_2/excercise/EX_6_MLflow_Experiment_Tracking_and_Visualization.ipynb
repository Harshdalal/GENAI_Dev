{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_dUwPFWmTBQ"
      },
      "source": [
        "# Python Assignment: MLflow Experiment Tracking and Visualization\n",
        "\n",
        "This assignment will challenge you to effectively use MLflow for tracking your machine learning experiments. You'll learn to log parameters, metrics, and models, manage different runs, and visualize their performance to make informed decisions about your models. This is a critical skill for MLOps and reproducible machine learning."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "naDW8NhXmTBS"
      },
      "source": [
        "## Part 1: Setup and Basic MLflow Tracking (30 points)\n",
        "\n",
        "In this part, you will set up your environment, generate a dataset, train a simple model, and perform basic MLflow logging."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7odGSYdcmTBS"
      },
      "outputs": [],
      "source": [
        "# 1.1 Install MLflow and other necessary libraries\n",
        "# Run this cell once to ensure you have the required packages.\n",
        "# !pip install mlflow scikit-learn pandas matplotlib\n",
        "\n",
        "import mlflow\n",
        "import mlflow.sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\") # Suppress warnings for cleaner output\n",
        "np.random.seed(42)\n",
        "\n",
        "# 1.2 Generate a Synthetic Dataset\n",
        "#    Create a synthetic regression dataset.\n",
        "#    - `n_samples`: 1000\n",
        "#    - `n_features`: 5 (3 informative, 2 noisy)\n",
        "#    Use `sklearn.datasets.make_regression` for this.\n",
        "\n",
        "from sklearn.datasets import make_regression\n",
        "\n",
        "X, y = make_regression(\n",
        "    # Your parameters here\n",
        ")\n",
        "\n",
        "print(f\"Dataset X shape: {X.shape}, y shape: {y.shape}\")\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# 1.3 Basic MLflow Tracking for a Linear Regression Model\n",
        "#    Train a `LinearRegression` model.\n",
        "#    Use `mlflow.start_run()` to create a new MLflow run.\n",
        "#    Inside the run:\n",
        "#    - Log parameters: `fit_intercept` (True/False).\n",
        "#    - Calculate and log metrics: `rmse` and `r2_score` on the test set.\n",
        "#    - Log the trained `LinearRegression` model using `mlflow.sklearn.log_model()`.\n",
        "#    - Set a run tag, e.g., `mlflow.set_tag(\"model_type\", \"LinearRegression\")`.\n",
        "\n",
        "print(\"\\n--- Running Linear Regression Experiment ---\")\n",
        "with mlflow.start_run(run_name=\"Linear_Regression_Run\") as run:\n",
        "    # Get run_id for later reference\n",
        "    linear_regression_run_id = run.info.run_id\n",
        "    print(f\"MLflow Run ID: {linear_regression_run_id}\")\n",
        "\n",
        "    # TODO: Initialize and train LinearRegression model\n",
        "    lr_model = # Your LinearRegression model here\n",
        "\n",
        "    # TODO: Log parameters (e.g., fit_intercept)\n",
        "    # mlflow.log_param(\"fit_intercept\", lr_model.fit_intercept)\n",
        "\n",
        "    # TODO: Make predictions and calculate metrics\n",
        "    lr_predictions = # Your predictions here\n",
        "    lr_rmse = # Calculate RMSE\n",
        "    lr_r2 = # Calculate R2 Score\n",
        "\n",
        "    # TODO: Log metrics\n",
        "    # mlflow.log_metric(\"rmse\", lr_rmse)\n",
        "    # mlflow.log_metric(\"r2_score\", lr_r2)\n",
        "\n",
        "    # TODO: Log the model\n",
        "    # mlflow.sklearn.log_model(lr_model, \"linear_regression_model\")\n",
        "\n",
        "    # TODO: Set a run tag\n",
        "    # mlflow.set_tag(\"model_type\", \"LinearRegression\")\n",
        "\n",
        "    print(f\"  RMSE: {lr_rmse:.4f}\")\n",
        "    print(f\"  R2 Score: {lr_r2:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SI8PumcUmTBT"
      },
      "source": [
        "## Part 2: Advanced MLflow Tracking & Experiment Management (40 points)\n",
        "\n",
        "Now, you'll perform a more complex experiment, track more details, and manage experiments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07989imymTBU"
      },
      "outputs": [],
      "source": [
        "# 2.1 Set up a new MLflow Experiment\n",
        "#    Use `mlflow.set_experiment()` to create or set a new experiment named \"RandomForest_Experiments\".\n",
        "\n",
        "# TODO: Set the experiment name\n",
        "# mlflow.set_experiment(\"RandomForest_Experiments\")\n",
        "\n",
        "print(\"\\n--- Running RandomForest Experiments ---\")\n",
        "\n",
        "# 2.2 Track Multiple Runs with Different Hyperparameters\n",
        "#    Perform at least 3 runs for a `RandomForestRegressor` model.\n",
        "#    For each run:\n",
        "#    - Vary at least 2 hyperparameters (e.g., `n_estimators`, `max_depth`).\n",
        "#    - Use `mlflow.start_run()` with a meaningful `run_name` (e.g., \"RF_Run_1_Estimators_100\").\n",
        "#    - Log all chosen hyperparameters using `mlflow.log_param()`.\n",
        "#    - Calculate and log `rmse` and `r2_score`.\n",
        "#    - Log the trained model.\n",
        "#    - **Log an artifact:** Create a simple scatter plot of `y_test` vs `predictions` and save it as a PNG file.\n",
        "#      Then, log this PNG file as an artifact using `mlflow.log_artifact()`.\n",
        "#      (Hint: `plt.savefig('predictions_plot.png')` then `mlflow.log_artifact('predictions_plot.png')`)\n",
        "\n",
        "rf_params_list = [\n",
        "    {\"n_estimators\": 50, \"max_depth\": 5},\n",
        "    {\"n_estimators\": 100, \"max_depth\": 10},\n",
        "    {\"n_estimators\": 150, \"max_depth\": 15}\n",
        "]\n",
        "\n",
        "for i, params in enumerate(rf_params_list):\n",
        "    run_name = f\"RF_Run_{i+1}_N{params['n_estimators']}_D{params['max_depth']}\"\n",
        "    print(f\"Starting run: {run_name}\")\n",
        "\n",
        "    with mlflow.start_run(run_name=run_name):\n",
        "        # TODO: Log params\n",
        "        # mlflow.log_params(params)\n",
        "\n",
        "        # TODO: Initialize and train RandomForestRegressor\n",
        "        rf_model = # Your RandomForestRegressor model here\n",
        "\n",
        "        # TODO: Make predictions and calculate metrics\n",
        "        rf_predictions = # Your predictions here\n",
        "        rf_rmse = # Calculate RMSE\n",
        "        rf_r2 = # Calculate R2 Score\n",
        "\n",
        "        # TODO: Log metrics\n",
        "        # mlflow.log_metric(\"rmse\", rf_rmse)\n",
        "        # mlflow.log_metric(\"r2_score\", rf_r2)\n",
        "\n",
        "        # TODO: Log the model\n",
        "        # mlflow.sklearn.log_model(rf_model, \"random_forest_model\")\n",
        "\n",
        "        # TODO: Create and log scatter plot as an artifact\n",
        "        # fig, ax = plt.subplots()\n",
        "        # ax.scatter(y_test, rf_predictions)\n",
        "        # ax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=2)\n",
        "        # ax.set_xlabel('Actual')\n",
        "        # ax.set_ylabel('Predicted')\n",
        "        # ax.set_title(f'Actual vs. Predicted for {run_name}')\n",
        "        # plt.savefig(\"predictions_plot.png\")\n",
        "        # mlflow.log_artifact(\"predictions_plot.png\")\n",
        "        # plt.close(fig) # Close the plot to free memory\n",
        "\n",
        "        print(f\"  RMSE: {rf_rmse:.4f}\")\n",
        "        print(f\"  R2 Score: {rf_r2:.4f}\")\n",
        "\n",
        "# 2.3 (Bonus) Demonstrate mlflow.autolog()\n",
        "#    Choose one more model (e.g., another RandomForestRegressor or a different type).\n",
        "#    Enable `mlflow.sklearn.autolog()` before training.\n",
        "#    Observe what parameters and metrics are automatically logged without explicit `mlflow.log_param` or `mlflow.log_metric` calls.\n",
        "\n",
        "print(\"\\n--- Running AutoLog Experiment ---\")\n",
        "mlflow.sklearn.autolog(disable=False) # Enable autologging\n",
        "\n",
        "with mlflow.start_run(run_name=\"AutoLog_RandomForest_Run\"):\n",
        "    # TODO: Train a RandomForestRegressor without explicit logging\n",
        "    autolog_rf_model = # Your RandomForestRegressor model here\n",
        "    autolog_rf_predictions = # Your predictions here\n",
        "    autolog_rf_rmse = # Calculate RMSE\n",
        "    autolog_rf_r2 = # Calculate R2 Score\n",
        "\n",
        "    print(f\"  RMSE (Autolog): {autolog_rf_rmse:.4f}\")\n",
        "    print(f\"  R2 Score (Autolog): {autolog_rf_r2:.4f}\")\n",
        "\n",
        "mlflow.sklearn.autolog(disable=True) # Disable autologging after the run\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8nKFPHepmTBU"
      },
      "source": [
        "## Part 3: Model Versioning and Comparison (20 points)\n",
        "\n",
        "In this section, you'll interact with the MLflow UI and demonstrate loading a logged model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQn-SLSnmTBV"
      },
      "source": [
        "**3.1 Explore MLflow UI**\n",
        "\n",
        "Open your terminal or command prompt, navigate to the directory where this notebook is saved, and run the MLflow UI:\n",
        "\n",
        "```bash\n",
        "mlflow ui\n",
        "```\n",
        "\n",
        "This will launch a local web server (usually at `http://localhost:5000`). Navigate to this URL in your web browser.\n",
        "\n",
        "**In the MLflow UI, perform the following and take screenshots (or describe them in the reflection):**\n",
        "-   Navigate between the \"Default\" experiment and your \"RandomForest_Experiments\".\n",
        "-   Compare the runs within \"RandomForest_Experiments\" based on `rmse` and `r2_score`.\n",
        "-   Examine the logged parameters and artifacts for a specific run (e.g., your `predictions_plot.png`).\n",
        "\n",
        "**3.2 Load and Use a Logged Model**\n",
        "\n",
        "Pick the `run_id` of your best performing `RandomForestRegressor` run from the MLflow UI. Use this `run_id` to load the corresponding model and make a prediction on a new data point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8m7HolcBmTBV"
      },
      "outputs": [],
      "source": [
        "# TODO: Replace 'YOUR_BEST_RF_RUN_ID' with the actual run_id from the MLflow UI\n",
        "best_rf_run_id = \"YOUR_BEST_RF_RUN_ID\"\n",
        "\n",
        "print(f\"\\n--- Loading Model from Run ID: {best_rf_run_id} ---\")\n",
        "\n",
        "try:\n",
        "    # TODO: Load the model using mlflow.pyfunc.load_model() or mlflow.sklearn.load_model()\n",
        "    # Example: loaded_model = mlflow.pyfunc.load_model(f\"runs/{best_rf_run_id}/artifacts/random_forest_model\")\n",
        "    loaded_model = # Your model loading code here\n",
        "\n",
        "    # Create a dummy new data point for prediction (must have same number of features as training data)\n",
        "    new_data_point = np.array([[0.5, -0.2, 1.3, 0.1, -0.8]]) # Example, adjust based on your features\n",
        "\n",
        "    # Make a prediction with the loaded model\n",
        "    prediction = loaded_model.predict(new_data_point)\n",
        "\n",
        "    print(f\"Prediction for new data point {new_data_point[0]}: {prediction[0]:.2f}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading or predicting with model: {e}\")\n",
        "    print(\"Please ensure 'YOUR_BEST_RF_RUN_ID' is correct and the artifact path is valid.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc-M_c_cmTBV"
      },
      "source": [
        "## Part 4: Reflection & Discussion (10 points)\n",
        "\n",
        "Answer the following questions in a markdown cell below."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GM7VI65UmTBV"
      },
      "source": [
        "### Your Answers to Reflection Questions:\n",
        "\n",
        "1.  **What are the primary benefits of using MLflow for experiment tracking compared to manual tracking (e.g., using spreadsheets or custom logs)?** (List at least 3 benefits)\n",
        "\n",
        "2.  **Describe one challenge you faced or can foresee facing when using MLflow in a larger, more complex machine learning project.**\n",
        "\n",
        "3.  **How can MLflow contribute to the reproducibility of machine learning experiments?**\n",
        "\n",
        "4.  **Briefly explain when you might use `mlflow.log_param()`, `mlflow.log_metric()`, and `mlflow.log_artifact()` in a typical ML workflow.**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gRb7ZrdmTBW"
      },
      "source": [
        "## Deliverables:\n",
        "\n",
        "1.  This completed Jupyter Notebook (`mlflow_experiment_tracking_assignment.ipynb`) with all code cells executed and reflection questions answered.\n",
        "2.  Screenshots (or detailed descriptions in your reflection) from the MLflow UI demonstrating comparison of runs and examination of artifacts."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}