{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Build a Long-Running Summarization + Citation Agent Loop\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Hw_vlh_bfcSQ"
      },
      "id": "Hw_vlh_bfcSQ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment challenges you to build a **long-running agent loop** that can continuously process new information, summarize it, and critically, **provide citations for the summarized content**. This simulates a real-world scenario where an AI needs to act as a research assistant, continuously ingesting data and providing attributed insights. You'll focus on designing the prompt engineering for summarization and citation, as well as managing the loop for continuous processing."
      ],
      "metadata": {
        "id": "iT5eoFUjfcSS"
      },
      "id": "iT5eoFUjfcSS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "UZfYi8a4fcSS"
      },
      "id": "UZfYi8a4fcSS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **LLM Access**: You'll need access to an LLM API. **OpenAI's models (e.g., GPT-4o, GPT-4, GPT-3.5-turbo)** are recommended for their strong summarization and instruction-following capabilities. Configure your API key securely (e.g., via environment variables).\n",
        "2.  **Environment Setup**: Install necessary Python libraries: `pip install openai python-dotenv`.\n",
        "3.  **Simulated Data Source**: You'll simulate a stream of 'new' articles or documents, each with content and a source/URL. This will be a simple Python list of dictionaries.\n",
        "4.  **Agent Loop**: The core of the assignment is a loop that:\n",
        "    * Picks a new document from your simulated stream.\n",
        "    * Sends its content to the LLM for summarization and citation extraction.\n",
        "    * Stores the summary and citation.\n",
        "    * Can be stopped by a specific command or after processing all available documents.\n",
        "5.  **Prompt Engineering**: Design a robust prompt that guides the LLM to:\n",
        "    * Summarize the provided text concisely.\n",
        "    * Explicitly cite the source (URL/title) provided with the text.\n",
        "    * Handle cases where information might be missing or incomplete.\n",
        "6.  **Jupyter Notebook**: All your code, outputs, observations, and analysis must be documented in this Jupyter Notebook.\n",
        "7.  **Analysis**: Explain your prompt design, the loop mechanism, and the challenges of ensuring accurate citations."
      ],
      "metadata": {
        "id": "P-cNC2plfcST"
      },
      "id": "P-cNC2plfcST"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "eVSS6Q6qfcST"
      },
      "id": "eVSS6Q6qfcST"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and LLM Configuration\n",
        "Begin by setting up your environment and configuring your LLM."
      ],
      "metadata": {
        "id": "emOoMysWfcST"
      },
      "id": "emOoMysWfcST"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: Install Libraries and Configure LLM\n",
        "Install `openai` and `python-dotenv`. Set up your OpenAI API key from environment variables."
      ],
      "metadata": {
        "id": "XLPPFKdPfcSU"
      },
      "id": "XLPPFKdPfcSU"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "# !pip install openai python-dotenv --quiet\n",
        "\n",
        "import openai\n",
        "import os\n",
        "import asyncio\n",
        "import time\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# --- IMPORTANT: Create a .env file in the same directory as this notebook with the line: ---\n",
        "# OPENAI_API_KEY=\"YOUR_OPENAI_API_KEY_HERE\"\n",
        "\n",
        "# Configure OpenAI API key\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if not openai.api_key:\n",
        "    print(\"WARNING: OPENAI_API_KEY not found in environment variables. Please set it in .env file.\")\n",
        "else:\n",
        "    print(\"OpenAI API key loaded!\")\n",
        "\n",
        "# Define the LLM model to use\n",
        "LLM_MODEL = \"gpt-3.5-turbo\" # You can use \"gpt-4o\", \"gpt-4\", etc. if you have access\n",
        "\n",
        "print(f\"Using LLM Model: {LLM_MODEL}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "QFavd076fcSU"
      },
      "id": "QFavd076fcSU",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Simulate a Stream of Articles\n",
        "Create a list of dictionaries, where each dictionary represents an article with `title`, `url`, and `content`. This will act as your continuous data source."
      ],
      "metadata": {
        "id": "KPf1YrWHfcSV"
      },
      "id": "KPf1YrWHfcSV"
    },
    {
      "cell_type": "code",
      "source": [
        "article_stream = [\n",
        "    {\n",
        "        \"id\": 1,\n",
        "        \"title\": \"Quantum Computing Breakthrough\",\n",
        "        \"url\": \"https://example.com/quantum-breakthrough\",\n",
        "        \"content\": \"Scientists at Quantum Labs have announced a significant breakthrough in quantum entanglement, achieving stable qubits for over 10 minutes. This could pave the way for more powerful quantum computers, moving beyond the current limitations of decoherence. The research paper, published in 'Nature Physics', details their novel method of using cryogenic chambers and magnetic shielding to maintain qubit integrity. This advancement is crucial for error correction and scaling quantum systems.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 2,\n",
        "        \"title\": \"New AI Model for Drug Discovery\",\n",
        "        \"url\": \"https://example.com/ai-drug-discovery\",\n",
        "        \"content\": \"AlphaMolecule, a new AI model developed by BioGen AI, has shown promising results in accelerating drug discovery. The model can predict molecular interactions with high accuracy, drastically reducing the time and cost associated with traditional pharmaceutical research. Early trials indicate a 20% improvement in identifying potential drug candidates for various diseases, including a new treatment for Alzheimer's. The model was trained on a vast dataset of chemical compounds and biological targets.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 3,\n",
        "        \"title\": \"Impact of Climate Change on Global Food Supply\",\n",
        "        \"url\": \"https://example.com/climate-food-supply\",\n",
        "        \"content\": \"A recent report from the UN's IPCC warns of severe disruptions to global food supply chains due to accelerating climate change. Extreme weather events, prolonged droughts, and unpredictable rainfall patterns are leading to crop failures and reduced agricultural yields in key farming regions. The report emphasizes the urgent need for climate-resilient farming practices and diversified food sources to ensure future food security. It also highlights the disproportionate impact on developing nations.\"\n",
        "    },\n",
        "    {\n",
        "        \"id\": 4,\n",
        "        \"title\": \"The Rise of Sustainable Urban Planning\",\n",
        "        \"url\": \"https://example.com/sustainable-cities\",\n",
        "        \"content\": \"Cities worldwide are increasingly adopting sustainable urban planning principles to combat climate change and improve livability. Initiatives include green infrastructure development, promoting public transportation, establishing car-free zones, and investing in renewable energy sources for urban consumption. Singapore, Copenhagen, and Curitiba are cited as leading examples, demonstrating how integrated planning can lead to reduced carbon footprints and enhanced public well-being. Community engagement is a critical component of these successful projects.\"\n",
        "    }\n",
        "]\n",
        "\n",
        "processed_articles = [] # To store summaries and citations\n",
        "\n",
        "print(f\"Simulated stream of {len(article_stream)} articles created.\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "damf34KLfcSV"
      },
      "id": "damf34KLfcSV",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "azzgM86CfcSV"
      },
      "id": "azzgM86CfcSV"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Design the Summarization + Citation Agent\n",
        "You'll create a function that takes an article and generates a summary with a citation using the LLM. This requires careful prompt engineering."
      ],
      "metadata": {
        "id": "n5mVoixFfcSW"
      },
      "id": "n5mVoixFfcSW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: Implement `summarize_with_citation` Function\n",
        "This asynchronous function will be the core of your agent. It takes an article dictionary and returns a structured summary including the citation."
      ],
      "metadata": {
        "id": "eXs1m24NfcSW"
      },
      "id": "eXs1m24NfcSW"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Prompt Design**: Your prompt should instruct the LLM to:\n",
        "    * Summarize the provided `content` concisely (e.g., 2-3 sentences).\n",
        "    * Explicitly include a citation at the end of the summary in the format `(Source: [Title], [URL])`.\n",
        "    * If the summary requires breaking down complex information, encourage simplification.\n",
        "    * Handle cases where content might be very short or irrelevant (though for this assignment, assume relevant content).\n",
        "* **Output Format**: You might want the LLM to output a specific format, or you can parse its response. For simplicity, instruct the LLM to directly output the combined summary and citation string.\n",
        "* **Error Handling**: Include `try-except` blocks for API errors."
      ],
      "metadata": {
        "id": "bnjL9Qf5fcSW"
      },
      "id": "bnjL9Qf5fcSW"
    },
    {
      "cell_type": "code",
      "source": [
        "async def summarize_with_citation(article: dict) -> dict:\n",
        "    \"\"\"\n",
        "    Sends an article's content to the LLM for summarization and citation.\n",
        "    Returns a dictionary with 'summary', 'citation_title', and 'citation_url'.\n",
        "    \"\"\"\n",
        "    title = article.get(\"title\", \"Unknown Title\")\n",
        "    url = article.get(\"url\", \"No URL provided\")\n",
        "    content = article.get(\"content\", \"\")\n",
        "\n",
        "    if not content:\n",
        "        return {\n",
        "            \"summary\": \"No content provided for summarization.\",\n",
        "            \"citation_title\": title,\n",
        "            \"citation_url\": url\n",
        "        }\n",
        "\n",
        "    system_message = (\n",
        "        \"You are an expert summarizer. Your task is to provide a concise summary (2-4 sentences) of the given article content. \"\n",
        "        \"Crucially, you must append a clear citation in the format: '(Source: [Article Title], [Article URL])'. \"\n",
        "        \"Ensure the summary accurately reflects the content and the citation is precise.\"\n",
        "    )\n",
        "\n",
        "    user_message = (\n",
        "        f\"Please summarize the following article and include its source:\\n\\n\"\n",
        "        f\"Article Title: {title}\\n\"\n",
        "        f\"Article URL: {url}\\n\\n\"\n",
        "        f\"Content:\\n{content}\"\n",
        "    )\n",
        "\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_message},\n",
        "        {\"role\": \"user\", \"content\": user_message}\n",
        "    ]\n",
        "\n",
        "    try:\n",
        "        response = await openai.chat.completions.create(\n",
        "            model=LLM_MODEL,\n",
        "            messages=messages,\n",
        "            temperature=0.2, # Keep temperature low for factual accuracy\n",
        "            max_tokens=200 # Sufficient tokens for summary and citation\n",
        "        )\n",
        "        full_response_content = response.choices[0].message.content\n",
        "\n",
        "        # Simple parsing to separate summary and citation, assuming LLM follows format\n",
        "        summary_part = full_response_content\n",
        "        extracted_citation_title = title # Default to provided title\n",
        "        extracted_citation_url = url # Default to provided URL\n",
        "\n",
        "        # A more robust parsing mechanism might be needed for production\n",
        "        # Here, we trust the LLM to include the exact citation provided in the prompt\n",
        "        # or we can try to extract it from the end of the response.\n",
        "        if \"(Source:\" in full_response_content and \")\" in full_response_content:\n",
        "            citation_start = full_response_content.rfind(\"(Source:\")\n",
        "            citation_end = full_response_content.rfind(\")\")\n",
        "            if citation_start != -1 and citation_end != -1 and citation_end > citation_start:\n",
        "                citation_text = full_response_content[citation_start:citation_end+1]\n",
        "                summary_part = full_response_content[:citation_start].strip()\n",
        "                # Basic attempt to parse title/url from LLM's citation output if it deviated\n",
        "                # For this assignment, we mostly rely on the LLM to output what it was given.\n",
        "                # In a real system, you'd use regex or a more robust parser.\n",
        "                if f\"(Source: {title}, {url})\" not in citation_text:\n",
        "                    # If LLM generated its own citation, try to extract it, otherwise stick to original\n",
        "                    pass\n",
        "\n",
        "        return {\n",
        "            \"summary\": summary_part,\n",
        "            \"citation_title\": title, # Use the original title from the input\n",
        "            \"citation_url\": url      # Use the original URL from the input\n",
        "        }\n",
        "    except openai.APIError as e:\n",
        "        print(f\"OpenAI API error during summarization: {e}\")\n",
        "        return {\n",
        "            \"summary\": f\"Error summarizing article: {e}\",\n",
        "            \"citation_title\": title,\n",
        "            \"citation_url\": url\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"An unexpected error occurred: {e}\")\n",
        "        return {\n",
        "            \"summary\": f\"An unexpected error occurred: {e}\",\n",
        "            \"citation_title\": title,\n",
        "            \"citation_url\": url\n",
        "        }\n",
        "\n",
        "print(\"summarize_with_citation function defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "2Bofql2ufcSW"
      },
      "id": "2Bofql2ufcSW",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "JsZlvwwDfcSX"
      },
      "id": "JsZlvwwDfcSX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Build the Long-Running Agent Loop\n",
        "Now, you'll create the main loop that iterates through your article stream, calls the summarization agent, and stores the results. You'll also implement a way to manage the loop (e.g., stopping condition)."
      ],
      "metadata": {
        "id": "_S4Fjdm5fcSX"
      },
      "id": "_S4Fjdm5fcSX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Implement `run_summarization_agent_loop`\n",
        "Create an asynchronous function that orchestrates the entire process."
      ],
      "metadata": {
        "id": "ueeaqsnRfcSX"
      },
      "id": "ueeaqsnRfcSX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Loop Control**: The loop should run until all articles in `article_stream` are processed, or until a simulated 'stop' condition (e.g., an empty stream).\n",
        "* **Processing Logic**: In each iteration:\n",
        "    1.  Fetch the next article from `article_stream` (you can `pop(0)` or just iterate and keep track of index).\n",
        "    2.  Call `summarize_with_citation` with the article.\n",
        "    3.  Store the result in `processed_articles` list.\n",
        "    4.  Print the current summary and citation for real-time observation.\n",
        "    5.  Include a small delay (`await asyncio.sleep(X)`) to simulate a long-running process and avoid hitting API rate limits too quickly.\n",
        "* **Reporting**: After the loop finishes, print a final summary of all processed articles or confirmation of completion."
      ],
      "metadata": {
        "id": "S96IdJLhfcSX"
      },
      "id": "S96IdJLhfcSX"
    },
    {
      "cell_type": "code",
      "source": [
        "async def run_summarization_agent_loop(articles_to_process: list, delay_seconds: int = 5):\n",
        "    \"\"\"\n",
        "    Runs a long-running loop to summarize articles with citations.\n",
        "    \"\"\"\n",
        "    global processed_articles # Ensure we're modifying the global list\n",
        "    processed_articles = [] # Reset for a fresh run\n",
        "\n",
        "    print(\"\\n--- Starting Long-Running Summarization Agent Loop ---\")\n",
        "    print(f\"Processing {len(articles_to_process)} articles with a delay of {delay_seconds} seconds between each.\")\n",
        "\n",
        "    for i, article in enumerate(articles_to_process):\n",
        "        print(f\"\\n--- Processing Article {i+1}/{len(articles_to_process)}: '{article.get('title', 'N/A')}' ---\")\n",
        "\n",
        "        # Simulate work/API call\n",
        "        summary_data = await summarize_with_citation(article)\n",
        "        processed_articles.append(summary_data)\n",
        "\n",
        "        print(\"Summary:\")\n",
        "        print(summary_data[\"summary\"].strip())\n",
        "        print(f\"Citation: (Source: {summary_data['citation_title']}, {summary_data['citation_url']})\")\n",
        "\n",
        "        if i < len(articles_to_process) - 1: # Don't delay after the last article\n",
        "            print(f\"\\nWaiting {delay_seconds} seconds before next article...\")\n",
        "            await asyncio.sleep(delay_seconds)\n",
        "\n",
        "    print(\"\\n--- Long-Running Summarization Agent Loop Finished ---\")\n",
        "    print(f\"Successfully processed {len(processed_articles)} articles.\")\n",
        "\n",
        "print(\"run_summarization_agent_loop function defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "SqzBGZtBfcSX"
      },
      "id": "SqzBGZtBfcSX",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_YCyyF6kfcSX"
      },
      "id": "_YCyyF6kfcSX"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Execute and Observe\n",
        "Run the agent loop and review its output."
      ],
      "metadata": {
        "id": "zK70P8zbfcSY"
      },
      "id": "zK70P8zbfcSY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.1: Run the Agent Loop\n",
        "Execute the `run_summarization_agent_loop` function with your `article_stream`."
      ],
      "metadata": {
        "id": "2O88ErngfcSY"
      },
      "id": "2O88ErngfcSY"
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the loop\n",
        "await run_summarization_agent_loop(article_stream, delay_seconds=7)"
      ],
      "outputs": [],
      "metadata": {
        "id": "zpCc370CfcSY"
      },
      "id": "zpCc370CfcSY",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.2: Review Processed Articles\n",
        "Inspect the `processed_articles` list to see the collected summaries and citations."
      ],
      "metadata": {
        "id": "OhMj8wupfcSY"
      },
      "id": "OhMj8wupfcSY"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- All Processed Summaries with Citations ---\")\n",
        "for i, data in enumerate(processed_articles):\n",
        "    print(f\"\\nArticle {i+1}:\")\n",
        "    print(f\"Summary: {data['summary']}\")\n",
        "    print(f\"Citation: (Source: {data['citation_title']}, {data['citation_url']})\")\n",
        "    print(\"-------------------------------------------\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "BUQNeKfBfcSY"
      },
      "id": "BUQNeKfBfcSY",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4FCvx-McfcSY"
      },
      "id": "4FCvx-McfcSY"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Analysis and Reflection\n",
        "Based on your implementation and observations, answer the following questions."
      ],
      "metadata": {
        "id": "8WyYtWGmfcSZ"
      },
      "id": "8WyYtWGmfcSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5.1: Prompt Engineering for Citation\n",
        "* **Effectiveness**: How effective was your prompt in consistently making the LLM include the citation in the required format? Did it ever omit it or misformat it?\n",
        "* **Robustness**: What challenges did you face in making the LLM reliably extract and include the *exact* provided source information (title and URL) in the summary's citation? Did you observe any instances where it hallucinated a URL or title, or modified the given ones?\n",
        "* **Improvement**: If you needed to make the citation process more robust (e.g., handling missing URLs, different source types), how would you modify your prompt or add post-processing logic?"
      ],
      "metadata": {
        "id": "ld_7mFCRfcSZ"
      },
      "id": "ld_7mFCRfcSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5.2: Long-Running Agent Loop Design\n",
        "* **Loop Mechanism**: Describe how your `run_summarization_agent_loop` function ensures continuous processing. How does it simulate new data arriving?\n",
        "* **State Management**: How is the state (i.e., `processed_articles`) managed across loop iterations? Why is it important to store the results externally rather than just printing them?\n",
        "* **Concurrency/Rate Limiting**: The current loop uses `asyncio.sleep`. In a real-world scenario with many articles, what strategies would you employ for managing API rate limits and potentially parallelizing API calls (e.g., using `asyncio.gather`, queues, or dedicated rate-limiting libraries)?"
      ],
      "metadata": {
        "id": "xgnikIN3fcSZ"
      },
      "id": "xgnikIN3fcSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 5.3: Application and Scalability\n",
        "* **Use Cases**: What real-world applications would benefit from a long-running summarization and citation agent like this (e.g., news monitoring, research assistance, content aggregation)?\n",
        "* **Scalability Challenges**: Discuss the challenges of scaling this system to process thousands or millions of articles daily. Consider computational resources, API costs, data storage, and the need for more advanced error recovery.\n",
        "* **Reliability**: How would you enhance the reliability of this agent to ensure it can run for days or weeks without human intervention, handling unexpected errors (e.g., API downtime, malformed content) gracefully?"
      ],
      "metadata": {
        "id": "-P9tAhOHfcSZ"
      },
      "id": "-P9tAhOHfcSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "EAnuOzlBfcSZ"
      },
      "id": "EAnuOzlBfcSZ"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission:\n",
        "* Ensure all code cells have been executed and their outputs are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Make sure your `.env` file (or equivalent API key setup) is mentioned but **NOT** included in the submitted notebook for security reasons.\n",
        "* Save your Jupyter Notebook as `[YourName]_Summarization_Citation_Agent_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "kTHiDed5fcSZ"
      },
      "id": "kTHiDed5fcSZ"
    }
  ]
}