{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Create AutoGen Chat Agents with User Proxy and Assistant Roles\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "x6eR-9YPbLsx"
      },
      "id": "x6eR-9YPbLsx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment will guide you through setting up a basic multi-agent conversation using **AutoGen**. You will create two core agent types: `UserProxyAgent` and `AssistantAgent`, understand their distinct roles, and orchestrate a simple automated chat between them to solve a defined problem. This serves as a foundational exercise for building more complex agentic workflows."
      ],
      "metadata": {
        "id": "UI0f2TrfbLsz"
      },
      "id": "UI0f2TrfbLsz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "abFahZOmbLs0"
      },
      "id": "abFahZOmbLs0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **LLM Access**: You will need access to an LLM API. **OpenAI's models (e.g., GPT-4o, GPT-4, GPT-3.5-turbo)** are recommended for their robust function calling capabilities, which AutoGen leverages heavily. You can also use local LLMs via `ollama` or `lmstudio` if configured correctly (see AutoGen docs for details).\n",
        "2.  **Environment Setup**: Install the necessary Python library: `pip install pyautogen`.\n",
        "3.  **API Key**: Securely handle your API key. It's best practice to load it from an environment variable or a configuration file (like `OAI_CONFIG_LIST`). For simplicity in this assignment, we'll demonstrate using `os.environ`.\n",
        "4.  **Jupyter Notebook**: All your code, outputs, observations, and analysis must be documented in this Jupyter Notebook.\n",
        "5.  **Task Scenario**: The agents will collaborate to solve a simple Python coding problem or a knowledge-based query.\n",
        "6.  **Analysis**: Explain the roles, interaction flow, and termination conditions."
      ],
      "metadata": {
        "id": "MtWMerFqbLs0"
      },
      "id": "MtWMerFqbLs0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "nNuT2iHMbLs1"
      },
      "id": "nNuT2iHMbLs1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and LLM Configuration\n",
        "Begin by installing AutoGen and configuring your LLM API key."
      ],
      "metadata": {
        "id": "a1LozOMubLs1"
      },
      "id": "a1LozOMubLs1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: Install AutoGen\n",
        "Ensure `pyautogen` is installed in your environment."
      ],
      "metadata": {
        "id": "Qm0XUAI5bLs2"
      },
      "id": "Qm0XUAI5bLs2"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install AutoGen (if not already installed)\n",
        "# !pip install pyautogen --quiet\n",
        "\n",
        "import autogen\n",
        "import os\n",
        "\n",
        "print(\"AutoGen imported!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "LFNwqPoObLs2"
      },
      "id": "LFNwqPoObLs2",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Configure LLM\n",
        "Set up your OpenAI API key (or configuration for other LLMs). For this assignment, we'll assume OpenAI. Replace `YOUR_OPENAI_API_KEY_HERE` with your actual key or load it from an environment variable."
      ],
      "metadata": {
        "id": "mLNJ2_obbLs3"
      },
      "id": "mLNJ2_obbLs3"
    },
    {
      "cell_type": "code",
      "source": [
        "# --- YOUR OPENAI API KEY HERE ---\n",
        "# It's highly recommended to load your API key from an environment variable.\n",
        "# On Linux/macOS: export OPENAI_API_KEY='your_key'\n",
        "# On Windows (cmd): set OPENAI_API_KEY=your_key\n",
        "\n",
        "# As an alternative for quick testing, you can uncomment and paste your key directly:\n",
        "# os.environ[\"OPENAI_API_KEY\"] = \"YOUR_OPENAI_API_KEY_HERE\"\n",
        "\n",
        "# Define the LLM configuration list.\n",
        "# AutoGen will try models in this list in order.\n",
        "config_list_openai = autogen.config_list_from_json(\n",
        "    \"OAI_CONFIG_LIST\",\n",
        "    filter_dict={\n",
        "        \"model\": [\"gpt-4o\", \"gpt-4\", \"gpt-3.5-turbo\"], # Prioritize larger models if available\n",
        "    },\n",
        ")\n",
        "\n",
        "# If OAI_CONFIG_LIST doesn't exist or you prefer direct configuration:\n",
        "if not config_list_openai:\n",
        "    # Fallback to direct environment variable if OAI_CONFIG_LIST is not found/configured\n",
        "    if \"OPENAI_API_KEY\" in os.environ:\n",
        "        print(\"Using OPENAI_API_KEY from environment variable.\")\n",
        "        config_list_openai = [\n",
        "            {\n",
        "                \"model\": \"gpt-4o\", # or \"gpt-4\", \"gpt-3.5-turbo\"\n",
        "                \"api_key\": os.environ[\"OPENAI_API_KEY\"],\n",
        "            }\n",
        "        ]\n",
        "    else:\n",
        "        print(\"WARNING: OPENAI_API_KEY not found in environment variables or OAI_CONFIG_LIST.\")\n",
        "        print(\"Please set OPENAI_API_KEY or create OAI_CONFIG_LIST file.\")\n",
        "        config_list_openai = [] # Empty list will cause errors if LLM is needed\n",
        "\n",
        "print(\"LLM configuration loaded!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "nTzgDMDvbLs4"
      },
      "id": "nTzgDMDvbLs4",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.3: Define the Problem Scenario\n",
        "Choose a simple problem for your agents to solve. This could be:\n",
        "* \"Write a Python function to check if a string is a palindrome.\"\n",
        "* \"Explain the concept of 'recursion' in simple terms.\"\n",
        "* \"Calculate the 10th Fibonacci number using a recursive approach.\"\n",
        "\n",
        "For this assignment, let's use the first one as a starting point. Feel free to modify it."
      ],
      "metadata": {
        "id": "V6ktP2xRbLs4"
      },
      "id": "V6ktP2xRbLs4"
    },
    {
      "cell_type": "code",
      "source": [
        "problem_statement = \"Write a Python function named `is_palindrome` that takes a string as input and returns `True` if it's a palindrome (reads the same forwards and backwards, ignoring case and spaces), and `False` otherwise. Provide at least two test cases with expected outputs.\"\n",
        "\n",
        "print(\"Problem statement defined:\", problem_statement)"
      ],
      "outputs": [],
      "metadata": {
        "id": "PfZkD1LzbLs5"
      },
      "id": "PfZkD1LzbLs5",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "QmqSIPTAbLs5"
      },
      "id": "QmqSIPTAbLs5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Agent Creation\n",
        "Now, create your `AssistantAgent` and `UserProxyAgent` instances."
      ],
      "metadata": {
        "id": "61BztTkwbLs5"
      },
      "id": "61BztTkwbLs5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: Create the `AssistantAgent`\n",
        "Instantiate an `AssistantAgent`. This agent typically represents the AI that generates responses and code.\n",
        "\n",
        "* **Name**: Choose a descriptive name (e.g., `coder_agent`, `solver`).\n",
        "* **System Message**: Define its role and objective concisely (e.g., \"You are a helpful AI assistant that writes Python code and explains concepts.\").\n",
        "* **LLM Config**: Pass your `config_list_openai`."
      ],
      "metadata": {
        "id": "lBB3EiVzbLs6"
      },
      "id": "lBB3EiVzbLs6"
    },
    {
      "cell_type": "code",
      "source": [
        "assistant = autogen.AssistantAgent(\n",
        "    name=\"PythonCoder\",\n",
        "    system_message=\"You are a helpful AI assistant that writes clean, functional Python code, provides explanations, and ensures correctness with test cases. Respond with 'TERMINATE' when the task is fully completed and all code and explanations are satisfactory.\",\n",
        "    llm_config={\n",
        "        \"config_list\": config_list_openai,\n",
        "        \"temperature\": 0.7, # Adjust temperature for creativity/determinism\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"AssistantAgent 'PythonCoder' created!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "2XQE_x9dbLs6"
      },
      "id": "2XQE_x9dbLs6",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.2: Create the `UserProxyAgent`\n",
        "Instantiate a `UserProxyAgent`. This agent acts on behalf of the user, can execute code, and often initiates conversations.\n",
        "\n",
        "* **Name**: Choose a descriptive name (e.g., `user_proxy`, `executor`).\n",
        "* **Human Input Mode**: Set to `\"NEVER\"` for fully automated execution (no human input during chat). For debugging or interactive use, `\"ALWAYS\"` or `\"TERMINATE\"` can be used.\n",
        "* **Max Consecutive Auto Reply**: Set a reasonable limit to prevent infinite loops.\n",
        "* **Code Execution Config**: Enable code execution. This is crucial for AutoGen agents to run generated Python code. Specify a `work_dir` where scripts will be saved and executed.\n",
        "* **Is Termination Message**: Define a function to determine when the conversation should end. This is how the `UserProxyAgent` knows when to stop relaying messages."
      ],
      "metadata": {
        "id": "9L1eL-XHbLs6"
      },
      "id": "9L1eL-XHbLs6"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the termination condition for the UserProxyAgent\n",
        "def is_termination_message(message):\n",
        "    return \"TERMINATE\" in message.get(\"content\", \"\").upper()\n",
        "\n",
        "user_proxy = autogen.UserProxyAgent(\n",
        "    name=\"User\",\n",
        "    human_input_mode=\"NEVER\", # Set to NEVER for full automation\n",
        "    max_consecutive_auto_reply=10, # Max number of turns before stopping\n",
        "    is_termination_msg=is_termination_message,\n",
        "    code_execution_config={\n",
        "        \"work_dir\": \"coding_temp\", # Directory to save and execute code\n",
        "        \"use_docker\": False, # Set to True if you have Docker installed for isolated execution\n",
        "    },\n",
        ")\n",
        "\n",
        "print(\"UserProxyAgent 'User' created!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "UrwINc0vbLs7"
      },
      "id": "UrwINc0vbLs7",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "zFVe8N2AbLs7"
      },
      "id": "zFVe8N2AbLs7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Initiating and Managing the Conversation\n",
        "Initiate the chat between your two agents and observe their interaction."
      ],
      "metadata": {
        "id": "1DuIlP0DbLs7"
      },
      "id": "1DuIlP0DbLs7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Start the Chat\n",
        "Use the `initiate_chat` method of the `UserProxyAgent` to begin the conversation with the `AssistantAgent` on the defined `problem_statement`."
      ],
      "metadata": {
        "id": "F4lKAJTTbLs8"
      },
      "id": "F4lKAJTTbLs8"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Initiating the Chat --- \")\n",
        "\n",
        "# Make sure the coding_temp directory exists\n",
        "if not os.path.exists(\"coding_temp\"):\n",
        "    os.makedirs(\"coding_temp\")\n",
        "\n",
        "chat_result = user_proxy.initiate_chat(\n",
        "    assistant, # The assistant agent to chat with\n",
        "    message=problem_statement, # The initial message/problem\n",
        "    clear_history=True, # Clear previous chat history if any\n",
        "    silent=False, # Set to True to suppress console output during chat\n",
        ")\n",
        "\n",
        "print(\"\\n--- Chat Ended --- \")"
      ],
      "outputs": [],
      "metadata": {
        "id": "hXAoXIgDbLs8"
      },
      "id": "hXAoXIgDbLs8",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.2: Observe and Analyze the Interaction\n",
        "Review the console output from the chat above. AutoGen provides detailed logs of message exchanges and code execution. Pay attention to:\n",
        "\n",
        "* Which agent is speaking (`User` or `PythonCoder`).\n",
        "* The content of the messages (code, explanations, execution results).\n",
        "* When and how code is executed (you'll see `exitcode` and output from the `User` agent).\n",
        "* The message that ultimately leads to termination (e.g., `TERMINATE`)."
      ],
      "metadata": {
        "id": "KumtCehAbLs8"
      },
      "id": "KumtCehAbLs8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Ds3wiNa3bLs8"
      },
      "id": "Ds3wiNa3bLs8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Analysis and Reflection\n",
        "Answer the following questions based on your observations of the AutoGen chat."
      ],
      "metadata": {
        "id": "PwQpX5ZwbLs9"
      },
      "id": "PwQpX5ZwbLs9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.1: Conversation Review\n",
        "* **Problem Resolution**: Was the `problem_statement` successfully addressed? Did the `PythonCoder` agent provide correct code and test cases?\n",
        "* **Agent Contributions**: Describe the key messages and actions taken by the `PythonCoder` (AssistantAgent) and the `User` (UserProxyAgent). How did they collaborate?\n",
        "* **Code Execution**: Did the `UserProxyAgent` execute code? If so, what was the output of the code execution?\n",
        "* **Termination**: How did the conversation conclude? Was the `is_termination_msg` function effective in stopping the chat when the assistant issued a 'TERMINATE' message?"
      ],
      "metadata": {
        "id": "kl_UoQ5sbLs9"
      },
      "id": "kl_UoQ5sbLs9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.2: Role and Functionality Discussion\n",
        "* **`UserProxyAgent` vs. `AssistantAgent`**: Clearly differentiate the primary responsibilities and capabilities of the `UserProxyAgent` and `AssistantAgent` roles within AutoGen.\n",
        "* **`human_input_mode`**: Explain the purpose of the `human_input_mode` parameter. What are the implications of setting it to `\"NEVER\"`, `\"ALWAYS\"`, or `\"TERMINATE\"` for different use cases?\n",
        "* **`is_termination_msg`**: Why is it important to define a clear termination condition for multi-agent conversations? What happens if it's not well-defined?\n",
        "* **`code_execution_config`**: Discuss the importance of `code_execution_config` for the `UserProxyAgent`. How does it enable agents to test and verify their own solutions?"
      ],
      "metadata": {
        "id": "BvSgcUCMbLs9"
      },
      "id": "BvSgcUCMbLs9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.3: Potential Extensions\n",
        "* **Adding Agents**: How would you extend this setup to include more agents (e.g., a \"Reviewer\" agent, a \"Debugger\" agent)? What roles would they play?\n",
        "* **Complex Problems**: How would you adapt this basic framework to solve more complex, multi-step problems that might require external tools (e.g., web search, API calls)?\n",
        "* **Interactive Mode**: If you were to change `human_input_mode` to `\"ALWAYS\"`, describe how you would interact with the agents during the conversation."
      ],
      "metadata": {
        "id": "3OqzKRmsbLs9"
      },
      "id": "3OqzKRmsbLs9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "_JCqC6lEbLs9"
      },
      "id": "_JCqC6lEbLs9"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission:\n",
        "* Ensure all code cells have been executed and their outputs are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Save your Jupyter Notebook as `[YourName]_AutoGen_Basic_Agents_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "A_6e6To3bLs-"
      },
      "id": "A_6e6To3bLs-"
    }
  ]
}