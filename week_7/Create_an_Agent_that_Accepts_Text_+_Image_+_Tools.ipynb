{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üß™ Practical: Create an Agent that Accepts Text + Image + Tools\n",
        "\n",
        "  üì• Image upload\n",
        "\n",
        "  üìù Text input\n",
        "\n",
        "  üõ†Ô∏è Tools: Image Captioning + Question Answering\n",
        "\n",
        "#üéØ Objectives\n",
        "By the end of this practical, you will:\n",
        "\n",
        "Upload an image and text-based question together\n",
        "\n",
        "Build an agent that:\n",
        "\n",
        "Captions the image\n",
        "\n",
        "Uses caption + question for question answering\n",
        "\n",
        "Use LangGraph to orchestrate tools\n",
        "\n",
        "Use Gemini 1.5 Flash (Free-tier) for all LLM work\n",
        "\n",
        "üß© Tools Required\n",
        "\n"
      ],
      "metadata": {
        "id": "NCqoy7YG3iOU"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFYkqT1s07EK",
        "outputId": "1a9fcfd0-5009-4161-d303-ba042a4777f7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (11.2.1)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langchain-google-genai langgraph google-generativeai pillow"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üóÇÔ∏è Folder Structure (Optional)\n",
        "\n",
        "multimodal_agent/\n",
        "\n",
        "‚îú‚îÄ‚îÄ app.py             # Main practical\n",
        "\n",
        "‚îú‚îÄ‚îÄ sample.jpg         # Try your own image\n"
      ],
      "metadata": {
        "id": "TThXcsXC3r6q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ Step-by-Step Practical (app.py)"
      ],
      "metadata": {
        "id": "vR7Km1I031Uw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from typing import TypedDict, Annotated, Union\n",
        "from PIL import Image\n",
        "import base64\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Set your free-tier Gemini API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCDyiafjDZo4pJf36HDz4QQtCgpCe2DD3E\"\n"
      ],
      "metadata": {
        "id": "8NREQX4o1FKh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Step 1: Define Shared State for Multimodal Agent"
      ],
      "metadata": {
        "id": "5_EIMAY_330w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiModalState(TypedDict):\n",
        "    image_path: Annotated[str, \"Path to input image\"]\n",
        "    user_question: Annotated[str, \"User's text-based question\"]\n",
        "    image_caption: Annotated[str, \"Caption generated from the image\"]\n",
        "    answer: Annotated[str, \"Answer to user's question\"]\n"
      ],
      "metadata": {
        "id": "V0JOvtsi1TPu"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Step 2: Load Gemini 1.5 Flash (with Image Support)"
      ],
      "metadata": {
        "id": "VhsEwmFd35vS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.4,\n",
        "    convert_system_message_to_human=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "dXHFVNQ41ZbW"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üì∑ Step 3: Define Image Captioning Node"
      ],
      "metadata": {
        "id": "elBVu7WH37sY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def image_caption_node(state: MultiModalState) -> MultiModalState:\n",
        "    image_path = state['image_path']\n",
        "\n",
        "    with open(image_path, \"rb\") as img_file:\n",
        "        image_data = img_file.read()\n",
        "\n",
        "    # Gemini accepts base64 encoded image in LangChain\n",
        "    image_base64 = base64.b64encode(image_data).decode(\"utf-8\")\n",
        "    mimetype = \"image/jpeg\" if image_path.endswith(\".jpg\") else \"image/png\"\n",
        "\n",
        "    response = llm.invoke(\n",
        "        [\n",
        "            {\"role\": \"user\", \"content\": [\n",
        "                {\"type\": \"text\", \"text\": \"Describe this image in one sentence.\"},\n",
        "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:{mimetype};base64,{image_base64}\"}}\n",
        "            ]}\n",
        "        ]\n",
        "    )\n",
        "\n",
        "    print(\"üñºÔ∏è Image Caption:\", response.content)\n",
        "    return {**state, \"image_caption\": response.content}"
      ],
      "metadata": {
        "id": "a8owjE1y1ace"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚ùì Step 4: Define QA Node Using Caption + User Question"
      ],
      "metadata": {
        "id": "RF0DlP_l3-AY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def question_answer_node(state: MultiModalState) -> MultiModalState:\n",
        "    question = state['user_question']\n",
        "    caption = state['image_caption']\n",
        "\n",
        "    qa_prompt = f\"\"\"Image Description: {caption}\n",
        "User Question: {question}\n",
        "Answer:\"\"\"\n",
        "\n",
        "    response = llm.invoke(qa_prompt)\n",
        "    print(\"‚ùì Answer:\", response.content)\n",
        "    return {**state, \"answer\": response.content}\n"
      ],
      "metadata": {
        "id": "72RnZiCI1bgO"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÑ Step 5: Build LangGraph and Connect Nodes"
      ],
      "metadata": {
        "id": "5dwuG8G94ADm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(MultiModalState)\n",
        "graph.add_node(\"caption\", image_caption_node)\n",
        "graph.add_node(\"qa\", question_answer_node)\n",
        "\n",
        "# Flow: caption ‚Üí qa ‚Üí END\n",
        "graph.set_entry_point(\"caption\")\n",
        "graph.add_edge(\"caption\", \"qa\")\n",
        "graph.add_edge(\"qa\", END)\n",
        "\n",
        "# Compile app\n",
        "app = graph.compile()\n"
      ],
      "metadata": {
        "id": "rxpfgce81cm1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üöÄ Step 6: Run the Agent on a Sample Image + Question"
      ],
      "metadata": {
        "id": "GBi5CUCX4CHn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Provide your own image path and question\n",
        "image_path = \"sample_image.jpg\"  # Make sure this image exists\n",
        "user_question = \"What is the person doing in this image?\"\n",
        "\n",
        "# Run agent\n",
        "initial_state = {\n",
        "    \"image_path\": image_path,\n",
        "    \"user_question\": user_question,\n",
        "    \"image_caption\": \"\",\n",
        "    \"answer\": \"\"\n",
        "}\n",
        "\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n‚úÖ Final Output:\")\n",
        "print(\"Caption:\", final_state[\"image_caption\"])\n",
        "print(\"Answer:\", final_state[\"answer\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgxAAcI12zzg",
        "outputId": "5d585ac1-f379-4307-cf47-d8bd1dd52908"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üñºÔ∏è Image Caption: An adorable Golden Retriever puppy lies in the grass, looking directly at the camera.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚ùì Answer: There is no person in the image.  The image only shows a Golden Retriever puppy.\n",
            "\n",
            "‚úÖ Final Output:\n",
            "Caption: An adorable Golden Retriever puppy lies in the grass, looking directly at the camera.\n",
            "Answer: There is no person in the image.  The image only shows a Golden Retriever puppy.\n"
          ]
        }
      ]
    }
  ]
}