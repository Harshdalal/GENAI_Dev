{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#üß™ Practical: Simulate a LangGraph Cognitive Loop (Goal ‚Üí Plan ‚Üí Act ‚Üí Reflect)\n",
        "\n",
        "\n",
        "#‚úÖ Tools: LangChain, LangGraph, and Gemini 1.5 Flash (Free API)\n",
        "üß† Agent thinks like: ‚ÄúWhat‚Äôs the goal? ‚Üí What should I do? ‚Üí Let me do it ‚Üí Was it effective?‚Äù\n",
        "\n",
        "#üéØ Objectives\n",
        "  Simulate a basic cognitive loop using LangGraph‚Äôs step-based architecture.\n",
        "\n",
        "  Create 4 nodes representing:\n",
        "\n",
        "  goal ‚Üí plan ‚Üí act ‚Üí reflect\n",
        "\n",
        "  Use Gemini 1.5 Flash (via LangChain) as the LLM for reasoning.\n",
        "\n",
        "  Allow the agent to decide whether to repeat or stop based on its reflection.\n",
        "\n",
        "  Fully runnable using the free Gemini API.\n",
        "\n",
        "#pre-requisite"
      ],
      "metadata": {
        "id": "84hE2H16zzS2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8cMc_mg6yKF3",
        "outputId": "dcae26c3-aff7-4661-942b-a1dc2c4cc7a7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.5-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting langgraph\n",
            "  Downloading langgraph-0.4.8-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.65)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.45)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.7)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.41)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Collecting langgraph-checkpoint>=2.0.26 (from langgraph)\n",
            "  Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl.metadata (4.2 kB)\n",
            "Collecting langgraph-prebuilt>=0.2.0 (from langgraph)\n",
            "  Downloading langgraph_prebuilt-0.2.2-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting langgraph-sdk>=0.1.42 (from langgraph)\n",
            "  Downloading langgraph_sdk-0.1.70-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "INFO: pip is looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting google-generativeai\n",
            "  Downloading google_generativeai-0.8.4-py3-none-any.whl.metadata (4.2 kB)\n",
            "  Downloading google_generativeai-0.8.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.8.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.7.2-py3-none-any.whl.metadata (4.0 kB)\n",
            "  Downloading google_generativeai-0.7.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: pip is still looking at multiple versions of google-generativeai to determine which version is compatible with other requirements. This could take a while.\n",
            "  Downloading google_generativeai-0.7.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.6.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.4-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.3-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.2-py3-none-any.whl.metadata (3.9 kB)\n",
            "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
            "  Downloading google_generativeai-0.5.1-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.5.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "  Downloading google_generativeai-0.4.1-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.4.0-py3-none-any.whl.metadata (6.2 kB)\n",
            "  Downloading google_generativeai-0.3.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.1-py3-none-any.whl.metadata (5.9 kB)\n",
            "  Downloading google_generativeai-0.3.0-py3-none-any.whl.metadata (5.8 kB)\n",
            "  Downloading google_generativeai-0.2.2-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.1-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.2.0-py3-none-any.whl.metadata (3.1 kB)\n",
            "  Downloading google_generativeai-0.1.0-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "  Downloading langchain_google_genai-2.1.3-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.2-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.1-py3-none-any.whl.metadata (4.7 kB)\n",
            "  Downloading langchain_google_genai-2.1.0-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.11-py3-none-any.whl.metadata (3.6 kB)\n",
            "  Downloading langchain_google_genai-2.0.10-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (24.2)\n",
            "Collecting ormsgpack>=1.10.0 (from langgraph-checkpoint>=2.0.26->langgraph)\n",
            "  Downloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.6.15)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.3)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n",
            "Downloading langchain_google_genai-2.0.10-py3-none-any.whl (41 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph-0.4.8-py3-none-any.whl (152 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m152.4/152.4 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading langgraph_checkpoint-2.1.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading langgraph_prebuilt-0.2.2-py3-none-any.whl (23 kB)\n",
            "Downloading langgraph_sdk-0.1.70-py3-none-any.whl (49 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.0/50.0 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ormsgpack-1.10.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m216.5/216.5 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, ormsgpack, langgraph-sdk, langgraph-checkpoint, langgraph-prebuilt, langgraph, langchain-google-genai\n",
            "Successfully installed filetype-1.2.0 langchain-google-genai-2.0.10 langgraph-0.4.8 langgraph-checkpoint-2.1.0 langgraph-prebuilt-0.2.2 langgraph-sdk-0.1.70 ormsgpack-1.10.0\n"
          ]
        }
      ],
      "source": [
        "#step 1\n",
        "!pip install langchain langchain-google-genai langgraph google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üõ†Ô∏è Step 2: Import Libraries and Set Up Gemini API"
      ],
      "metadata": {
        "id": "SD3PHYps0Ds0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# Set your Gemini API key (Free tier)\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCDyiafjDZo4pJf36HDz4QQtCgpCe2DD3E\"\n"
      ],
      "metadata": {
        "id": "gZ_avwS_y-8Q"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Step 3: Define the Shared State Format"
      ],
      "metadata": {
        "id": "zmkq1eMW0Fr5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from typing import TypedDict, Annotated\n",
        "\n",
        "class CognitiveState(TypedDict):\n",
        "    goal: Annotated[str, \"User-defined goal\"]\n",
        "    plan: Annotated[str, \"Plan generated\"]\n",
        "    result: Annotated[str, \"Result of action\"]\n",
        "    reflect: Annotated[str, \"Self-evaluation of the result\"]\n"
      ],
      "metadata": {
        "id": "xEATRhoHzMhd"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üí° Step 4: Initialize Gemini 1.5 Flash LLM"
      ],
      "metadata": {
        "id": "mcgcnRwk0KXQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = ChatGoogleGenerativeAI(\n",
        "    model=\"gemini-1.5-flash\",\n",
        "    temperature=0.5,\n",
        "    convert_system_message_to_human=True\n",
        ")\n"
      ],
      "metadata": {
        "id": "ydcIBCJGzOZt"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Step 5: Define the Cognitive Loop Nodes"
      ],
      "metadata": {
        "id": "kxaZnA-X0MWO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Goal ‚Üí Plan\n",
        "def plan_node(state: CognitiveState) -> CognitiveState:\n",
        "    response = llm.invoke(f\"\"\"You are a helpful planner. Based on the user's goal: '{state['goal']}', break it into a short plan.\"\"\")\n",
        "    print(\"üß† PLAN:\", response.content)\n",
        "    return {**state, \"plan\": response.content}\n",
        "\n",
        "# Plan ‚Üí Act\n",
        "def act_node(state: CognitiveState) -> CognitiveState:\n",
        "    response = llm.invoke(f\"\"\"You are an agent. Execute this plan: '{state['plan']}'. Return the output.\"\"\")\n",
        "    print(\"ü§ñ ACTION:\", response.content)\n",
        "    return {**state, \"result\": response.content}\n",
        "\n",
        "# Act ‚Üí Reflect\n",
        "def reflect_node(state: CognitiveState) -> CognitiveState:\n",
        "    response = llm.invoke(f\"\"\"You are a reflective agent. Review the result: '{state['result']}' for goal '{state['goal']}'.\n",
        "Was this effective? If yes, say 'COMPLETE'. Otherwise suggest improvements.\"\"\")\n",
        "    print(\"üîç REFLECTION:\", response.content)\n",
        "    return {**state, \"reflect\": response.content}\n"
      ],
      "metadata": {
        "id": "TS-gjOX9zWLu"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÅ Step 6: Define Reflection-Based Routing Logic"
      ],
      "metadata": {
        "id": "tJBU0_qt0Oqw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Based on reflection, decide whether to continue or end\n",
        "def route(state: CognitiveState) -> str:\n",
        "    if \"COMPLETE\" in state[\"reflect\"].upper():\n",
        "        return END\n",
        "    else:\n",
        "        return \"plan\"  # Loop back to planning with improved insight\n"
      ],
      "metadata": {
        "id": "69v_wzkJzXR-"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîÑ Step 7: Build LangGraph Loop (Plan ‚Üí Act ‚Üí Reflect)"
      ],
      "metadata": {
        "id": "nxzomwwI0RRU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = StateGraph(CognitiveState)\n",
        "\n",
        "# Add nodes\n",
        "graph.add_node(\"planner\", plan_node)\n",
        "graph.add_node(\"act\", act_node)\n",
        "graph.add_node(\"reflector\", reflect_node)\n",
        "\n",
        "# Define edges\n",
        "graph.set_entry_point(\"planner\")\n",
        "graph.add_edge(\"planner\", \"act\")\n",
        "graph.add_edge(\"act\", \"reflector\")\n",
        "graph.add_conditional_edges(\"reflector\", route, {\n",
        "    \"plan\": \"planner\",  # Loop\n",
        "    END: END         # End\n",
        "})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDZn1syEzYSP",
        "outputId": "b7579b4b-611d-4667-988d-7171d5c45462"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x796578fac250>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#‚úÖ Step 8: Compile and Run the Graph"
      ],
      "metadata": {
        "id": "P7lk62C_0ZDQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compile the app\n",
        "app = graph.compile()\n",
        "\n",
        "# Define the initial input\n",
        "initial_state = {\n",
        "    \"goal\": \"Summarize a paragraph and generate Python code to count its words.\",\n",
        "    \"plan\": \"\",\n",
        "    \"result\": \"\",\n",
        "    \"reflect\": \"\"\n",
        "}\n",
        "\n",
        "# Run the loop\n",
        "final_state = app.invoke(initial_state)\n",
        "\n",
        "print(\"\\n‚úÖ FINAL STATE:\")\n",
        "for k, v in final_state.items():\n",
        "    print(f\"{k.upper()}:\\n{v}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kxT3RssLzZN9",
        "outputId": "3603bf07-fdfb-47e8-b62f-5ed895db9d65"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üß† PLAN: **Plan:**\n",
            "\n",
            "1. **Input:** Obtain the paragraph text from the user.\n",
            "2. **Summarization:**  Use a summarization technique (e.g., extractive summarization using sentence scoring or a pre-trained model like transformers) to generate a concise summary.\n",
            "3. **Word Counting:** Write a Python function to count the words in the original paragraph (and optionally the summary).  This will involve splitting the text into words (handling punctuation appropriately).\n",
            "4. **Output:** Display both the generated summary and the word counts (original paragraph and summary).\n",
            "5. **Error Handling:** Include basic error handling (e.g., for empty input).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ü§ñ ACTION: ```python\n",
            "import nltk\n",
            "from transformers import pipeline\n",
            "\n",
            "nltk.download('punkt', quiet=True)\n",
            "\n",
            "def summarize_text(text):\n",
            "    \"\"\"Summarizes the input text using a transformer model.\"\"\"\n",
            "    try:\n",
            "        summarizer = pipeline(\"summarization\")\n",
            "        summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
            "        return summary\n",
            "    except Exception as e:\n",
            "        return f\"Error during summarization: {e}\"\n",
            "\n",
            "\n",
            "def count_words(text):\n",
            "    \"\"\"Counts the words in the input text.\"\"\"\n",
            "    try:\n",
            "        words = nltk.word_tokenize(text)\n",
            "        return len(words)\n",
            "    except Exception as e:\n",
            "        return f\"Error counting words: {e}\"\n",
            "\n",
            "\n",
            "def main():\n",
            "    \"\"\"Main function to execute the plan.\"\"\"\n",
            "    paragraph = input(\"Enter a paragraph of text: \")\n",
            "\n",
            "    if not paragraph.strip():\n",
            "        print(\"Error: Input cannot be empty.\")\n",
            "        return\n",
            "\n",
            "    summary = summarize_text(paragraph)\n",
            "    original_word_count = count_words(paragraph)\n",
            "    summary_word_count = count_words(summary)\n",
            "\n",
            "    print(\"\\n--- Summary ---\\n\")\n",
            "    print(summary)\n",
            "    print(\"\\n--- Word Counts ---\\n\")\n",
            "    print(f\"Original Paragraph: {original_word_count} words\")\n",
            "    print(f\"Summary: {summary_word_count} words\")\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n",
            "```\n",
            "\n",
            "This improved code addresses the prompt's requirements:\n",
            "\n",
            "1. **Input:** Prompts the user for a paragraph.\n",
            "2. **Summarization:** Uses the `transformers` library for a more robust summarization (requires installation: `pip install transformers`).  Handles potential errors during summarization.\n",
            "3. **Word Counting:** Uses `nltk` for accurate word tokenization, handling punctuation. Includes error handling.\n",
            "4. **Output:** Clearly displays the summary and word counts.\n",
            "5. **Error Handling:** Checks for empty input and handles errors in summarization and word counting.\n",
            "\n",
            "\n",
            "To run this code:\n",
            "\n",
            "1.  Make sure you have `transformers` and `nltk` installed:  `pip install transformers nltk`\n",
            "2.  Run the Python script.  It will prompt you to enter a paragraph.\n",
            "\n",
            "\n",
            "Example usage:\n",
            "\n",
            "```\n",
            "Enter a paragraph of text: The quick brown fox jumps over the lazy dog. This is a simple sentence.  Another sentence follows.  And yet another, slightly longer one, to test the summarization capabilities.\n",
            "\n",
            "--- Summary ---\n",
            "The quick brown fox jumps over the lazy dog. This is a simple sentence. Another sentence follows.\n",
            "--- Word Counts ---\n",
            "Original Paragraph: 29 words\n",
            "Summary: 19 words\n",
            "```\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/langchain_google_genai/chat_models.py:357: UserWarning: Convert_system_message_to_human will be deprecated!\n",
            "  warnings.warn(\"Convert_system_message_to_human will be deprecated!\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîç REFLECTION: COMPLETE\n",
            "\n",
            "‚úÖ FINAL STATE:\n",
            "GOAL:\n",
            "Summarize a paragraph and generate Python code to count its words.\n",
            "\n",
            "PLAN:\n",
            "**Plan:**\n",
            "\n",
            "1. **Input:** Obtain the paragraph text from the user.\n",
            "2. **Summarization:**  Use a summarization technique (e.g., extractive summarization using sentence scoring or a pre-trained model like transformers) to generate a concise summary.\n",
            "3. **Word Counting:** Write a Python function to count the words in the original paragraph (and optionally the summary).  This will involve splitting the text into words (handling punctuation appropriately).\n",
            "4. **Output:** Display both the generated summary and the word counts (original paragraph and summary).\n",
            "5. **Error Handling:** Include basic error handling (e.g., for empty input).\n",
            "\n",
            "RESULT:\n",
            "```python\n",
            "import nltk\n",
            "from transformers import pipeline\n",
            "\n",
            "nltk.download('punkt', quiet=True)\n",
            "\n",
            "def summarize_text(text):\n",
            "    \"\"\"Summarizes the input text using a transformer model.\"\"\"\n",
            "    try:\n",
            "        summarizer = pipeline(\"summarization\")\n",
            "        summary = summarizer(text, max_length=130, min_length=30, do_sample=False)[0]['summary_text']\n",
            "        return summary\n",
            "    except Exception as e:\n",
            "        return f\"Error during summarization: {e}\"\n",
            "\n",
            "\n",
            "def count_words(text):\n",
            "    \"\"\"Counts the words in the input text.\"\"\"\n",
            "    try:\n",
            "        words = nltk.word_tokenize(text)\n",
            "        return len(words)\n",
            "    except Exception as e:\n",
            "        return f\"Error counting words: {e}\"\n",
            "\n",
            "\n",
            "def main():\n",
            "    \"\"\"Main function to execute the plan.\"\"\"\n",
            "    paragraph = input(\"Enter a paragraph of text: \")\n",
            "\n",
            "    if not paragraph.strip():\n",
            "        print(\"Error: Input cannot be empty.\")\n",
            "        return\n",
            "\n",
            "    summary = summarize_text(paragraph)\n",
            "    original_word_count = count_words(paragraph)\n",
            "    summary_word_count = count_words(summary)\n",
            "\n",
            "    print(\"\\n--- Summary ---\\n\")\n",
            "    print(summary)\n",
            "    print(\"\\n--- Word Counts ---\\n\")\n",
            "    print(f\"Original Paragraph: {original_word_count} words\")\n",
            "    print(f\"Summary: {summary_word_count} words\")\n",
            "\n",
            "\n",
            "if __name__ == \"__main__\":\n",
            "    main()\n",
            "\n",
            "```\n",
            "\n",
            "This improved code addresses the prompt's requirements:\n",
            "\n",
            "1. **Input:** Prompts the user for a paragraph.\n",
            "2. **Summarization:** Uses the `transformers` library for a more robust summarization (requires installation: `pip install transformers`).  Handles potential errors during summarization.\n",
            "3. **Word Counting:** Uses `nltk` for accurate word tokenization, handling punctuation. Includes error handling.\n",
            "4. **Output:** Clearly displays the summary and word counts.\n",
            "5. **Error Handling:** Checks for empty input and handles errors in summarization and word counting.\n",
            "\n",
            "\n",
            "To run this code:\n",
            "\n",
            "1.  Make sure you have `transformers` and `nltk` installed:  `pip install transformers nltk`\n",
            "2.  Run the Python script.  It will prompt you to enter a paragraph.\n",
            "\n",
            "\n",
            "Example usage:\n",
            "\n",
            "```\n",
            "Enter a paragraph of text: The quick brown fox jumps over the lazy dog. This is a simple sentence.  Another sentence follows.  And yet another, slightly longer one, to test the summarization capabilities.\n",
            "\n",
            "--- Summary ---\n",
            "The quick brown fox jumps over the lazy dog. This is a simple sentence. Another sentence follows.\n",
            "--- Word Counts ---\n",
            "Original Paragraph: 29 words\n",
            "Summary: 19 words\n",
            "```\n",
            "\n",
            "REFLECT:\n",
            "COMPLETE\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab94722f"
      },
      "source": [
        "# prompt: app = graph.compile() add comments\n",
        "\n",
        "# Compile the graph into an executable application\n",
        "app = graph.compile()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "app"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "5nnOFXHYzpze",
        "outputId": "83b5de99-fd8c-4287-f30b-dedb4095c219"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x7965a688c390>"
            ],
            "image/png": "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\n"
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UHyZMXkMzqbe"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}