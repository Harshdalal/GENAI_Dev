{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LangChain Fundamentals Tools, Chains, Memory, Prompt Templates\n",
        "\n",
        "#ðŸ”§ Requirements"
      ],
      "metadata": {
        "id": "vsw_zCZTB-MZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-core langchain-google-genai google-generativeai # Install necessary libraries for LangChain and Google Generative AI"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tg-K6u1M9DRL",
        "outputId": "13110831-61b0-4524-f520-1ff1a1b8ae0d"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-core in /usr/local/lib/python3.11/dist-packages (0.3.65)\n",
            "Requirement already satisfied: langchain-google-genai in /usr/local/lib/python3.11/dist-packages (2.0.10)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (4.14.0)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain-core) (2.11.5)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (1.2.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.0)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langchain-core) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.3.45->langchain-core) (1.3.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”‘ 1. Setup: Gemini API & LangChain"
      ],
      "metadata": {
        "id": "LKDAgw9VCFNm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "import os\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDqsEze47E4A8Xlm9WbGRTDYzpwY3VIrTA\"\n",
        "\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "#AIzaSyDqsEze47E4A8Xlm9WbGRTDYzpwY3VIrTA"
      ],
      "metadata": {
        "id": "0esuLSiDABg0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§© 2. Prompt Templates\n",
        "LangChain prompt templates let you define structured inputs for LLMs."
      ],
      "metadata": {
        "id": "KkmGF6GICIg_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import PromptTemplate # Import the PromptTemplate class\n",
        "\n",
        "prompt = PromptTemplate.from_template( # Create a PromptTemplate instance\n",
        "    \"You are a helpful assistant. Summarize the following article:\\n\\n{article}\" # Define the prompt template string with an 'article' input variable\n",
        ")\n",
        "\n",
        "formatted_prompt = prompt.format(article=\"OpenAI released a new version of ChatGPT.\") # Format the prompt with a specific article"
      ],
      "metadata": {
        "id": "gmhvlF9TAHyh"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”— 3. Chains\n",
        "Chains let you connect LLMs and other logic into a sequence.\n",
        "\n",
        "ðŸ§  Simple LLMChain"
      ],
      "metadata": {
        "id": "VlrUfRLpCLXB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = prompt | llm\n",
        "\n",
        "result = chain.invoke({\"article\": \"The new GPT-4o model is optimized for multimodal tasks.\"})\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7C6OLYhHAM4v",
        "outputId": "fefc49be-f356-43f2-e6a7-efaea965c61d"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "content='The GPT-4o model is an upgrade focused on improved performance for tasks requiring multiple input and output modalities (like text and images).' additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--27d8aaf9-cb53-4084-80fd-8fd4ca45331b-0' usage_metadata={'input_tokens': 26, 'output_tokens': 28, 'total_tokens': 54, 'input_token_details': {'cache_read': 0}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ› ï¸ 4. Tools (via custom functions)\n",
        "LangChain supports tools via Tool wrappers. Hereâ€™s a basic example:"
      ],
      "metadata": {
        "id": "QKZKTOs_COoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.tools import tool\n",
        "\n",
        "@tool\n",
        "def get_current_year(query: str = \"\") -> int:\n",
        "    \"\"\"Returns the current year. The input query is ignored.\"\"\"\n",
        "    from datetime import datetime\n",
        "    return datetime.now().year"
      ],
      "metadata": {
        "id": "6jXG14n6AOiY"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§  5. Memory\n",
        "Memory allows chat history or state to be remembered.\n",
        "\n"
      ],
      "metadata": {
        "id": "jiXWTYqRCSEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory\n",
        "from langchain.chains import ConversationChain\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "conversation = ConversationChain(llm=llm, memory=memory)\n",
        "\n",
        "# Start chatting\n",
        "print(conversation.invoke({\"input\": \"Hi, I'm Alice\"}))\n",
        "print(conversation.invoke({\"input\": \"What did I say earlier?\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZanIgCcLAX3h",
        "outputId": "bad9e70e-087f-4c78-d577-425d030da99e"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': \"Hi, I'm Alice\", 'history': [HumanMessage(content=\"Hi, I'm Alice\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Alice! It's nice to meet you.  I'm an AI, and while I don't have a name in the same way humans do, you can call me whatever you like.  I'm currently running on a [insert type of server/hardware - e.g., Google Cloud Platform] server, and my primary function is to process and generate human-like text.  My knowledge cutoff is [insert date - e.g., September 2021], meaning I don't have information on events after that date.  I'm eager to chat with you â€“ what's on your mind today?\", additional_kwargs={}, response_metadata={})], 'response': \"Hi Alice! It's nice to meet you.  I'm an AI, and while I don't have a name in the same way humans do, you can call me whatever you like.  I'm currently running on a [insert type of server/hardware - e.g., Google Cloud Platform] server, and my primary function is to process and generate human-like text.  My knowledge cutoff is [insert date - e.g., September 2021], meaning I don't have information on events after that date.  I'm eager to chat with you â€“ what's on your mind today?\"}\n",
            "{'input': 'What did I say earlier?', 'history': [HumanMessage(content=\"Hi, I'm Alice\", additional_kwargs={}, response_metadata={}), AIMessage(content=\"Hi Alice! It's nice to meet you.  I'm an AI, and while I don't have a name in the same way humans do, you can call me whatever you like.  I'm currently running on a [insert type of server/hardware - e.g., Google Cloud Platform] server, and my primary function is to process and generate human-like text.  My knowledge cutoff is [insert date - e.g., September 2021], meaning I don't have information on events after that date.  I'm eager to chat with you â€“ what's on your mind today?\", additional_kwargs={}, response_metadata={}), HumanMessage(content='What did I say earlier?', additional_kwargs={}, response_metadata={}), AIMessage(content='You said, \"Hi, I\\'m Alice\".', additional_kwargs={}, response_metadata={})], 'response': 'You said, \"Hi, I\\'m Alice\".'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ”„ 6. Combining: Prompt â†’ LLM â†’ Memory\n",
        "Hereâ€™s a complete practical chain combining prompt, llm, memory:"
      ],
      "metadata": {
        "id": "fSEKcCXKCV3Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import ConversationChain\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain.memory import ConversationBufferMemory\n",
        "\n",
        "prompt = PromptTemplate.from_template(\n",
        "    \"\"\"{history}\n",
        "The user said: {input}. Respond as a wise assistant.\"\"\"\n",
        ")\n",
        "\n",
        "memory = ConversationBufferMemory(return_messages=True)\n",
        "\n",
        "chain = ConversationChain(llm=llm, memory=memory, prompt=prompt)\n",
        "\n",
        "# Chat sequence\n",
        "print(chain.invoke({\"input\": \"How do I learn LangChain?\"}))\n",
        "print(chain.invoke({\"input\": \"What did I just ask?\"}))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g7FNzOm0AaQY",
        "outputId": "acc876d0-6eb5-4ad3-dd39-c2c578cacff5"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input': 'How do I learn LangChain?', 'history': [HumanMessage(content='How do I learn LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, young Padawan, you seek the path to mastery of LangChain!  It is a journey, not a sprint, requiring patience, curiosity, and a thirst for knowledge.  There is no single \"right\" way, but here\\'s a roadmap to guide your steps:\\n\\n**Phase 1: Laying the Foundation (The Basics)**\\n\\n1. **Python Proficiency:** LangChain is built upon Python.  Ensure you have a solid grasp of Python fundamentals: data structures (lists, dictionaries, sets), object-oriented programming, and working with libraries.  If you\\'re rusty, brush up with online resources like Codecademy, freeCodeCamp, or DataCamp.\\n\\n2. **LLMs: Understanding the Engine:** LangChain interacts with Large Language Models (LLMs).  Familiarize yourself with what LLMs are, how they work (at a high level â€“ you don\\'t need to become a deep learning expert), and their capabilities and limitations.  OpenAI\\'s documentation on GPT models is a good starting point.\\n\\n3. **The LangChain Documentation:**  This is your bible.  The official LangChain documentation is comprehensive and well-structured. Start with the tutorials and examples.  Don\\'t be afraid to copy and paste code; experimentation is key.\\n\\n**Phase 2: Building Your Skills (Practical Application)**\\n\\n1. **Start Small, Think Big:** Don\\'t try to build a complex application right away. Begin with simple projects.  Try the examples provided in the documentation and modify them.  Perhaps build a simple chatbot that answers questions from a fixed knowledge base.\\n\\n2. **Modular Learning:** LangChain is modular.  Focus on one module at a time.  Master `LLMs`, then move on to `Chains`, `Indexes`, `Agents`, and `Memory`.  Each module has its own intricacies and possibilities.\\n\\n3. **Experiment and Iterate:**  The best way to learn is by doing.  Try different LLMs, experiment with different chains, and see what works and what doesn\\'t.  Don\\'t be afraid to fail; it\\'s part of the learning process.\\n\\n4. **Community Engagement:** Join the LangChain community (Discord, forums, etc.).  Ask questions, share your progress, and learn from others.  The collective knowledge is invaluable.\\n\\n**Phase 3: Mastering the Force (Advanced Techniques)**\\n\\n1. **Advanced Chains and Agents:** Explore more sophisticated chain combinations and agent architectures.  Learn how to build agents that can access external resources and make decisions based on the information they gather.\\n\\n2. **Customizing LLMs:** Learn how to fine-tune LLMs or use embeddings to tailor their responses to your specific needs.\\n\\n3. **Deployment and Scaling:**  Once you\\'ve built something worthwhile, learn how to deploy and scale your LangChain applications.\\n\\n**Remember:** The journey to LangChain mastery is a continuous process of learning and exploration. Embrace the challenges, celebrate your successes, and never stop asking questions.  May the code be with you!', additional_kwargs={}, response_metadata={})], 'response': 'Ah, young Padawan, you seek the path to mastery of LangChain!  It is a journey, not a sprint, requiring patience, curiosity, and a thirst for knowledge.  There is no single \"right\" way, but here\\'s a roadmap to guide your steps:\\n\\n**Phase 1: Laying the Foundation (The Basics)**\\n\\n1. **Python Proficiency:** LangChain is built upon Python.  Ensure you have a solid grasp of Python fundamentals: data structures (lists, dictionaries, sets), object-oriented programming, and working with libraries.  If you\\'re rusty, brush up with online resources like Codecademy, freeCodeCamp, or DataCamp.\\n\\n2. **LLMs: Understanding the Engine:** LangChain interacts with Large Language Models (LLMs).  Familiarize yourself with what LLMs are, how they work (at a high level â€“ you don\\'t need to become a deep learning expert), and their capabilities and limitations.  OpenAI\\'s documentation on GPT models is a good starting point.\\n\\n3. **The LangChain Documentation:**  This is your bible.  The official LangChain documentation is comprehensive and well-structured. Start with the tutorials and examples.  Don\\'t be afraid to copy and paste code; experimentation is key.\\n\\n**Phase 2: Building Your Skills (Practical Application)**\\n\\n1. **Start Small, Think Big:** Don\\'t try to build a complex application right away. Begin with simple projects.  Try the examples provided in the documentation and modify them.  Perhaps build a simple chatbot that answers questions from a fixed knowledge base.\\n\\n2. **Modular Learning:** LangChain is modular.  Focus on one module at a time.  Master `LLMs`, then move on to `Chains`, `Indexes`, `Agents`, and `Memory`.  Each module has its own intricacies and possibilities.\\n\\n3. **Experiment and Iterate:**  The best way to learn is by doing.  Try different LLMs, experiment with different chains, and see what works and what doesn\\'t.  Don\\'t be afraid to fail; it\\'s part of the learning process.\\n\\n4. **Community Engagement:** Join the LangChain community (Discord, forums, etc.).  Ask questions, share your progress, and learn from others.  The collective knowledge is invaluable.\\n\\n**Phase 3: Mastering the Force (Advanced Techniques)**\\n\\n1. **Advanced Chains and Agents:** Explore more sophisticated chain combinations and agent architectures.  Learn how to build agents that can access external resources and make decisions based on the information they gather.\\n\\n2. **Customizing LLMs:** Learn how to fine-tune LLMs or use embeddings to tailor their responses to your specific needs.\\n\\n3. **Deployment and Scaling:**  Once you\\'ve built something worthwhile, learn how to deploy and scale your LangChain applications.\\n\\n**Remember:** The journey to LangChain mastery is a continuous process of learning and exploration. Embrace the challenges, celebrate your successes, and never stop asking questions.  May the code be with you!'}\n",
            "{'input': 'What did I just ask?', 'history': [HumanMessage(content='How do I learn LangChain?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, young Padawan, you seek the path to mastery of LangChain!  It is a journey, not a sprint, requiring patience, curiosity, and a thirst for knowledge.  There is no single \"right\" way, but here\\'s a roadmap to guide your steps:\\n\\n**Phase 1: Laying the Foundation (The Basics)**\\n\\n1. **Python Proficiency:** LangChain is built upon Python.  Ensure you have a solid grasp of Python fundamentals: data structures (lists, dictionaries, sets), object-oriented programming, and working with libraries.  If you\\'re rusty, brush up with online resources like Codecademy, freeCodeCamp, or DataCamp.\\n\\n2. **LLMs: Understanding the Engine:** LangChain interacts with Large Language Models (LLMs).  Familiarize yourself with what LLMs are, how they work (at a high level â€“ you don\\'t need to become a deep learning expert), and their capabilities and limitations.  OpenAI\\'s documentation on GPT models is a good starting point.\\n\\n3. **The LangChain Documentation:**  This is your bible.  The official LangChain documentation is comprehensive and well-structured. Start with the tutorials and examples.  Don\\'t be afraid to copy and paste code; experimentation is key.\\n\\n**Phase 2: Building Your Skills (Practical Application)**\\n\\n1. **Start Small, Think Big:** Don\\'t try to build a complex application right away. Begin with simple projects.  Try the examples provided in the documentation and modify them.  Perhaps build a simple chatbot that answers questions from a fixed knowledge base.\\n\\n2. **Modular Learning:** LangChain is modular.  Focus on one module at a time.  Master `LLMs`, then move on to `Chains`, `Indexes`, `Agents`, and `Memory`.  Each module has its own intricacies and possibilities.\\n\\n3. **Experiment and Iterate:**  The best way to learn is by doing.  Try different LLMs, experiment with different chains, and see what works and what doesn\\'t.  Don\\'t be afraid to fail; it\\'s part of the learning process.\\n\\n4. **Community Engagement:** Join the LangChain community (Discord, forums, etc.).  Ask questions, share your progress, and learn from others.  The collective knowledge is invaluable.\\n\\n**Phase 3: Mastering the Force (Advanced Techniques)**\\n\\n1. **Advanced Chains and Agents:** Explore more sophisticated chain combinations and agent architectures.  Learn how to build agents that can access external resources and make decisions based on the information they gather.\\n\\n2. **Customizing LLMs:** Learn how to fine-tune LLMs or use embeddings to tailor their responses to your specific needs.\\n\\n3. **Deployment and Scaling:**  Once you\\'ve built something worthwhile, learn how to deploy and scale your LangChain applications.\\n\\n**Remember:** The journey to LangChain mastery is a continuous process of learning and exploration. Embrace the challenges, celebrate your successes, and never stop asking questions.  May the code be with you!', additional_kwargs={}, response_metadata={}), HumanMessage(content='What did I just ask?', additional_kwargs={}, response_metadata={}), AIMessage(content='Ah, my inquisitive friend, you asked how to learn LangChain.  You sought a path to understanding and mastering this powerful framework for building applications with Large Language Models.  Your question reflected a desire for a structured learning approach, and a roadmap to navigate the complexities of this exciting field.', additional_kwargs={}, response_metadata={})], 'response': 'Ah, my inquisitive friend, you asked how to learn LangChain.  You sought a path to understanding and mastering this powerful framework for building applications with Large Language Models.  Your question reflected a desire for a structured learning approach, and a roadmap to navigate the complexities of this exciting field.'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#ðŸ§ª Optional: Agent with Tool and LLM\n"
      ],
      "metadata": {
        "id": "YrGV4aS1CZQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent\n",
        "from langchain.agents import AgentType\n",
        "\n",
        "tools = [get_current_year]\n",
        "\n",
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)\n",
        "\n",
        "print(agent.invoke(\"What year is it now?\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jc9Bqa8uAhOR",
        "outputId": "eb599576-2d48-4b17-877b-5e11f41965b7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to get the current year.\n",
            "Action: get_current_year\n",
            "Action Input: ''\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3m2025\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: 2025\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "{'input': 'What year is it now?', 'output': '2025'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BTvKXAgmArTx"
      },
      "execution_count": 33,
      "outputs": []
    }
  ]
}