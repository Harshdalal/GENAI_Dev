{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#1.ğŸ§ª Practical: Build a Document Summarization Agent using LangChain + Gemini\n",
        "\n",
        "#âœ… Objective\n",
        "\n",
        "Load a document\n",
        "\n",
        "Use LangChain to create a summarization chain\n",
        "\n",
        "Plug in Gemini as the LLM using GoogleGenerativeAI\n",
        "\n",
        "Output a summary"
      ],
      "metadata": {
        "id": "oi0bhg_T7ZwK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 1: Install Gemini SDK"
      ],
      "metadata": {
        "id": "eCDg__ph7Ztd"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j-g5nrY557kB",
        "outputId": "e7afdb07-a3e6-4526-8a58-fd7457ad8cf7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.0/1.3 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[90mâ•º\u001b[0m\u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m0.3/1.3 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[91mâ•¸\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.5 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q --upgrade langchain langchain-community google-generativeai\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 2:  Set Up Gemini LLM in LangChain"
      ],
      "metadata": {
        "id": "pD0Tl8eM8G3V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.docstore.document import Document\n"
      ],
      "metadata": {
        "id": "ydpFQ-m07aOv"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# ğŸ” Replace with your Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyCOQXtLBKUXIlw4p-jarVeENvtvmnBPLiw\"\n",
        "\n",
        "\n",
        "# Load Gemini 1.5 Flash\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\", temperature=0.3)\n"
      ],
      "metadata": {
        "id": "qPuaf3KrNDLZ"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 3: Load and Prepare Document\n",
        "You can load .txt or .docx files. Here's a sample using raw text:"
      ],
      "metadata": {
        "id": "OhnBJQt08I2P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample text (you can also load from file)\n",
        "text = \"\"\"\n",
        "Artificial Intelligence (AI) is rapidly transforming many aspects of our lives, including healthcare, education, and business.\n",
        "By automating tasks, providing decision support, and enabling personalization, AI technologies are improving efficiency\n",
        "and driving innovation. However, there are also ethical concerns such as privacy, bias, and job displacement that need to be addressed.\n",
        "\"\"\"\n",
        "\n",
        "# Wrap text in a LangChain Document\n",
        "docs = [Document(page_content=text)]\n"
      ],
      "metadata": {
        "id": "itlKMUde7g8Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ğŸ”¹ Step 4: Build a Summarization Chain"
      ],
      "metadata": {
        "id": "_Wb1sgGm8LLJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load summarization chain (basic version using \"stuff\" strategy)\n",
        "chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "# Run the chain on the document\n",
        "summary = chain.run(docs)\n",
        "\n",
        "# Show the summary\n",
        "print(\"ğŸ“„ Document Summary:\\n\")\n",
        "print(summary)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DnXTUjNO7iaM",
        "outputId": "7d2d67cc-446f-457f-923a-c8dbc154a6a4"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“„ Document Summary:\n",
            "\n",
            "AI is revolutionizing various sectors, boosting efficiency and innovation, but raises ethical concerns about privacy, bias, and job losses.\n"
          ]
        }
      ]
    }
  ]
}