{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Test Fail-Safe Handling and Memory Debugging in LangGraph\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "UzEsOW9zZdYw"
      },
      "id": "UzEsOW9zZdYw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment focuses on two critical aspects of robust LangGraph application development:\n",
        "1.  **Fail-Safe Handling**: Designing a LangGraph workflow that can gracefully handle errors or unexpected outcomes in one of its nodes, preventing a complete crash and allowing for alternative execution paths.\n",
        "2.  **Memory Debugging**: Understanding and inspecting the state (memory) of the LangGraph workflow at each step of its execution to effectively debug and trace data flow."
      ],
      "metadata": {
        "id": "nLw3nozyZdYy"
      },
      "id": "nLw3nozyZdYy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "FV-jWKHUZdYz"
      },
      "id": "FV-jWKHUZdYz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **Environment Setup**: Install the necessary Python libraries: `pip install langgraph langchain_core`.\n",
        "2.  **Jupyter Notebook**: All your code, outputs, observations, and analysis must be documented in this Jupyter Notebook.\n",
        "3.  **Workflow Scenario**: You will build a three-node workflow for a simulated data processing task:\n",
        "    * **Data Fetcher**: Simulates fetching data, which can *sometimes fail*.\n",
        "    * **Data Processor**: Processes the fetched data.\n",
        "    * **Report Generator**: Generates a final report.\n",
        "4.  **Fail-Safe Implementation**: If the `Data Fetcher` node fails, the graph should skip the `Data Processor` and directly transition to the `Report Generator`, which will then generate an \"error report\" or a report indicating data unavailability.\n",
        "5.  **Memory Debugging**: Use LangGraph's streaming capabilities (`app.stream()`) to observe and print the state of the graph after each node's execution. Add print statements within nodes to show intermediate data and state updates.\n",
        "6.  **Analysis**: Critically evaluate your implementation of fail-safe mechanisms and demonstrate your ability to debug the graph's memory."
      ],
      "metadata": {
        "id": "4d129wiQZdYz"
      },
      "id": "4d129wiQZdYz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "pRHP-KX5ZdY0"
      },
      "id": "pRHP-KX5ZdY0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and Workflow State Definition\n",
        "Begin by setting up your environment and defining the state your LangGraph workflow will manage."
      ],
      "metadata": {
        "id": "EfJ6zq2TZdY0"
      },
      "id": "EfJ6zq2TZdY0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: Install Libraries\n",
        "Ensure `langgraph` and `langchain_core` are installed."
      ],
      "metadata": {
        "id": "51hTHICYZdY0"
      },
      "id": "51hTHICYZdY0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Install necessary libraries (if not already installed)\n",
        "# !pip install langgraph langchain_core --quiet\n",
        "\n",
        "from typing import TypedDict, Optional\n",
        "from langgraph.graph import StateGraph, END\n",
        "import random # For simulating random failures\n",
        "\n",
        "print(\"Libraries imported!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "0Ek48C2nZdY0"
      },
      "id": "0Ek48C2nZdY0",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Define Workflow State\n",
        "Define a `TypedDict` to represent the state of your LangGraph workflow. This state will hold all necessary information as it passes through the nodes."
      ],
      "metadata": {
        "id": "bxBcR3NkZdY1"
      },
      "id": "bxBcR3NkZdY1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* `query`: The initial request or topic for data fetching.\n",
        "* `raw_data`: The data fetched by the `Data Fetcher` node.\n",
        "* `processed_data`: The data after being processed by the `Data Processor` node.\n",
        "* `report`: The final report generated.\n",
        "* `fetch_success`: A boolean flag indicating if data fetching was successful (crucial for fail-safe).\n",
        "* `error_message`: A string to store any error messages during data fetching."
      ],
      "metadata": {
        "id": "usbq2-l2ZdY2"
      },
      "id": "usbq2-l2ZdY2"
    },
    {
      "cell_type": "code",
      "source": [
        "class DataWorkflowState(TypedDict):\n",
        "    query: str\n",
        "    raw_data: Optional[str]\n",
        "    processed_data: Optional[str]\n",
        "    report: Optional[str]\n",
        "    fetch_success: bool\n",
        "    error_message: Optional[str]\n",
        "\n",
        "print(\"DataWorkflowState defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "fU17mb1uZdY2"
      },
      "id": "fU17mb1uZdY2",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "GrmdB1qCZdY2"
      },
      "id": "GrmdB1qCZdY2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Define Nodes with Fail-Safe Handling\n",
        "Create the nodes, incorporating error handling and state updates for graceful failure."
      ],
      "metadata": {
        "id": "2TnCP7o3ZdY3"
      },
      "id": "2TnCP7o3ZdY3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: `fetch_data_node` (with controlled failure)\n",
        "This node simulates fetching data. Implement a mechanism where it *can fail* based on a probability or a specific input. If it fails, update the state accordingly (set `fetch_success` to `False` and populate `error_message`). Use `try-except` blocks."
      ],
      "metadata": {
        "id": "dmMyfNqEZdY3"
      },
      "id": "dmMyfNqEZdY3"
    },
    {
      "cell_type": "code",
      "source": [
        "def fetch_data_node(state: DataWorkflowState) -> DataWorkflowState:\n",
        "    print(f\"\\n--- Node: fetch_data_node (Query: {state['query']}) ---\")\n",
        "    query = state[\"query\"]\n",
        "\n",
        "    # Simulate a failure condition (e.g., 30% chance of failure)\n",
        "    # Or, make it fail if query contains a specific keyword like 'fail_data_fetch'\n",
        "    should_fail = random.random() < 0.3 or \"fail_data_fetch\" in query.lower()\n",
        "\n",
        "    if should_fail:\n",
        "        print(\"Simulating data fetch FAILURE!\")\n",
        "        return {\n",
        "            \"raw_data\": None,\n",
        "            \"fetch_success\": False,\n",
        "            \"error_message\": f\"Failed to fetch data for '{query}' due to a simulated network error.\"\n",
        "        }\n",
        "    else:\n",
        "        print(\"Simulating data fetch SUCCESS.\")\n",
        "        simulated_data = f\"Successfully fetched sales data for {query}. Key metrics: Revenue up 10%, Customers up 5%, Satisfaction 85%.\"\n",
        "        return {\n",
        "            \"raw_data\": simulated_data,\n",
        "            \"fetch_success\": True,\n",
        "            \"error_message\": None\n",
        "        }\n",
        "\n",
        "print(\"fetch_data_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "GW6csvU9ZdY3"
      },
      "id": "GW6csvU9ZdY3",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.2: `process_data_node`\n",
        "This node processes the fetched data. It should only proceed if `fetch_success` is `True` in the state. Otherwise, it should skip processing and leave `processed_data` as `None`."
      ],
      "metadata": {
        "id": "o6D6nlEfZdY3"
      },
      "id": "o6D6nlEfZdY3"
    },
    {
      "cell_type": "code",
      "source": [
        "def process_data_node(state: DataWorkflowState) -> DataWorkflowState:\n",
        "    print(f\"\\n--- Node: process_data_node (Fetch Success: {state['fetch_success']}) ---\")\n",
        "    if not state[\"fetch_success\"]:\n",
        "        print(\"Skipping data processing due to previous fetch failure.\")\n",
        "        return {\"processed_data\": None}\n",
        "    else:\n",
        "        raw_data = state[\"raw_data\"]\n",
        "        # Simulate data processing\n",
        "        processed_data = f\"Processed data: Derived key insights from '{raw_data}'. Identified growth opportunities in Q3 and risk factors related to customer churn.\"\n",
        "        print(\"Data successfully processed.\")\n",
        "        return {\"processed_data\": processed_data}\n",
        "\n",
        "print(\"process_data_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "V3mdcjMhZdY3"
      },
      "id": "V3mdcjMhZdY3",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.3: `generate_report_node`\n",
        "This node generates the final report. Its content should depend on whether data fetching and processing were successful. If `fetch_success` is `False`, generate an \"Error Report\"; otherwise, generate a report based on `processed_data`."
      ],
      "metadata": {
        "id": "EQ7bp4BBZdY4"
      },
      "id": "EQ7bp4BBZdY4"
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_report_node(state: DataWorkflowState) -> DataWorkflowState:\n",
        "    print(f\"\\n--- Node: generate_report_node (Fetch Success: {state['fetch_success']}) ---\")\n",
        "    if not state[\"fetch_success\"]:\n",
        "        report = f\"Error Report for Query: {state['query']}\\n\\nData Fetching Status: Failed\\nReason: {state['error_message']}\\n\\nCould not generate a full report due to data acquisition failure. Please investigate the data source or retry with a different query.\"\n",
        "        print(\"Generated error report.\")\n",
        "    else:\n",
        "        processed_data = state[\"processed_data\"]\n",
        "        report = f\"Comprehensive Report for Query: {state['query']}\\n\\n-- Raw Data Summary --\\n{state['raw_data']}\\n\\n-- Processed Insights --\\n{processed_data}\\n\\n-- Conclusion --\\nBased on the analysis, significant opportunities for growth are present, but require strategic investment in identified areas.\"\n",
        "        print(\"Generated full report.\")\n",
        "    return {\"report\": report}\n",
        "\n",
        "print(\"generate_report_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "KrRtIhCFZdY4"
      },
      "id": "KrRtIhCFZdY4",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "kFbDfku9ZdY4"
      },
      "id": "kFbDfku9ZdY4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Construct and Execute the LangGraph Workflow\n",
        "Combine your nodes into a `StateGraph`, define conditional edges for fail-safe handling, and execute the workflow while observing its state."
      ],
      "metadata": {
        "id": "0_Byf4bfZdY4"
      },
      "id": "0_Byf4bfZdY4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Define Conditional Edge Logic\n",
        "Create a function that will determine the next node based on the `fetch_success` flag in the state. This is your routing logic for fail-safe handling."
      ],
      "metadata": {
        "id": "S8nOEi1SZdY5"
      },
      "id": "S8nOEi1SZdY5"
    },
    {
      "cell_type": "code",
      "source": [
        "def route_after_fetch(state: DataWorkflowState) -> str:\n",
        "    print(f\"\\n--- Router: route_after_fetch (Current fetch_success: {state['fetch_success']}) ---\")\n",
        "    if state[\"fetch_success\"]:\n",
        "        print(\"Routing to 'process_data' node.\")\n",
        "        return \"process_data\"\n",
        "    else:\n",
        "        print(\"Routing directly to 'generate_report' due to fetch failure.\")\n",
        "        return \"generate_report\"\n",
        "\n",
        "print(\"route_after_fetch router defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "6ryJS1GDZdY5"
      },
      "id": "6ryJS1GDZdY5",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.2: Build and Compile the Graph\n",
        "Assemble the nodes and define the edges, including the conditional edge for fail-safe handling."
      ],
      "metadata": {
        "id": "3gT8eorMZdY5"
      },
      "id": "3gT8eorMZdY5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Nodes**: Add `fetch_data_node`, `process_data_node`, `generate_report_node`.\n",
        "* **Entry Point**: Start at `fetch_data_node`.\n",
        "* **Conditional Edge**: From `fetch_data_node`, use `add_conditional_edges` with `route_after_fetch`.\n",
        "* **Standard Edges**: From `process_data_node` to `generate_report_node`.\n",
        "* **End Point**: From `generate_report_node` to `END`."
      ],
      "metadata": {
        "id": "4U-8fbCDZdY5"
      },
      "id": "4U-8fbCDZdY5"
    },
    {
      "cell_type": "code",
      "source": [
        "# Build the graph\n",
        "workflow = StateGraph(DataWorkflowState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"fetch_data\", fetch_data_node)\n",
        "workflow.add_node(\"process_data\", process_data_node)\n",
        "workflow.add_node(\"generate_report\", generate_report_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"fetch_data\")\n",
        "\n",
        "# Define conditional edge from fetch_data\n",
        "workflow.add_conditional_edges(\n",
        "    \"fetch_data\",\n",
        "    route_after_fetch,\n",
        "    {\n",
        "        \"process_data\": \"process_data\",\n",
        "        \"generate_report\": \"generate_report\" # Directly to report if fetch failed\n",
        "    }\n",
        ")\n",
        "\n",
        "# Define direct edge from process_data to generate_report\n",
        "workflow.add_edge(\"process_data\", \"generate_report\")\n",
        "\n",
        "# Define exit point\n",
        "workflow.add_edge(\"generate_report\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"LangGraph workflow compiled!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Kz47VXp7ZdY5"
      },
      "id": "Kz47VXp7ZdY5",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.3: Execute Workflow (Success Scenario)\n",
        "Run the compiled `app` with an input that is likely to succeed (e.g., no `fail_data_fetch` keyword). Observe the full state updates at each step to see how data flows and is transformed."
      ],
      "metadata": {
        "id": "1HSEYxR7ZdY6"
      },
      "id": "1HSEYxR7ZdY6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n=========== Running Workflow (Success Scenario) ===========\")\n",
        "initial_state_success = {\n",
        "    \"query\": \"Q2 2024 Market Trends\",\n",
        "    \"raw_data\": None, \"processed_data\": None, \"report\": None,\n",
        "    \"fetch_success\": False, \"error_message\": None\n",
        "}\n",
        "\n",
        "final_state_success = None\n",
        "for state_update in app.stream(initial_state_success):\n",
        "    print(\"\\n[LangGraph State Update]:\")\n",
        "    for key, value in state_update.items():\n",
        "        # Print only the latest update for each key, or the whole state if it's the full step output\n",
        "        if isinstance(value, dict) and 'node' in value:\n",
        "            print(f\"  Node '{value['node']}': {value}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "    final_state_success = state_update # Keep track of the last state\n",
        "\n",
        "print(\"\\n--- Workflow Execution Complete (Success) --- \")\n",
        "print(\"Final Report:\\n\", final_state_success.get('report', 'N/A'))"
      ],
      "outputs": [],
      "metadata": {
        "id": "tvgr97bVZdY6"
      },
      "id": "tvgr97bVZdY6",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.4: Execute Workflow (Failure Scenario)\n",
        "Run the compiled `app` with an input that *will guarantee failure* in the `fetch_data_node` (e.g., by including the `fail_data_fetch` keyword in the query). Observe how the graph handles the failure and the resulting report."
      ],
      "metadata": {
        "id": "xmtm0Mo6ZdY6"
      },
      "id": "xmtm0Mo6ZdY6"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n\\n=========== Running Workflow (Failure Scenario) ===========\")\n",
        "initial_state_failure = {\n",
        "    \"query\": \"Recent Stock Market Data (fail_data_fetch)\", # Trigger failure\n",
        "    \"raw_data\": None, \"processed_data\": None, \"report\": None,\n",
        "    \"fetch_success\": False, \"error_message\": None\n",
        "}\n",
        "\n",
        "final_state_failure = None\n",
        "for state_update in app.stream(initial_state_failure):\n",
        "    print(\"\\n[LangGraph State Update]:\")\n",
        "    for key, value in state_update.items():\n",
        "        if isinstance(value, dict) and 'node' in value:\n",
        "            print(f\"  Node '{value['node']}': {value}\")\n",
        "        else:\n",
        "            print(f\"  {key}: {value}\")\n",
        "    final_state_failure = state_update # Keep track of the last state\n",
        "\n",
        "print(\"\\n--- Workflow Execution Complete (Failure) --- \")\n",
        "print(\"Final Report:\\n\", final_state_failure.get('report', 'N/A'))"
      ],
      "outputs": [],
      "metadata": {
        "id": "vTDzIZhuZdY6"
      },
      "id": "vTDzIZhuZdY6",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "gZT8lw_hZdY6"
      },
      "id": "gZT8lw_hZdY6"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Analysis and Reflection\n",
        "Provide a comprehensive summary of your findings and reflections based on this assignment."
      ],
      "metadata": {
        "id": "ZNQUy-XWZdY7"
      },
      "id": "ZNQUy-XWZdY7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.1: Fail-Safe Handling Analysis\n",
        "* **How was fail-safe handled?**: Describe the mechanism you implemented to handle the failure in `fetch_data_node`. How did the graph's execution path change?\n",
        "* **Effectiveness**: Was the fail-safe mechanism effective in preventing a full workflow crash? Did it produce a meaningful output in the failure scenario?\n",
        "* **Alternative Strategies**: What other strategies could be used for fail-safe handling in LangGraph (e.g., retries, human-in-the-loop, more granular error types)? When would you use them?"
      ],
      "metadata": {
        "id": "FupCufhKZdY7"
      },
      "id": "FupCufhKZdY7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.2: Memory Debugging Analysis\n",
        "* **Observing State**: How did `app.stream()` help you understand the state of the graph at each step? What specific information was visible, and how did it change?\n",
        "* **Debugging Insights**: Provide an example from your `app.stream()` output (either success or failure scenario) that illustrates how you used the state updates to debug or confirm the data flow.\n",
        "* **Importance of State**: Why is maintaining and being able to inspect the graph's state crucial for debugging complex multi-step LLM applications?\n",
        "* **Challenges in Debugging**: What might be challenging when debugging memory in larger, more complex LangGraph applications? How could you mitigate these challenges?"
      ],
      "metadata": {
        "id": "ClREtfE_ZdY8"
      },
      "id": "ClREtfE_ZdY8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "lG7qU71MZdY8"
      },
      "id": "lG7qU71MZdY8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission:\n",
        "* Ensure all code cells have been executed and their outputs are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Save your Jupyter Notebook as `[YourName]_LangGraph_FailSafe_Memory_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "ZgpCiFkkZdY8"
      },
      "id": "ZgpCiFkkZdY8"
    }
  ]
}