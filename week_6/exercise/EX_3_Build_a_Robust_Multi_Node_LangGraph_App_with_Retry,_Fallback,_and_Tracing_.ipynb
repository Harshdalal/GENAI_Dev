{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Build a Robust Multi-Node LangGraph App with Retry, Fallback, and Tracing\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "ruoJBepERclq"
      },
      "id": "ruoJBepERclq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment challenges you to design and implement a **resilient multi-node LangGraph application** that incorporates crucial production-ready features: **retry mechanisms, fallback strategies, and comprehensive tracing**. You'll build a workflow that simulates a content generation and review process, demonstrating how to handle potential failures gracefully and monitor your agent's execution. This project will deepen your understanding of building robust and observable LLM-powered applications."
      ],
      "metadata": {
        "id": "-zTVvHWIRcls"
      },
      "id": "-zTVvHWIRcls"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "t6m7dAcpRcls"
      },
      "id": "t6m7dAcpRcls"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **LLM Access**: You'll need access to an LLM API (e.g., Google's Gemini, OpenAI's GPT-4). For this assignment, we'll primarily use **Google's Gemini Pro model** via the `langchain-google-genai` integration.\n",
        "2.  **Environment Setup**: Install the necessary Python libraries: `pip install langchain-google-genai langgraph langsmith pydantic tenacity`.\n",
        "3.  **API Keys**: Securely handle your LLM API key and your LangSmith API key. It's best practice to load them from environment variables.\n",
        "4.  **Jupyter Notebook**: All your code, outputs, workflow diagrams (if you generate them), observations, and analysis must be documented in this Jupyter Notebook.\n",
        "5.  **Simulated Failures**: You will need to introduce *simulated failures* (e.g., random exceptions, LLM outputting incorrect formats) to test your retry and fallback mechanisms.\n",
        "6.  **Tracing**: Use LangSmith for tracing your workflow executions. Provide screenshots or links to your LangSmith traces.\n",
        "7.  **Analysis**: Critically evaluate your LangGraph workflow's resilience and observability."
      ],
      "metadata": {
        "id": "axVqjVW7Rcls"
      },
      "id": "axVqjVW7Rcls"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "tSXRKnjNRclt"
      },
      "id": "tSXRKnjNRclt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and Workflow State Definition\n",
        "Begin by configuring your LLM and LangSmith, then define the state that your LangGraph workflow will manage."
      ],
      "metadata": {
        "id": "DnX3hDkkRclt"
      },
      "id": "DnX3hDkkRclt"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: API and LangSmith Configuration\n",
        "Set up your Google Generative AI API key and configure LangSmith for tracing. Initialize the `ChatGoogleGenerativeAI` model."
      ],
      "metadata": {
        "id": "6HrwY61gRclu"
      },
      "id": "6HrwY61gRclu"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import random\n",
        "import time\n",
        "from typing import Literal, TypedDict\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed, retry_if_exception_type\n",
        "\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.pydantic_v1 import BaseModel, Field, ValidationError\n",
        "\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "# --- YOUR API KEYS HERE ---\n",
        "# It's highly recommended to load API keys from environment variables for security.\n",
        "# On Linux/macOS: export GOOGLE_API_KEY='your_key' ; export LANGCHAIN_API_KEY='your_key' ; export LANGCHAIN_TRACING_V2='true' ; export LANGCHAIN_PROJECT='your_project_name'\n",
        "# On Windows (cmd): set GOOGLE_API_KEY=your_key & set LANGCHAIN_API_KEY=your_key & set LANGCHAIN_TRACING_V2=true & set LANGCHAIN_PROJECT=your_project_name\n",
        "\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_GOOGLE_API_KEY_HERE\" # Replace with your actual Google API key\n",
        "\n",
        "# Configure LangSmith\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"YOUR_LANGCHAIN_API_KEY_HERE\" # Replace with your actual LangSmith API key\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"LangGraph_Retry_Fallback_Assignment\" # Choose a project name for LangSmith\n",
        "\n",
        "# Initialize the LLM (Gemini Pro)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7) # A bit of temperature for creativity\n",
        "\n",
        "print(\"LLM and LangSmith configured!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "dbizpJoiRclu"
      },
      "id": "dbizpJoiRclu",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Define Workflow State\n",
        "Define a `TypedDict` to represent the state of your LangGraph workflow for content generation and review."
      ],
      "metadata": {
        "id": "I3-6VrAyRclv"
      },
      "id": "I3-6VrAyRclv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Requirements for State**:\n",
        "    * `topic`: The subject of the content to be generated.\n",
        "    * `generated_content`: The text content generated by the LLM (optional, as it's generated later).\n",
        "    * `review_feedback`: Feedback from the review process (optional).\n",
        "    * `status`: Current status of the content (e.g., \"Draft\", \"Needs Review\", \"Approved\", \"Rejected\", \"Failed\").\n",
        "    * `retries_left`: An integer to track how many retries are available for a failed step.\n",
        "    * `error_message`: An optional string to store details of any error that occurred."
      ],
      "metadata": {
        "id": "nT3SXGVjRclv"
      },
      "id": "nT3SXGVjRclv"
    },
    {
      "cell_type": "code",
      "source": [
        "class ContentWorkflowState(TypedDict):\n",
        "    topic: str\n",
        "    generated_content: str\n",
        "    review_feedback: str\n",
        "    status: Literal[\"Draft\", \"Needs Review\", \"Approved\", \"Rejected\", \"Failed\"]\n",
        "    retries_left: int\n",
        "    error_message: str\n",
        "\n",
        "print(\"ContentWorkflowState defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "6tVB_ojBRclv"
      },
      "id": "6tVB_ojBRclv",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Nm9CTBp2Rclv"
      },
      "id": "Nm9CTBp2Rclv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Define Nodes with Retry and Fallback\n",
        "Create the individual nodes (functions) that represent steps in your workflow, incorporating retry logic and fallback mechanisms."
      ],
      "metadata": {
        "id": "VgiZqeEMRclv"
      },
      "id": "VgiZqeEMRclv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: `generate_content` Node with Retry\n",
        "This node will generate content based on the `topic`. Implement a **retry mechanism** using `tenacity` for transient failures (e.g., API errors, rate limits)."
      ],
      "metadata": {
        "id": "cwHs74QdRclw"
      },
      "id": "cwHs74QdRclw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Simulated Failure**: Introduce a `random.random() < 0.3` check to raise a `RuntimeError` (simulating a transient API error) in about 30% of calls.\n",
        "* **Retry Strategy**: Use `@retry` decorator with `stop_after_attempt` (e.g., 3 attempts) and `wait_fixed` (e.g., 2 seconds).\n",
        "* **Output**: Update `generated_content` and `status` to \"Needs Review\" upon success."
      ],
      "metadata": {
        "id": "Nu5Zp0WARclw"
      },
      "id": "Nu5Zp0WARclw"
    },
    {
      "cell_type": "code",
      "source": [
        "generation_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a content writer. Generate a short article (around 150-200 words) on the following topic.\"),\n",
        "    (\"user\", \"Topic: {topic}\")\n",
        "])\n",
        "\n",
        "generation_chain = generation_prompt | llm\n",
        "\n",
        "@retry(\n",
        "    stop=stop_after_attempt(3),\n",
        "    wait=wait_fixed(2),\n",
        "    retry=retry_if_exception_type(RuntimeError),\n",
        "    reraise=True # Re-raise the exception after retries are exhausted\n",
        ")\n",
        "def _generate_content_inner(topic: str) -> str:\n",
        "    # Simulate a transient failure\n",
        "    if random.random() < 0.3: # 30% chance of failure\n",
        "        raise RuntimeError(\"Simulated API error during content generation!\")\n",
        "\n",
        "    print(f\"  Generating content for: {topic}...\")\n",
        "    response = generation_chain.invoke({\"topic\": topic})\n",
        "    return response.content\n",
        "\n",
        "def generate_content_node(state: ContentWorkflowState) -> ContentWorkflowState:\n",
        "    print(\"\\n--- Node: Generating Content ---\")\n",
        "    topic = state[\"topic\"]\n",
        "    retries_left = state.get(\"retries_left\", 3) # Initial retries\n",
        "\n",
        "    if retries_left <= 0:\n",
        "        print(\"  No retries left for content generation. Falling back...\")\n",
        "        return {\"status\": \"Failed\", \"error_message\": \"Content generation failed after multiple retries.\"}\n",
        "\n",
        "    try:\n",
        "        content = _generate_content_inner(topic)\n",
        "        print(\"  Content generated successfully.\")\n",
        "        return {\"generated_content\": content, \"status\": \"Needs Review\", \"retries_left\": 3, \"error_message\": \"\"}\n",
        "    except RuntimeError as e:\n",
        "        print(f\"  Content generation failed: {e}. Retrying...\")\n",
        "        return {\"status\": \"Draft\", \"retries_left\": retries_left - 1, \"error_message\": str(e)}\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred during content generation: {e}. Escalating...\")\n",
        "        return {\"status\": \"Failed\", \"error_message\": f\"Unexpected error in content generation: {e}\"}\n",
        "\n",
        "print(\"generate_content_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "bFFDGdiKRclw"
      },
      "id": "bFFDGdiKRclw",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.2: `review_content` Node with Fallback\n",
        "This node will review the generated content. Implement a **fallback mechanism** if the LLM fails to provide a structured review (e.g., using Pydantic output).\n",
        "\n",
        "    * **Simulated Failure**: Introduce a `random.random() < 0.2` check to raise a `ValidationError` (simulating LLM outputting malformed data) in about 20% of calls. Also, occasionally simulate an LLM giving a 'Rejected' status even if content is okay, to test the retry to `generate_content`.\n",
        "    * **Fallback Strategy**: If `ValidationError` occurs, the node should `pass` the content directly to an `escalate_human_review` node instead of failing the workflow.\n",
        "    * **Output**: Update `review_feedback` and `status` to \"Approved\" or \"Rejected\"."
      ],
      "metadata": {
        "id": "Dkvn8EOjRclw"
      },
      "id": "Dkvn8EOjRclw"
    },
    {
      "cell_type": "code",
      "source": [
        "class ReviewOutput(BaseModel):\n",
        "    status: Literal[\"Approved\", \"Rejected\"]\n",
        "    feedback: str = Field(description=\"Detailed feedback for approval or rejection.\")\n",
        "\n",
        "review_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", \"You are a content reviewer. Review the following content for quality, relevance, and adherence to the topic. Provide feedback and categorize the content as 'Approved' or 'Rejected'.\"),\n",
        "    (\"user\", \"Topic: {topic}\\n\\nContent: {content}\")\n",
        "]).partial(\n",
        "    format_instructions=ReviewOutput.schema_json()\n",
        ")\n",
        "\n",
        "review_chain = review_prompt | llm.with_structured_output(ReviewOutput)\n",
        "\n",
        "def review_content_node(state: ContentWorkflowState) -> ContentWorkflowState:\n",
        "    print(\"\\n--- Node: Reviewing Content ---\")\n",
        "    topic = state[\"topic\"]\n",
        "    content = state[\"generated_content\"]\n",
        "\n",
        "    # Simulate LLM outputting malformed data (ValidationError) or a 'Rejected' status for good content\n",
        "    if random.random() < 0.2: # 20% chance of ValidationError\n",
        "        print(\"  Simulating ValidationError during review (malformed output).\")\n",
        "        # Raise a fake ValidationError that will be caught\n",
        "        raise ValidationError([{'loc': ('sentiment',), 'msg': 'value is not a valid enumeration member', 'type': 'type_error.enum'}], ReviewOutput)\n",
        "\n",
        "    # Occasionally simulate a 'Rejected' output even if content is good, to test retry to generation\n",
        "    if random.random() < 0.1: # 10% chance of a 'false negative' review\n",
        "        print(\"  Simulating a 'Rejected' review to trigger re-generation.\")\n",
        "        return {\n",
        "            \"review_feedback\": \"Content was unexpectedly rejected during review process, needs re-generation.\",\n",
        "            \"status\": \"Rejected\" # Will lead back to generate_content\n",
        "        }\n",
        "\n",
        "    try:\n",
        "        review_result = review_chain.invoke({\"topic\": topic, \"content\": content})\n",
        "        print(f\"  Review result: {review_result.status} - {review_result.feedback}\")\n",
        "        return {\n",
        "            \"review_feedback\": review_result.feedback,\n",
        "            \"status\": review_result.status,\n",
        "            \"error_message\": \"\"\n",
        "        }\n",
        "    except ValidationError as e:\n",
        "        print(f\"  Review failed validation: {e}. Falling back to human review.\")\n",
        "        return {\n",
        "            \"status\": \"Failed\", # Mark as failed to trigger escalation\n",
        "            \"error_message\": f\"Review output validation failed: {e}\"\n",
        "        }\n",
        "    except Exception as e:\n",
        "        print(f\"  An unexpected error occurred during content review: {e}. Falling back to human review.\")\n",
        "        return {\n",
        "            \"status\": \"Failed\", # Mark as failed to trigger escalation\n",
        "            \"error_message\": f\"Unexpected error in content review: {e}\"\n",
        "        }\n",
        "\n",
        "print(\"review_content_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "UWvHMqRPRclw"
      },
      "id": "UWvHMqRPRclw",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.3: `escalate_human_review` Node\n",
        "This node handles situations where automated steps fail or a human needs to intervene. It should capture the reason for escalation."
      ],
      "metadata": {
        "id": "IXimOUxURclx"
      },
      "id": "IXimOUxURclx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Purpose**: Marks the workflow for human intervention.\n",
        "* **Output**: Updates `status` to \"Failed\" and sets `error_message` with a clear reason."
      ],
      "metadata": {
        "id": "oMRYQCzIRclx"
      },
      "id": "oMRYQCzIRclx"
    },
    {
      "cell_type": "code",
      "source": [
        "def escalate_human_review_node(state: ContentWorkflowState) -> ContentWorkflowState:\n",
        "    print(\"\\n--- Node: Escalating to Human Review ---\")\n",
        "    reason = state.get(\"error_message\", \"Unknown reason for escalation.\")\n",
        "    if state[\"status\"] == \"Rejected\":\n",
        "        reason = \"Content rejected by automated review. Needs human re-evaluation.\"\n",
        "    elif state[\"status\"] == \"Draft\" and \"retries_left\" in state and state[\"retries_left\"] <= 0:\n",
        "        reason = \"Content generation failed after multiple retries. Needs human intervention.\"\n",
        "\n",
        "    print(f\"  Escalated. Reason: {reason}\")\n",
        "    return {\n",
        "        \"status\": \"Failed\",\n",
        "        \"error_message\": reason\n",
        "    }\n",
        "\n",
        "print(\"escalate_human_review_node defined!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "y_sUl116Rclx"
      },
      "id": "y_sUl116Rclx",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Jn1FQILURclx"
      },
      "id": "Jn1FQILURclx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Constructing the LangGraph Workflow\n",
        "Combine your nodes into a directed graph using LangGraph's `StateGraph`, defining conditional logic for retries and fallbacks."
      ],
      "metadata": {
        "id": "ripUHiDSRclx"
      },
      "id": "ripUHiDSRclx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Define Edges and Conditional Logic\n",
        "Define the graph's nodes, entry point, and the conditional edges that determine the flow based on the `status` and `retries_left`."
      ],
      "metadata": {
        "id": "IdJzG0unRclx"
      },
      "id": "IdJzG0unRclx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Graph Flow**:\n",
        "    1.  **Entry Point**: `generate_content`.\n",
        "    2.  From `generate_content`:\n",
        "        * If `status` is \"Needs Review\", go to `review_content`.\n",
        "        * If `status` is \"Draft\" and `retries_left > 0`, loop back to `generate_content` (retry).\n",
        "        * If `status` is \"Failed\" or `retries_left == 0`, go to `escalate_human_review` (fallback).\n",
        "    3.  From `review_content`:\n",
        "        * If `status` is \"Approved\", `END` the workflow.\n",
        "        * If `status` is \"Rejected\", loop back to `generate_content` (re-generation).\n",
        "        * If `status` is \"Failed\" (due to review validation error), go to `escalate_human_review` (fallback).\n",
        "    4.  From `escalate_human_review`: `END` the workflow."
      ],
      "metadata": {
        "id": "J9WcDhwrRclx"
      },
      "id": "J9WcDhwrRclx"
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the graph\n",
        "workflow = StateGraph(ContentWorkflowState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"generate\", generate_content_node)\n",
        "workflow.add_node(\"review\", review_content_node)\n",
        "workflow.add_node(\"escalate\", escalate_human_review_node)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"generate\")\n",
        "\n",
        "# Define conditional edges from 'generate'\n",
        "def route_after_generate(state: ContentWorkflowState) -> Literal[\"review\", \"generate\", \"escalate\"]:\n",
        "    if state[\"status\"] == \"Needs Review\":\n",
        "        return \"review\"\n",
        "    elif state[\"status\"] == \"Draft\" and state[\"retries_left\"] > 0:\n",
        "        return \"generate\" # Retry generation\n",
        "    else: # status is 'Failed' or retries_left == 0\n",
        "        return \"escalate\" # Fallback to human review\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"generate\",\n",
        "    route_after_generate,\n",
        "    {\n",
        "        \"review\": \"review\",\n",
        "        \"generate\": \"generate\",\n",
        "        \"escalate\": \"escalate\",\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define conditional edges from 'review'\n",
        "def route_after_review(state: ContentWorkflowState) -> Literal[\"generate\", \"escalate\", END]:\n",
        "    if state[\"status\"] == \"Approved\":\n",
        "        return END\n",
        "    elif state[\"status\"] == \"Rejected\":\n",
        "        return \"generate\" # Re-generate content\n",
        "    else: # status is 'Failed' (due to validation error or unexpected error)\n",
        "        return \"escalate\" # Fallback to human review\n",
        "\n",
        "workflow.add_conditional_edges(\n",
        "    \"review\",\n",
        "    route_after_review,\n",
        "    {\n",
        "        \"generate\": \"generate\",\n",
        "        \"escalate\": \"escalate\",\n",
        "        END: END,\n",
        "    },\n",
        ")\n",
        "\n",
        "# Define edge from 'escalate' to END\n",
        "workflow.add_edge(\"escalate\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "\n",
        "print(\"LangGraph workflow compiled!\")\n",
        "\n",
        "# Optional: Visualize the graph (requires 'graphviz' and 'pydotplus')\n",
        "# try:\n",
        "#     from IPython.display import Image, display\n",
        "#     display(Image(app.get_graph().draw_png()))\n",
        "# except ImportError:\n",
        "#     print(\"Install graphviz and pydotplus for visualization: pip install graphviz pydotplus\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "OPPvF1k-Rclx"
      },
      "id": "OPPvF1k-Rclx",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "NxDKGRQARcly"
      },
      "id": "NxDKGRQARcly"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Testing and Tracing the Workflow\n",
        "Test your workflow with various topics, observing its behavior, retries, fallbacks, and utilizing LangSmith for tracing."
      ],
      "metadata": {
        "id": "n7h0LKbeRcly"
      },
      "id": "n7h0LKbeRcly"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 4.1: Test Cases and Observation\n",
        "Run the workflow with the following types of inputs. For each run, observe the console output and then examine the corresponding trace in LangSmith.\n",
        "\n",
        "* **Test Topics**:\n",
        "    1.  `'The benefits of sustainable agriculture'` (Expected: Approved, if no simulated failures)\n",
        "    2.  `'The future of quantum computing'` (Expected: Should trigger retry/fallback, depending on `generate_content` failures)\n",
        "    3.  `'Tips for healthy eating'` (Expected: Should trigger review rejection/fallback, depending on `review_content` failures)\n",
        "    4.  `'The history of artificial intelligence'` (Test multiple times to see different paths due to random failures)\n",
        "\n",
        "For each test case:\n",
        "1.  Run the workflow by calling `run_workflow_and_print_state`.\n",
        "2.  **Paste the console output (steps and final state)**.\n",
        "3.  **Provide a screenshot or a direct link to the LangSmith trace** for that specific run.\n",
        "4.  **Describe** what happened during the execution (e.g., \"Retried 2 times for generation, then approved\", \"Generated successfully, but review failed validation and escalated\")."
      ],
      "metadata": {
        "id": "PC-SxNzGRcly"
      },
      "id": "PC-SxNzGRcly"
    },
    {
      "cell_type": "code",
      "source": [
        "def run_workflow_and_print_state(topic: str):\n",
        "    print(f\"\\n\\n=========== Processing Topic: '{topic}' ===========\")\n",
        "    initial_state = {\n",
        "        \"topic\": topic,\n",
        "        \"generated_content\": \"\",\n",
        "        \"review_feedback\": \"\",\n",
        "        \"status\": \"Draft\", # Initial status\n",
        "        \"retries_left\": 3, # Max retries for generation\n",
        "        \"error_message\": \"\"\n",
        "    }\n",
        "\n",
        "    final_state = None\n",
        "    try:\n",
        "        for s in app.stream(initial_state):\n",
        "            print(f\"Current state: {s}\")\n",
        "            final_state = s\n",
        "        print(f\"Final state for '{topic}': {final_state}\")\n",
        "    except Exception as e:\n",
        "        print(f\"An unhandled error occurred during workflow execution: {e}\")\n",
        "\n",
        "# --- Run your test cases ---\n",
        "test_topics = [\n",
        "    'The benefits of sustainable agriculture', # Expected: Approved, if no simulated failures\n",
        "    'The future of quantum computing',          # Expected: Should trigger retry/fallback\n",
        "    'Tips for healthy eating',                  # Expected: Should trigger review rejection/fallback\n",
        "    'The history of artificial intelligence'    # Test multiple times to see different paths\n",
        "]\n",
        "\n",
        "# Uncomment and run each test case individually to analyze its LangSmith trace clearly\n",
        "# run_workflow_and_print_state(test_topics[0])\n",
        "# run_workflow_and_print_state(test_topics[1])\n",
        "# run_workflow_and_print_state(test_topics[2])\n",
        "# run_workflow_and_print_state(test_topics[3])\n",
        "\n",
        "print(\"Uncomment the 'run_workflow_and_print_state' calls above to execute tests.\")\n",
        "print(\"Remember to observe console output and check LangSmith for traces.\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "xyeM5PwDRcly"
      },
      "id": "xyeM5PwDRcly",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 4.1:\n",
        "\n",
        "**Test Case 1: 'The benefits of sustainable agriculture'**\n",
        "\n",
        "* **Console Output:**\n",
        "    ```\n",
        "    [Paste console output here]\n",
        "    ```\n",
        "* **LangSmith Trace Link/Screenshot:**\n",
        "    [Paste LangSmith Trace Link or embed screenshot here]\n",
        "* **Execution Description:**\n",
        "    [Describe what happened during this run.]\n",
        "\n",
        "**Test Case 2: 'The future of quantum computing'**\n",
        "\n",
        "* **Console Output:**\n",
        "    ```\n",
        "    [Paste console output here]\n",
        "    ```\n",
        "* **LangSmith Trace Link/Screenshot:**\n",
        "    [Paste LangSmith Trace Link or embed screenshot here]\n",
        "* **Execution Description:**\n",
        "    [Describe what happened during this run, specifically focusing on retries/fallbacks.]\n",
        "\n",
        "**Test Case 3: 'Tips for healthy eating'**\n",
        "\n",
        "* **Console Output:**\n",
        "    ```\n",
        "    [Paste console output here]\n",
        "    ```\n",
        "* **LangSmith Trace Link/Screenshot:**\n",
        "    [Paste LangSmith Trace Link or embed screenshot here]\n",
        "* **Execution Description:**\n",
        "    [Describe what happened during this run, specifically focusing on review failures/fallbacks.]\n",
        "\n",
        "**Test Case 4: 'The history of artificial intelligence' (Run multiple times)**\n",
        "\n",
        "* **Run 1 Console Output:**\n",
        "    ```\n",
        "    [Paste console output here]\n",
        "    ```\n",
        "* **Run 1 LangSmith Trace Link/Screenshot:**\n",
        "    [Paste LangSmith Trace Link or embed screenshot here]\n",
        "* **Run 1 Execution Description:**\n",
        "    [Describe what happened during this run.]\n",
        "\n",
        "* **Run 2 Console Output:**\n",
        "    ```\n",
        "    [Paste console output here]\n",
        "    ```\n",
        "* **Run 2 LangSmith Trace Link/Screenshot:**\n",
        "    [Paste LangSmith Trace Link or embed screenshot here]\n",
        "* **Run 2 Execution Description:**\n",
        "    [Describe what happened during this run.]"
      ],
      "metadata": {
        "id": "MOOZ8k1FRcly"
      },
      "id": "MOOZ8k1FRcly"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "Wq1ey352Rclz"
      },
      "id": "Wq1ey352Rclz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Conclusion and Reflection\n",
        "In this markdown cell, provide a comprehensive summary of your findings and reflections based on this assignment."
      ],
      "metadata": {
        "id": "Loms1bAFRclz"
      },
      "id": "Loms1bAFRclz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Effectiveness of Resilience Patterns**: How effective were the retry and fallback mechanisms in making your LangGraph workflow more robust? Provide concrete examples from your traces.\n",
        "* **Value of Tracing**: How did LangSmith tracing aid in debugging, understanding, and evaluating your complex LangGraph workflow, especially when failures occurred?\n",
        "* **Challenges in Implementation**: What were the main challenges you faced in implementing retry, fallback, and integrating tracing?\n",
        "* **Future Enhancements**: If you were to extend this workflow, what other resilience patterns or observability features would you add (e.g., circuit breakers, alerts, more sophisticated error handling, different fallback options)?\n",
        "* **Production Readiness**: Discuss what it means for an LLM application to be \"production-ready\" from the perspective of resilience and observability, based on this assignment."
      ],
      "metadata": {
        "id": "kmnd8ZCXRclz"
      },
      "id": "kmnd8ZCXRclz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "7td3ltW-Rclz"
      },
      "id": "7td3ltW-Rclz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission:\n",
        "* Ensure all code cells have been executed and their outputs are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Provide screenshots or direct links to your LangSmith traces for each test case.\n",
        "* Save your Jupyter Notebook as `[YourName]_LangGraph_Resilience_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "acgy4dQGRclz"
      },
      "id": "acgy4dQGRclz"
    }
  ]
}