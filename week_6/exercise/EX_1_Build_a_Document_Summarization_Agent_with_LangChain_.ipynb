{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "colab": {
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Build a Document Summarization Agent with LangChain\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "MKIBWDl5Pfpv"
      },
      "id": "MKIBWDl5Pfpv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Objective:\n",
        "This assignment will guide you through building a **document summarization agent using LangChain**. You'll learn how to load documents, split them into manageable chunks, and apply different summarization techniques (like `stuff`, `map_reduce`, and `refine`) with a Large Language Model (LLM). By the end, you'll be able to summarize long texts efficiently and understand the trade-offs of various summarization strategies."
      ],
      "metadata": {
        "id": "wXu2Lme1Pfpw"
      },
      "id": "wXu2Lme1Pfpw"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "4wyL-YE8Pfpx"
      },
      "id": "4wyL-YE8Pfpx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Instructions:\n",
        "1.  **LLM Access**: You'll need access to an LLM API (e.g., Google's Gemini, OpenAI's GPT-4). For this assignment, we'll primarily use **Google's Gemini Pro model** via the `google-generativeai` integration with LangChain.\n",
        "2.  **Environment Setup**: Install the necessary Python libraries: `pip install langchain-google-genai langchain_community unstructured pypdf`.\n",
        "3.  **API Key**: Securely handle your API key. It's best practice to load it from an environment variable.\n",
        "4.  **Jupyter Notebook**: All your code, outputs, observations, and analysis must be documented in this Jupyter Notebook.\n",
        "5.  **Document Selection**: You'll need a long document (e.g., a research paper, an article, a chapter from a book) to summarize. A PDF file is recommended for testing `PyPDFLoader`.\n",
        "6.  **Analysis**: Critically evaluate the summaries generated by each method."
      ],
      "metadata": {
        "id": "0MBNYTQiPfpx"
      },
      "id": "0MBNYTQiPfpx"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "5tOeqT3OPfpy"
      },
      "id": "5tOeqT3OPfpy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Setup and Document Loading\n",
        "Begin by configuring your LLM and loading a document into LangChain."
      ],
      "metadata": {
        "id": "6kDge3D_Pfpy"
      },
      "id": "6kDge3D_Pfpy"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.1: API Configuration and LLM Initialization\n",
        "Set up your Google Generative AI API key and initialize the `ChatGoogleGenerativeAI` model in LangChain."
      ],
      "metadata": {
        "id": "rv7rBmGyPfpy"
      },
      "id": "rv7rBmGyPfpy"
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.chains.summarize import load_summarize_chain\n",
        "\n",
        "# --- YOUR API KEY HERE ---\n",
        "# It's highly recommended to load your API key from an environment variable for security.\n",
        "# For example:\n",
        "# os.environ[\"GOOGLE_API_KEY\"] = os.getenv(\"GOOGLE_API_KEY\")\n",
        "# For this assignment, you can temporarily paste it directly, but be careful not to share your notebook with the key.\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"YOUR_API_KEY_HERE\" # Replace with your actual API key\n",
        "\n",
        "# Initialize the LLM (Gemini Pro)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-pro\", temperature=0.7)\n",
        "\n",
        "print(\"LangChain LLM initialized with Gemini Pro!\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "mCj5yqYhPfpz"
      },
      "id": "mCj5yqYhPfpz",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 1.2: Document Loading and Splitting\n",
        "Choose a document (e.g., a PDF, a long text file) and load it using an appropriate LangChain Document Loader. Then, split the document into smaller, manageable chunks using a `RecursiveCharacterTextSplitter`."
      ],
      "metadata": {
        "id": "oqiyoCgXPfp0"
      },
      "id": "oqiyoCgXPfp0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Choose a document**: Ideally, a PDF or a `.txt` file that is at least 3-5 pages long (or contains equivalent text).\n",
        "    * If using PDF: Place the PDF file in the same directory as this notebook.\n",
        "    * If using text: Create a `.txt` file with your long text.\n",
        "* **Document Loader**: Use `PyPDFLoader` for PDFs or `TextLoader` for text files.\n",
        "* **Text Splitter**: Use `RecursiveCharacterTextSplitter` with `chunk_size` and `chunk_overlap` of your choice. Experiment with these values.\n",
        "\n",
        "**Chosen Document**: [Specify the name and type of your chosen document, e.g., `my_research_paper.pdf`]\n",
        "**Chosen `chunk_size`**: [Your chosen chunk size]\n",
        "**Chosen `chunk_overlap`**: [Your chosen chunk overlap]"
      ],
      "metadata": {
        "id": "zEU8c6RlPfp0"
      },
      "id": "zEU8c6RlPfp0"
    },
    {
      "cell_type": "code",
      "source": [
        "# Replace 'path/to/your/document.pdf' or 'path/to/your/document.txt' with your actual file path\n",
        "# Example for PDF:\n",
        "file_path = \"sample_document.pdf\" # Make sure this file exists in your directory\n",
        "loader = PyPDFLoader(file_path)\n",
        "# If you're using a .txt file, uncomment the line below and comment the PyPDFLoader line:\n",
        "# loader = TextLoader(\"sample_document.txt\")\n",
        "\n",
        "documents = loader.load()\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,   # Experiment with this value\n",
        "    chunk_overlap=200, # Experiment with this value\n",
        "    length_function=len,\n",
        "    is_separator_regex=False,\n",
        ")\n",
        "\n",
        "chunks = text_splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Original document loaded into {len(documents)} document(s).\")\n",
        "print(f\"Document split into {len(chunks)} chunks.\")\n",
        "print(f\"First chunk example (first 200 chars):\\n{chunks[0].page_content[:200]}...\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "EDdaG0M_Pfp1"
      },
      "id": "EDdaG0M_Pfp1",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 1.2:\n",
        "* Why is it necessary to split documents for summarization with LLMs?\n",
        "* How do `chunk_size` and `chunk_overlap` affect the chunks? What are the potential trade-offs of using very small vs. very large chunks?\n",
        "* What challenges might arise when splitting documents (e.g., losing context between chunks)?"
      ],
      "metadata": {
        "id": "4iZtWO0sPfp1"
      },
      "id": "4iZtWO0sPfp1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "M2QM7XdzPfp1"
      },
      "id": "M2QM7XdzPfp1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: Implementing Summarization Chains\n",
        "Now, you'll apply different summarization strategies provided by LangChain."
      ],
      "metadata": {
        "id": "DL0bGs8MPfp1"
      },
      "id": "DL0bGs8MPfp1"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.1: 'Stuff' Chain Summarization\n",
        "Use the `stuff` chain, which simply 'stuffs' all document chunks into a single prompt. This works best for smaller documents that fit within the LLM's context window."
      ],
      "metadata": {
        "id": "dj3G8xUsPfp2"
      },
      "id": "dj3G8xUsPfp2"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"--- Running 'Stuff' Chain Summarization ---\")\n",
        "try:\n",
        "    # Make sure your chunks are small enough to fit into the LLM's context window\n",
        "    # For very large documents, 'stuff' will fail due to token limit.\n",
        "    # Consider using only the first few chunks for demonstration if your document is long.\n",
        "    stuff_chain = load_summarize_chain(llm, chain_type=\"stuff\")\n",
        "\n",
        "    # If your document is very long, you might need to summarize only the first few chunks:\n",
        "    # summary_stuff = stuff_chain.run(chunks[:5]) # Example: summarize only first 5 chunks\n",
        "\n",
        "    summary_stuff = stuff_chain.run(chunks) # Tries to summarize all chunks if they fit\n",
        "\n",
        "    print(\"\\n--- 'Stuff' Summary ---\")\n",
        "    print(summary_stuff)\n",
        "except Exception as e:\n",
        "    print(f\"Error with 'Stuff' chain: {e}\")\n",
        "    print(\"This often means your document is too long for the model's context window.\")\n",
        "    print(\"Try reducing the number of chunks passed to the chain (e.g., `chunks[:X]`) or using a smaller document.\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "LnpLo0eyPfp2"
      },
      "id": "LnpLo0eyPfp2",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 2.1:\n",
        "* What are the advantages of the 'stuff' chain? (e.g., capturing full context, simpler implementation).\n",
        "* What are its primary limitations?\n",
        "* How does the quality of the 'stuff' summary compare to your expectation?"
      ],
      "metadata": {
        "id": "yQQhC75DPfp2"
      },
      "id": "yQQhC75DPfp2"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.2: 'Map-Reduce' Chain Summarization\n",
        "Implement the `map_reduce` chain, which summarizes chunks individually (`map` step) and then combines those summaries (`reduce` step)."
      ],
      "metadata": {
        "id": "Jc1VxptZPfp2"
      },
      "id": "Jc1VxptZPfp2"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Running 'Map-Reduce' Chain Summarization ---\")\n",
        "map_reduce_chain = load_summarize_chain(llm, chain_type=\"map_reduce\")\n",
        "\n",
        "try:\n",
        "    summary_map_reduce = map_reduce_chain.run(chunks)\n",
        "    print(\"\\n--- 'Map-Reduce' Summary ---\")\n",
        "    print(summary_map_reduce)\n",
        "except Exception as e:\n",
        "    print(f\"Error with 'Map-Reduce' chain: {e}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "Q8mvP_MvPfp3"
      },
      "id": "Q8mvP_MvPfp3",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 2.2:\n",
        "* How does the 'map-reduce' summary differ from the 'stuff' summary in terms of style, length, and detail?\n",
        "* What are the main benefits of using 'map-reduce' for summarization?\n",
        "* What are its potential drawbacks (e.g., loss of global context, repetition)?"
      ],
      "metadata": {
        "id": "PVn-JFh-Pfp3"
      },
      "id": "PVn-JFh-Pfp3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 2.3: 'Refine' Chain Summarization\n",
        "Utilize the `refine` chain, which iteratively builds a summary by passing each chunk and the current summary to the LLM."
      ],
      "metadata": {
        "id": "TpHl2ytXPfp3"
      },
      "id": "TpHl2ytXPfp3"
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\n--- Running 'Refine' Chain Summarization ---\")\n",
        "refine_chain = load_summarize_chain(llm, chain_type=\"refine\")\n",
        "\n",
        "try:\n",
        "    summary_refine = refine_chain.run(chunks)\n",
        "    print(\"\\n--- 'Refine' Summary ---\")\n",
        "    print(summary_refine)\n",
        "except Exception as e:\n",
        "    print(f\"Error with 'Refine' chain: {e}\")"
      ],
      "outputs": [],
      "metadata": {
        "id": "RLIoU0BTPfp3"
      },
      "id": "RLIoU0BTPfp3",
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 2.3:\n",
        "* How does the 'refine' summary compare to 'stuff' and 'map-reduce'? Does it seem more coherent or detailed?\n",
        "* What are the advantages of the 'refine' approach (e.g., better contextual understanding, iterative improvement)?\n",
        "* What are its potential disadvantages (e.g., slower, potential for bias accumulation)?"
      ],
      "metadata": {
        "id": "H4wEW3YtPfp4"
      },
      "id": "H4wEW3YtPfp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "2z3ZFp08Pfp4"
      },
      "id": "2z3ZFp08Pfp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Comparative Analysis and Evaluation\n",
        "Compare the different summarization methods and discuss their suitability for various use cases."
      ],
      "metadata": {
        "id": "6GMVyTVePfp4"
      },
      "id": "6GMVyTVePfp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Task 3.1: Qualitative Comparison\n",
        "Compare the three generated summaries based on the following criteria:\n",
        "* **Conciseness**: How brief and to-the-point is each summary?\n",
        "* **Completeness**: Does each summary capture all key information?\n",
        "* **Coherence/Readability**: Does each summary flow well and make sense?\n",
        "* **Accuracy**: Is the information in the summary factual and free of hallucination?\n",
        "* **Length**: How long is each summary (e.g., word count)?"
      ],
      "metadata": {
        "id": "A8mYCujbPfp4"
      },
      "id": "A8mYCujbPfp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Comparison Table (Fill in your observations):**\n",
        "\n",
        "| Criteria             | 'Stuff' Chain | 'Map-Reduce' Chain | 'Refine' Chain |\n",
        "| :------------------- | :------------ | :----------------- | :------------- |\n",
        "| **Conciseness** |               |                    |                |\n",
        "| **Completeness** |               |                    |                |\n",
        "| **Coherence** |               |                    |                |\n",
        "| **Accuracy** |               |                    |                |\n",
        "| **Approx. Word Count** |               |                    |                |"
      ],
      "metadata": {
        "id": "fTI_0tUkPfp4"
      },
      "id": "fTI_0tUkPfp4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Analysis for Task 3.1:\n",
        "* Based on your comparison, which summarization method (`stuff`, `map_reduce`, `refine`) performed best for *your chosen document* and why?\n",
        "* Under what circumstances would you recommend each method for a practical application?\n",
        "    * When is `stuff` ideal?\n",
        "    * When is `map_reduce` most suitable?\n",
        "    * When does `refine` shine?\n",
        "* Did you observe any instances of hallucination or factual inaccuracies in any of the summaries? If so, describe them."
      ],
      "metadata": {
        "id": "AF3ZEjlgPfp5"
      },
      "id": "AF3ZEjlgPfp5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "yS9sSHYzPfp5"
      },
      "id": "yS9sSHYzPfp5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Conclusion and Reflection\n",
        "In this markdown cell, provide a comprehensive summary of your findings and reflections based on this assignment."
      ],
      "metadata": {
        "id": "PTkng5yOPfp5"
      },
      "id": "PTkng5yOPfp5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Key Learnings about LangChain Summarization**: What were your main takeaways regarding LangChain's capabilities for document summarization?\n",
        "* **Challenges Encountered**: What difficulties did you face during the assignment (e.g., token limits, quality of summaries, debugging)?\n",
        "* **Practical Applications**: How can document summarization agents be used in real-world scenarios (e.g., business, research, education)?\n",
        "* **Future Improvements**: If you were to further develop this summarization agent, what features or techniques would you explore next (e.g., custom prompts, combining methods, RAG for better factual accuracy)?\n",
        "* **Ethical Considerations**: Discuss any ethical implications related to automated document summarization, such as potential for bias, loss of nuance, or misrepresentation of original content."
      ],
      "metadata": {
        "id": "S6S07VjmPfp5"
      },
      "id": "S6S07VjmPfp5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "---"
      ],
      "metadata": {
        "id": "VQQ6BpYiPfp5"
      },
      "id": "VQQ6BpYiPfp5"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Submission:\n",
        "* Ensure all code cells have been executed and their outputs (including prints and summaries) are visible.\n",
        "* All analysis and reflections are clearly written in markdown cells.\n",
        "* Save your Jupyter Notebook as `[YourName]_LangChain_Summarization_Assignment.ipynb`."
      ],
      "metadata": {
        "id": "qjb_yhUTPfp6"
      },
      "id": "qjb_yhUTPfp6"
    }
  ]
}