{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#LangGraph ‚Äì Build & Link Execution Nodes using Gemini 1.5 Flash\n",
        "‚úÖ Step-by-Step Updated Implementation\n"
      ],
      "metadata": {
        "id": "5eAMajgnqnC5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Purpose: Build a multi-node LangGraph using the Gemini API for a full LLM workflow ‚Äî cleaning, summarizing, and refining text.\n",
        "\n",
        "#‚úÖ Use Case:\n",
        "Build a LangGraph that performs the following steps:\n",
        "\n",
        "Preprocess the input text (clean/remove unnecessary characters)\n",
        "\n",
        "Summarize it using Gemini\n",
        "\n",
        "Refine the summary using Gemini\n",
        "\n",
        "#üß∞ Requirements\n",
        "Install these first:"
      ],
      "metadata": {
        "id": "POewh40JqgsA"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZu4inn8ofIG",
        "outputId": "27cf56bf-ec00-44c9-94ce-ab37d5828270"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.11/dist-packages (0.4.8)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: langchain-core>=0.1 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.3.65)\n",
            "Requirement already satisfied: langgraph-checkpoint>=2.0.26 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.1.0)\n",
            "Requirement already satisfied: langgraph-prebuilt>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.2.2)\n",
            "Requirement already satisfied: langgraph-sdk>=0.1.42 in /usr/local/lib/python3.11/dist-packages (from langgraph) (0.1.70)\n",
            "Requirement already satisfied: pydantic>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langgraph) (2.11.7)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from langgraph) (3.5.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (0.6.15)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.25.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.172.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.14.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.3.45 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (0.3.45)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core>=0.1->langgraph) (24.2)\n",
            "Requirement already satisfied: ormsgpack>=1.10.0 in /usr/local/lib/python3.11/dist-packages (from langgraph-checkpoint>=2.0.26->langgraph) (1.10.0)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.11/dist-packages (from langgraph-sdk>=0.1.42->langgraph) (3.10.18)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic>=2.7.4->langgraph) (0.4.1)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.2.0)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.73.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (2025.6.15)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core>=0.1->langgraph) (3.0.0)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.3.45->langchain-core>=0.1->langgraph) (0.23.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx>=0.25.2->langgraph-sdk>=0.1.42->langgraph) (1.3.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install langgraph google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üßë‚Äçüíª Practical: LangGraph + Gemini - Multi-Node LLM Workflow"
      ],
      "metadata": {
        "id": "SWUDzhqDsq0X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 1: Import Required Libraries\n",
        "\n",
        "#Step 2: Set Up Gemini API Key"
      ],
      "metadata": {
        "id": "H3SMRvefssCG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Import necessary libraries\n",
        "import os\n",
        "from typing import TypedDict\n",
        "import google.generativeai as genai\n",
        "from langgraph.graph import StateGraph, END\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Set up Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyDqsEze47E4A8Xlm9WbGRTDYzpwY3VIrTA\"\n",
        "genai.configure(api_key=os.environ[\"GOOGLE_API_KEY\"])\n",
        "\n"
      ],
      "metadata": {
        "id": "P8xTKlCwpVff"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 3: Define State Schema Using TypedDict"
      ],
      "metadata": {
        "id": "dlh3nxn-s2R5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LLMState(TypedDict):\n",
        "    input: str\n",
        "    cleaned: str\n",
        "    summary: str\n",
        "    refined: str\n"
      ],
      "metadata": {
        "id": "WQxYelmspryz"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 4: Define Helper and Node Functions Using Gemini 1.5 Flash\n",
        "#üîπ Preprocessing Node"
      ],
      "metadata": {
        "id": "TGcToysEs3nv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_node(state: LLMState) -> LLMState:\n",
        "    text = state[\"input\"]\n",
        "    cleaned_text = text.replace(\"\\n\", \" \").strip()\n",
        "    return {**state, \"cleaned\": cleaned_text}\n"
      ],
      "metadata": {
        "id": "3XFuYYcdqbXP"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîπ Gemini 1.5 Flash Summarization Helper"
      ],
      "metadata": {
        "id": "4jwI8KsRs7GC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def gemini_flash_summarize(prompt: str) -> str:\n",
        "    model = genai.GenerativeModel(model_name=\"models/gemini-1.5-flash-latest\")\n",
        "    response = model.generate_content(prompt)\n",
        "    return response.text\n"
      ],
      "metadata": {
        "id": "PLDGdUWArTUI"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîπ Summarize Node"
      ],
      "metadata": {
        "id": "-B-_y9hOtA7D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def summarize_node(state: LLMState) -> LLMState:\n",
        "    cleaned = state[\"cleaned\"]\n",
        "    summary = gemini_flash_summarize(f\"Summarize the following text:\\n\\n{cleaned}\")\n",
        "    return {**state, \"summary\": summary}\n"
      ],
      "metadata": {
        "id": "g9PZRcxvrT6S"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üîπ Refine Node"
      ],
      "metadata": {
        "id": "6IWmUqM5tDeI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def refine_node(state: LLMState) -> LLMState:\n",
        "    summary = state[\"summary\"]\n",
        "    prompt = f\"Refine this summary to make it concise and more professional:\\n\\n{summary}\"\n",
        "    refined = gemini_flash_summarize(prompt)\n",
        "    return {**state, \"refined\": refined}\n"
      ],
      "metadata": {
        "id": "iuo8VT4zrYRk"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 5: Build the LangGraph"
      ],
      "metadata": {
        "id": "s5yeeDlMtGwh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder = StateGraph(LLMState)\n"
      ],
      "metadata": {
        "id": "bc-Ixo-Hrg5d"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 6: Add Nodes"
      ],
      "metadata": {
        "id": "2tFdFqnhtJTP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder.add_node(\"preprocess\", preprocess_node)\n",
        "builder.add_node(\"summarize\", summarize_node)\n",
        "builder.add_node(\"refine\", refine_node)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvDx2DxPsHhl",
        "outputId": "3ca5b61e-55a1-42cc-a2ca-a92c6b836010"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78c68473c410>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 7: Link the Nodes"
      ],
      "metadata": {
        "id": "wLBCoNIKtMCR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "builder.set_entry_point(\"preprocess\")\n",
        "builder.add_edge(\"preprocess\", \"summarize\")\n",
        "builder.add_edge(\"summarize\", \"refine\")\n",
        "builder.add_edge(\"refine\", END)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JuPSIWiCsI-d",
        "outputId": "71d646df-2b21-4395-9a4c-6bb7d4ef6148"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<langgraph.graph.state.StateGraph at 0x78c68473c410>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 8: Compile the Graph"
      ],
      "metadata": {
        "id": "sA_MXIQctOvE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "graph = builder.compile()\n"
      ],
      "metadata": {
        "id": "LJ2NpKfTsKVd"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Step 9: Run the LangGraph Workflow"
      ],
      "metadata": {
        "id": "OEXv3LKatRZg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_text = {\n",
        "    \"input\": \"\"\"\n",
        "    LangGraph is a Python framework that allows developers to build multi-step applications\n",
        "    with LLMs. It supports structured control over memory, branching, state transitions, and flow.\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "result = graph.invoke(input_text)\n",
        "\n",
        "# Print results\n",
        "print(\"üîπ Cleaned Input:\\n\", result[\"cleaned\"])\n",
        "print(\"\\nüìù Summary:\\n\", result[\"summary\"])\n",
        "print(\"\\n‚úÖ Refined Summary:\\n\", result[\"refined\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "id": "a9LBiBBxsLxl",
        "outputId": "783bc599-a16c-46dc-a9ca-484240c4d0af"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üîπ Cleaned Input:\n",
            " LangGraph is a Python framework that allows developers to build multi-step applications     with LLMs. It supports structured control over memory, branching, state transitions, and flow.\n",
            "\n",
            "üìù Summary:\n",
            " LangGraph is a Python framework for creating complex, multi-step applications using large language models (LLMs).  It provides structured management of application memory, branching logic, state changes, and overall workflow.\n",
            "\n",
            "\n",
            "‚úÖ Refined Summary:\n",
            " LangGraph is a Python framework for building complex LLM applications, managing application state, workflow, and branching logic efficiently.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üß† Key Concepts Covered\n",
        "\n",
        "| Concept      | Description                           |\n",
        "| ------------ | ------------------------------------- |\n",
        "| `TypedDict`  | Defines a schema for state            |\n",
        "| `StateGraph` | Manages node execution order and data |\n",
        "| `add_node()` | Registers a function as a node        |\n",
        "| `add_edge()` | Links nodes for control flow          |\n",
        "| `invoke()`   | Executes the full graph               |\n"
      ],
      "metadata": {
        "id": "wjoZxHxjtW8X"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WV9nQMM3sNAt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}