{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Assignment: Legal Q&A Assistant using RAG, LangGraph, and Streamlit\n",
        "\n",
        "## Objective\n",
        "This assignment challenges you to build an interactive Legal Question-Answering (Q&A) assistant using a Retrieval-Augmented Generation (RAG) architecture. You will integrate key technologies: a vector database (FAISS) for document retrieval, an LLM for generation, LangGraph for orchestrating a multi-step conversational flow (e.g., self-correction, factual checking), and Streamlit for creating a user-friendly web interface."
      ],
      "metadata": {
        "id": "yglKgmTJFT23"
      },
      "id": "yglKgmTJFT23"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1: Environment Setup and Document Ingestion (25 Marks)\n",
        "\n",
        "1.  **Environment Setup:**\n",
        "    * Create a new Python virtual environment.\n",
        "    * Install necessary libraries: `langchain`, `langchain-community`, `langchain-openai` (or `langchain-google-genai`, etc.), `faiss-cpu`, `sentence-transformers`, `streamlit`, `python-dotenv`, `tiktoken`.\n",
        "        * Provide a `requirements.txt` file.\n",
        "    * Set up your LLM API key (e.g., OpenAI API key, Google API key) in a `.env` file and load it in your script.\n",
        "\n",
        "2.  **Legal Document Corpus:**\n",
        "    * Find or create a small, focused set of legal documents (e.g., excerpts from a specific law, a few legal case summaries, terms and conditions of a service, or a simplified legal guide).\n",
        "    * **Minimum Requirement:** At least 5-10 distinct legal documents or sections, totaling at least 5-10 pages of text.\n",
        "    * Store these documents in a `data/` directory (e.g., as `.txt` or `.pdf` files).\n",
        "    * Describe your chosen legal corpus: what type of documents, their source, and approximate size.\n",
        "\n",
        "3.  **Document Loading and Splitting:**\n",
        "    * Implement code to load your legal documents (e.g., using `PyPDFLoader` or `TextLoader` from LangChain).\n",
        "    * Split the documents into smaller, manageable chunks (e.g., using `RecursiveCharacterTextSplitter`). Experiment with `chunk_size` and `chunk_overlap`.\n",
        "    * Print the number of original documents and the number of resulting chunks."
      ],
      "metadata": {
        "id": "0tqJHOELFT25"
      },
      "id": "0tqJHOELFT25"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6E89eSLtFT26"
      },
      "outputs": [],
      "source": [
        "# Your code for environment setup and requirements.txt.\n",
        "# Description of your legal corpus.\n",
        "# Code for document loading and splitting.\n",
        "# Print document and chunk counts."
      ],
      "id": "6E89eSLtFT26"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2: RAG Pipeline with FAISS Vector Store (25 Marks)\n",
        "\n",
        "1.  **Embeddings and Vector Store Creation:**\n",
        "    * Choose an embedding model (e.g., `OpenAIEmbeddings`, `HuggingFaceEmbeddings` with `sentence-transformers/all-MiniLM-L6-v2`).\n",
        "    * Create a FAISS vector store from your document chunks and embeddings.\n",
        "    * Save the FAISS index locally (e.g., `faiss_index.faiss`).\n",
        "    * Load the FAISS index to demonstrate it can be reloaded.\n",
        "\n",
        "2.  **Retriever Setup:**\n",
        "    * Create a retriever from your FAISS vector store.\n",
        "    * Configure the retriever to return a suitable number of relevant documents (e.g., `k=3` or `k=5`).\n",
        "    * Demonstrate the retriever by querying it with a legal question and printing the content of the retrieved documents.\n",
        "\n",
        "3.  **Basic RAG Chain:**\n",
        "    * Create a simple RAG chain using LangChain `Runnable` objects or an `LCEL` chain.\n",
        "    * The chain should:\n",
        "        * Take a user `question`.\n",
        "        * Retrieve relevant `context` from the vector store.\n",
        "        * Use a `ChatPromptTemplate` to construct a prompt for the LLM, incorporating both the `question` and `context`.\n",
        "        * Invoke an LLM to generate an `answer`.\n",
        "    * Test your basic RAG chain with 2-3 legal questions related to your corpus and print the generated answers."
      ],
      "metadata": {
        "id": "FOTehUMEFT27"
      },
      "id": "FOTehUMEFT27"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMUep_DLFT27"
      },
      "outputs": [],
      "source": [
        "# Your code for embedding creation, FAISS vector store creation/saving/loading.\n",
        "# Code for retriever setup and demonstration.\n",
        "        # Code for basic RAG chain and test queries."
      ],
      "id": "pMUep_DLFT27"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3: Advanced RAG with LangGraph (30 Marks)\n",
        "\n",
        "1.  **Define Graph Nodes:**\n",
        "    * Design a LangGraph application for your legal Q&A assistant. At a minimum, include the following nodes:\n",
        "        * **`retrieve`:** Takes the current state's `question` and retrieves relevant documents.\n",
        "        * **`generate`:** Takes the `question` and `context` and generates an initial answer.\n",
        "        * **`check_faithfulness` (Critique/Self-Correction):** This is a key node. It should take the generated `answer` and the `context`.\n",
        "            * Use an LLM call to determine if the `answer` is fully supported by the `context` (i.e., is it faithful to the retrieved documents?). Output a boolean (`True`/`False`) or a score and a reasoning.\n",
        "            * If not faithful, it should flag for regeneration or refinement.\n",
        "        * **`decide_next_step` (Conditional Edge):** Based on the `check_faithfulness` result, decide whether to `regenerate` or `end`.\n",
        "        * **`regenerate` (Optional):** If `check_faithfulness` fails, re-prompt the LLM with an instruction to be more faithful to the context.\n",
        "    * Define the `State` for your graph (e.g., `question`, `context`, `answer`, `faithfulness_check_result`).\n",
        "\n",
        "2.  **Define Graph Edges:**\n",
        "    * Connect your nodes with conditional and direct edges to form a flow.\n",
        "    * Example flow: `start -> retrieve -> generate -> check_faithfulness -> decide_next_step (conditional: regenerate / end)`.\n",
        "\n",
        "3.  **Compile and Test Graph:**\n",
        "    * Compile your LangGraph `StateGraph` into an `app`.\n",
        "    * Test your LangGraph application with at least **3 legal questions**.\n",
        "    * Include one question where you expect good grounding, and one where the model might struggle or hallucinate (to trigger the `check_faithfulness` logic).\n",
        "    * For each test case, print the final answer and observe the flow of execution (if possible, by including print statements in nodes or using LangSmith tracing if enabled). Discuss how the graph logic helped (or didn't help) improve the answer."
      ],
      "metadata": {
        "id": "4iJ2degOFT27"
      },
      "id": "4iJ2degOFT27"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cdw7CIlEFT28"
      },
      "outputs": [],
      "source": [
        "# Your Python code for defining LangGraph nodes, state, and edges.\n",
        "# Code for compiling and testing the graph with sample legal questions.\n",
        "# Discuss the observed flow and its impact on answers."
      ],
      "id": "cdw7CIlEFT28"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4: Streamlit Web Interface (20 Marks)\n",
        "\n",
        "1.  **Streamlit Application (`app.py`):**\n",
        "    * Create a Streamlit application (`app.py`) that serves as the user interface for your Legal Q&A Assistant.\n",
        "    * The app should:\n",
        "        * Have a clear title (e.g., \"Legal Q&A Assistant\").\n",
        "        * Provide a text input field for the user's legal question.\n",
        "        * Include a button to trigger the Q&A process.\n",
        "        * Display the LLM's generated answer.\n",
        "        * **Crucially:** Integrate your LangGraph application from Part 3. When the user submits a question, run the question through your LangGraph and display the final output.\n",
        "        * (Bonus) Display the retrieved context alongside the answer for transparency.\n",
        "        * (Bonus) Add a simple history/chat memory using `st.session_state`.\n",
        "\n",
        "2.  **Run and Demonstrate:**\n",
        "    * Run your Streamlit application locally (`streamlit run app.py`).\n",
        "    * Interact with your assistant, asking various legal questions.\n",
        "    * Take screenshots of your Streamlit application:\n",
        "        * The main interface with a question and its generated answer.\n",
        "        * (If bonus) A screenshot showing conversation history or retrieved context.\n",
        "    * Discuss the user experience. How well does the Streamlit interface present the assistant? What are its strengths and weaknesses?"
      ],
      "metadata": {
        "id": "xagoMTDAFT28"
      },
      "id": "xagoMTDAFT28"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTT1WBv6FT28"
      },
      "outputs": [],
      "source": [
        "# Your full Python code for `app.py` (the Streamlit application).\n",
        "# Commands to run the Streamlit app.\n",
        "# Screenshots of your running Streamlit application.\n",
        "# Discussion of the user experience."
      ],
      "id": "ZTT1WBv6FT28"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Reflection and Future Work (Bonus - 5 Marks)\n",
        "\n",
        "1.  **Impact of LangGraph:**\n",
        "    * How did LangGraph help in building a more robust or intelligent RAG pipeline compared to a simple linear chain?\n",
        "    * Discuss the benefits of defining explicit states and conditional logic.\n",
        "\n",
        "2.  **Legal Domain Challenges:**\n",
        "    * What specific challenges did you encounter when dealing with legal documents or legal questions for a Q&A system?\n",
        "    * How might the chosen LLM or retrieval approach need to be adapted for higher accuracy and trustworthiness in a legal context?\n",
        "\n",
        "3.  **Future Enhancements:**\n",
        "    * Suggest at least three significant enhancements for your Legal Q&A assistant (e.g., more sophisticated `check_faithfulness`, handling ambiguity, multi-document summarization for context, fine-tuning, user feedback collection, integrating with a real-time legal database)."
      ],
      "metadata": {
        "id": "1-j3O7PUFT28"
      },
      "id": "1-j3O7PUFT28"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Submission Guidelines\n",
        "\n",
        "* Submit this Jupyter Notebook (.ipynb file) with all cells executed and outputs visible.\n",
        "    * Ensure your code is well-commented and easy to understand.\n",
        "* Include all necessary project files in a single compressed archive (e.g., `.zip` file) or provide a link to a Git repository:\n",
        "    * Your Jupyter Notebook.\n",
        "    * `requirements.txt`.\n",
        "    * `app.py` (Streamlit application).\n",
        "    * `data/` directory with your legal documents.\n",
        "    * Your saved FAISS index file(s).\n",
        "    * `.env` (ensure API keys are not directly committed if using Git).\n",
        "* Clearly present all requested code, outputs, and screenshots.\n",
        "* Make sure your application can be set up and run successfully by the instructor."
      ],
      "metadata": {
        "id": "AFEmOVTOFT29"
      },
      "id": "AFEmOVTOFT29"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}